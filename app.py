# Y-Compass (ì™€ì´ì»´í¼ìŠ¤) â€” Streamlit MVP+ (ì‹¬ì‚¬ì ì„¤ë“ë ¥ ê°•í™” ë²„ì „)
# (1) CSV ì—…ë¡œë“œ ê¸°ë°˜ ë°ì´í„° ì»¤ë²„ë¦¬ì§€ í™•ì¥
# (2) ê²°ê³¼ ë°°ì§€(ë°ì´í„° ê¸°ë°˜/ê°€ì´ë“œ ê¸°ë°˜)
# (3) A/B/C ì ìˆ˜í™” + ê¸°ì—¬ë„ breakdown(ì„¤ëª…ê°€ëŠ¥ì„± ê°•í™”)
# (4) ì—°ë„ë³„ ê¸°ì¤€ì„  vs ë‚´ ì„±ì  ë¯¸ë‹ˆ ì°¨íŠ¸(ì—­ì¶•) + ì ìˆ˜/ê¸°ì—¬ë„ ì°¨íŠ¸
#
# ì‹¤í–‰:
#   streamlit run app.py
#
# í•„ìš” íŒ¨í‚¤ì§€:
#   pip install streamlit pandas altair requests

from __future__ import annotations

import json
from dataclasses import dataclass
from datetime import date
from typing import Any, Dict, List, Optional, Tuple

import altair as alt
import pandas as pd
import requests
import streamlit as st

# =========================================================
# Page Config + Styling
# =========================================================
st.set_page_config(page_title="ğŸ§­ Y-Compass", page_icon="ğŸ§­", layout="wide")

st.markdown(
    """
<style>
/* Badge pills */
.badge {
  display: inline-block;
  padding: 0.25rem 0.6rem;
  border-radius: 999px;
  font-weight: 700;
  font-size: 0.9rem;
  line-height: 1.2rem;
  border: 1px solid rgba(0,0,0,0.08);
}
.badge-data { background: rgba(16,185,129,0.14); color: rgb(6,95,70); }
.badge-guide { background: rgba(245,158,11,0.18); color: rgb(120,53,15); }
.badge-stable { background: rgba(59,130,246,0.14); color: rgb(30,64,175); }
.badge-fit { background: rgba(168,85,247,0.14); color: rgb(88,28,135); }
.badge-challenge { background: rgba(239,68,68,0.14); color: rgb(153,27,27); }

/* Cards */
.card-title { font-weight: 800; margin-bottom: 0.2rem; }
.small { color: rgba(0,0,0,0.6); font-size: 0.92rem; }
</style>
""",
    unsafe_allow_html=True,
)

# =========================================================
# Options
# =========================================================
ADMISSION_ROUTE = ["ìˆ˜ì‹œ", "ì •ì‹œ"]
SUSI_DETAIL = ["í•™ìƒë¶€êµê³¼", "í•™ìƒë¶€ì¢…í•©", "ë…¼ìˆ ", "íŠ¹ê¸°ì(í•´ë‹¹ ì‹œ)"]
MAJOR_GROUPS = ["ì¸ë¬¸", "ì‚¬íšŒ", "ìƒê²½", "ìì—°", "ê³µí•™", "ì˜ˆì²´ëŠ¥", "ìœµí•©/ììœ ì „ê³µ"]
ACTIVITY_PREF = ["ì‚¬ëŒ(ì†Œí†µ/ë¦¬ë”ì‹­)", "ë°ì´í„°(ë¶„ì„/ì •ëŸ‰)", "ê¸€(ì—ì„¸ì´/ìŠ¤í† ë¦¬)", "í˜„ì¥(í™œë™/í”„ë¡œì íŠ¸)"]
GOAL_PRIORITY = ["í•©ê²© ì•ˆì •ì„±", "ì ì„±/í¥ë¯¸", "ì·¨ì—…/ì§„ë¡œ ì—°ê³„", "ì¥í•™/ë¹„ìš©", "ì§€ì—­/ìƒí™œí™˜ê²½"]
CONSTRAINTS = ["ì§€ì—­(í†µí•™/ê±°ì£¼)", "ì˜ˆì‚°(ë¹„ìš©)", "ì‹œê°„(ë³‘í–‰ ì¼ì •)", "ê°€ì¡±/ëŒë´„", "ê¸°íƒ€"]
CURRENT_STAGE = ["ë‚´ì‹ /ìˆ˜ëŠ¥ ì¤€ë¹„", "ìê¸°ì†Œê°œì„œ/í•™ìƒë¶€ ì •ë¦¬", "ë©´ì ‘ ì¤€ë¹„", "ë…¼ìˆ  ì¤€ë¹„", "ì§€ì›ì „ëµ ìµœì¢… ì ê²€"]
EXTRACURRICULAR_LEVELS = ["ë‚®ìŒ", "ë³´í†µ", "ë†’ìŒ"]

CSV_REQUIRED_COLS = ["university", "major", "route", "year", "metric", "threshold"]
CSV_OPTIONAL_COLS = ["route_detail", "source", "note"]

# =========================================================
# Utilities
# =========================================================
def _nonempty(s: Optional[str]) -> str:
    return s.strip() if isinstance(s, str) and s.strip() else ""


def safe_int(x: Any) -> Optional[int]:
    try:
        return int(x)
    except Exception:
        return None


def safe_float(x: Any) -> Optional[float]:
    try:
        v = float(x)
        if pd.isna(v):
            return None
        return v
    except Exception:
        return None


def band_to_float(band: str) -> Optional[float]:
    """
    Convert UI band string to float-ish threshold.
    - "1.x" -> 1.5
    - "2.x" -> 2.5
    - "ì§ì ‘ì…ë ¥(ì˜ˆ: 2.3)" -> parse as float
    - "ëª¨ë¦„/ì…ë ¥ì•ˆí•¨" -> None
    """
    band = _nonempty(band)
    if not band or "ëª¨ë¦„" in band:
        return None
    if band.endswith(".x"):
        try:
            return float(band.replace(".x", "")) + 0.5
        except Exception:
            return None
    try:
        return float(band)
    except Exception:
        return None


def clamp(v: float, lo: float, hi: float) -> float:
    return max(lo, min(v, hi))


def coverage_badge_html(is_data_based: bool) -> str:
    if is_data_based:
        return '<span class="badge badge-data">ë°ì´í„° ê¸°ë°˜ âœ…</span>'
    return '<span class="badge badge-guide">ê°€ì´ë“œ ê¸°ë°˜ ğŸŸ¡</span>'


def band_badge_html(band: str) -> str:
    band = _nonempty(band)
    if band == "ì•ˆì •":
        return '<span class="badge badge-stable">ì•ˆì •</span>'
    if band == "ì ì •":
        return '<span class="badge badge-fit">ì ì •</span>'
    return '<span class="badge badge-challenge">ë„ì „</span>'


# =========================================================
# Data Handling: CSV -> normalized dataframe
# =========================================================
def normalize_df(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [c.strip().lower() for c in df.columns]

    missing = [c for c in CSV_REQUIRED_COLS if c not in df.columns]
    if missing:
        raise ValueError(f"CSVì— í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë¨: {missing}")

    for c in CSV_OPTIONAL_COLS:
        if c not in df.columns:
            df[c] = ""

    # normalize values
    df["university"] = df["university"].astype(str).str.strip()
    df["major"] = df["major"].astype(str).str.strip()
    df["route"] = df["route"].astype(str).str.strip()
    df["route_detail"] = df["route_detail"].astype(str).str.strip()
    df["metric"] = df["metric"].astype(str).str.strip().str.lower()

    df["year"] = df["year"].apply(safe_int)
    df["threshold"] = df["threshold"].apply(safe_float)

    df["source"] = df["source"].astype(str).str.strip()
    df["note"] = df["note"].astype(str).str.strip()

    df = df.dropna(subset=["year", "threshold"])
    df = df[df["metric"].isin(["gpa", "mock"])]

    # Clean route variants
    df["route"] = df["route"].replace({"ìˆ˜ì‹œ ": "ìˆ˜ì‹œ", "ì •ì‹œ ": "ì •ì‹œ"})
    df = df[df["route"].isin(["ìˆ˜ì‹œ", "ì •ì‹œ"])]

    # Remove obvious invalid threshold
    df = df[(df["threshold"] > 0) & (df["threshold"] < 10)]

    return df


def _major_match(mj_input: str, mj_row: str) -> bool:
    mj_input = _nonempty(mj_input)
    mj_row = _nonempty(mj_row)
    if not mj_input or not mj_row:
        return True
    return (mj_input in mj_row) or (mj_row in mj_input)


def match_rows(
    df: pd.DataFrame,
    university: str,
    major_text: str,
    route: str,
    route_detail: str,
    metric: str,
    max_rows: int = 200,
) -> pd.DataFrame:
    if df is None or df.empty:
        return df

    uni = _nonempty(university)
    mj = _nonempty(major_text)

    sub = df[df["university"] == uni]
    if mj:
        sub = sub[sub["major"].apply(lambda x: _major_match(mj, str(x)))]

    sub = sub[sub["route"] == route]
    sub = sub[sub["metric"] == metric]

    if route == "ìˆ˜ì‹œ":
        rd = _nonempty(route_detail)
        if rd:
            exact = sub[sub["route_detail"] == rd]
            generic = sub[sub["route_detail"] == ""]
            sub = pd.concat([exact, generic], ignore_index=True).drop_duplicates()

    sub = sub.sort_values("year", ascending=True).head(max_rows)
    return sub


# =========================================================
# Explainable Scoring: Score -> Band, and A/B/C scoring
# =========================================================
@dataclass
class ScoreWeights:
    academics: float
    extracurricular: float
    constraints: float
    preference_fit: float


def extracurricular_score(level: str) -> float:
    return {"ë‚®ìŒ": 20.0, "ë³´í†µ": 60.0, "ë†’ìŒ": 90.0}.get(level, 60.0)


def constraints_penalty(constraints: List[str]) -> float:
    p = 0.0
    for c in constraints:
        if "ì‹œê°„" in c:
            p += 18
        elif "ì˜ˆì‚°" in c:
            p += 15
        elif "ì§€ì—­" in c:
            p += 12
        else:
            p += 10
    return min(p, 45.0)


def preference_fit_score(activity_pref: List[str], route: str, route_detail: str) -> float:
    s = 50.0
    pref = " ".join(activity_pref)

    if route == "ì •ì‹œ":
        if "ë°ì´í„°" in pref:
            s += 25
        if "ê¸€" in pref:
            s += 5
        if "ì‚¬ëŒ" in pref:
            s += 5

    if route == "ìˆ˜ì‹œ":
        if "í•™ìƒë¶€ì¢…í•©" in route_detail:
            if "ê¸€" in pref:
                s += 20
            if "í˜„ì¥" in pref:
                s += 15
            if "ì‚¬ëŒ" in pref:
                s += 10
        elif "í•™ìƒë¶€êµê³¼" in route_detail:
            if "ë°ì´í„°" in pref:
                s += 20
        elif "ë…¼ìˆ " in route_detail:
            if "ê¸€" in pref:
                s += 20
            if "ë°ì´í„°" in pref:
                s += 10

    return clamp(s, 0.0, 100.0)


def academics_score(
    user_value: Optional[float],
    ref_series: Optional[pd.Series],
) -> Tuple[float, str, Optional[float]]:
    """
    Score 0..100. Lower grade is better.
    - If ref exists: anchor = most recent threshold (last year)
    - Return score, message, anchor
    """
    if user_value is None:
        return 50.0, "ì„±ì  ì…ë ¥ì´ ì—†ì–´ í•™ì—… ì ìˆ˜ëŠ” ì¤‘ë¦½(50)ìœ¼ë¡œ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.", None

    if ref_series is None or ref_series.empty:
        s = 100.0 - (user_value - 1.0) * 15.0
        s = clamp(s, 10.0, 90.0)
        return s, "ë°ì´í„° ì»¤ë²„ë¦¬ì§€ ë°–ì´ë¼ ì ˆëŒ€ê°’ ê¸°ë°˜(ê±°ì¹œ) ì ìˆ˜ë¡œ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.", None

    anchor = float(ref_series.dropna().iloc[-1])
    diff = user_value - anchor

    if diff <= -0.2:
        s = 90.0
        msg = f"ì…ë ¥ ì„±ì ({user_value:.1f})ì´ ìµœê·¼ ê¸°ì¤€ì„ ({anchor:.1f})ë³´ë‹¤ ìœ ë¦¬ â†’ í•™ì—… ì ìˆ˜â†‘"
    elif diff <= 0.4:
        s = 65.0
        msg = f"ì…ë ¥ ì„±ì ({user_value:.1f})ì´ ìµœê·¼ ê¸°ì¤€ì„ ({anchor:.1f}) ê·¼ì²˜ â†’ í•™ì—… ì ìˆ˜ ì¤‘ê°„"
    else:
        s = 35.0
        msg = f"ì…ë ¥ ì„±ì ({user_value:.1f})ì´ ìµœê·¼ ê¸°ì¤€ì„ ({anchor:.1f})ë³´ë‹¤ ë¶ˆë¦¬ â†’ í•™ì—… ì ìˆ˜â†“"

    return s, msg, anchor


def normalize_weights(w: ScoreWeights) -> ScoreWeights:
    s = w.academics + w.extracurricular + w.constraints + w.preference_fit
    if s <= 0:
        return ScoreWeights(0.45, 0.25, 0.2, 0.1)
    return ScoreWeights(w.academics / s, w.extracurricular / s, w.constraints / s, w.preference_fit / s)


def total_score(
    w: ScoreWeights,
    acad: float,
    extra: float,
    penalty: float,
    fit: float,
) -> Tuple[float, Dict[str, float]]:
    wn = normalize_weights(w)

    contrib_acad = acad * wn.academics
    contrib_extra = extra * wn.extracurricular
    contrib_fit = fit * wn.preference_fit
    contrib_penalty = penalty * wn.constraints

    score = contrib_acad + contrib_extra + contrib_fit - contrib_penalty
    score = clamp(score, 0.0, 100.0)

    breakdown = {
        "í•™ì—…(ì„±ì )": contrib_acad,
        "ë¹„êµê³¼": contrib_extra,
        "ì í•©ë„(ì„±í–¥â†”ì „í˜•)": contrib_fit,
        "ì œì•½(ê°ì )": -contrib_penalty,
        "ì´ì ": score,
    }
    return score, breakdown


def score_to_band(score: float) -> str:
    if score >= 75:
        return "ì•ˆì •"
    if score >= 55:
        return "ì ì •"
    return "ë„ì „"


def abc_scores(
    base_score: float,
    constraints: List[str],
    priorities: List[str],
) -> Dict[str, Dict[str, Any]]:
    """
    A/B/C ì ìˆ˜í™”(ì„¤ëª…ê°€ëŠ¥ ê·œì¹™):
    - base_score: ì‚¬ìš©ì ê¸°ë³¸ ì í•©ë„/ê°€ëŠ¥ì„± ì´ì 
    - A(ì•ˆì •): ë¦¬ìŠ¤í¬ íšŒí”¼(ì œì•½ ë§ì„ìˆ˜ë¡ A ê¶Œì¥ ê°€ì‚°), +8
    - B(ì ì •): ê¸°ì¤€, +0
    - C(ë„ì „): ìƒí–¥(ì œì•½ ë§ì„ìˆ˜ë¡ ê°ì‚°), -10

    ì¶”ê°€ë¡œ "ëª©í‘œ ìš°ì„ ìˆœìœ„"ê°€ 'í•©ê²© ì•ˆì •ì„±'ì´ë©´ A ìª½ ì†Œí­ ê°€ì‚°,
    'ì ì„±/í¥ë¯¸'ê°€ ìˆìœ¼ë©´ B ìª½ ì†Œí­ ê°€ì‚°,
    'ì·¨ì—…/ì§„ë¡œ ì—°ê³„'ê°€ ìˆìœ¼ë©´ C/B ìª½ ì†Œí­ ê°€ì‚°(ë„ì „ í—ˆìš©).
    """
    n_constraints = len(constraints)
    risk_factor = clamp(n_constraints / 4.0, 0.0, 1.0)  # 0~1

    p = " ".join(priorities or [])

    # small priority nudges
    a_nudge = 2.0 if "í•©ê²© ì•ˆì •ì„±" in p else 0.0
    b_nudge = 1.5 if "ì ì„±/í¥ë¯¸" in p else 0.0
    c_nudge = 1.5 if "ì·¨ì—…/ì§„ë¡œ ì—°ê³„" in p else 0.0

    a = base_score + 8.0 + (risk_factor * 4.0) + a_nudge
    b = base_score + 0.0 + b_nudge
    c = base_score - 10.0 - (risk_factor * 5.0) + c_nudge

    out = {
        "A": {"label": "ì•ˆì •", "score": clamp(a, 0, 100)},
        "B": {"label": "ì ì •", "score": clamp(b, 0, 100)},
        "C": {"label": "ë„ì „", "score": clamp(c, 0, 100)},
    }
    for k in out:
        out[k]["band"] = score_to_band(out[k]["score"])
    return out


# =========================================================
# OpenAI Responses API (optional)
# =========================================================
def openai_generate_plan(
    api_key: str,
    model: str,
    payload_json: Dict[str, Any],
    context_docs: List[Dict[str, str]],
) -> Dict[str, Any]:
    """
    Uses Responses API. Requests JSON object output.
    """
    url = "https://api.openai.com/v1/responses"
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}

    prompt = f"""
ë„ˆëŠ” 'ëŒ€í•™ ì§„í•™ AI ì»¨ì„¤í„´íŠ¸'ë‹¤.

ì›ì¹™(ë§¤ìš° ì¤‘ìš”):
- ì‚¬ìš©ìê°€ ì„ íƒ/ì…ë ¥í•œ ì „í˜•ì„ ìš°ì„  ì¡´ì¤‘í•˜ë˜, ê°€ëŠ¥ì„±/ë¦¬ìŠ¤í¬/ëŒ€ì•ˆê¹Œì§€ í•¨ê»˜ ì œì‹œí•˜ë¼.
- ì‚¬ì‹¤(ì „í˜•ìš”ê°•/ë°ì´í„°)ì€ ì•„ë˜ [ê·¼ê±° ë¬¸ì„œ]ì— ìˆëŠ” ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ë¼.
- ê·¼ê±° ë¬¸ì„œì— ì—†ëŠ” ìˆ˜ì¹˜/ì‚¬ì‹¤ì€ ë‹¨ì •í•˜ì§€ ë§ê³  "ì¼ë°˜ ê°€ì´ë“œ"ë¡œ í‘œí˜„í•˜ë¼.
- í™•ë¥  ë‹¨ì • ê¸ˆì§€. ëŒ€ì‹  ì•ˆì •/ì ì •/ë„ì „ êµ¬ê°„ìœ¼ë¡œ í‘œí˜„í•˜ë¼.
- 8ì£¼ ë¡œë“œë§µì€ ì‚¬ìš©ìê°€ ì„ íƒí•œ ì „í˜•ê³¼ í˜„ì¬ ì‹œì (ì›”/ì£¼ì°¨)ì„ ê³ ë ¤í•´
  "ì£¼ì°¨ë³„ í•µì‹¬ ëª©í‘œ 1ê°œ + í•  ì¼ 2~3ê°œ + ì‚°ì¶œë¬¼ 1ê°œ"ë¡œ êµ¬ì¡°í™”í•˜ë¼.

ì¶œë ¥ì€ ë°˜ë“œì‹œ ì•„ë˜ JSON ìŠ¤í‚¤ë§ˆë¡œë§Œ ì‘ì„±í•˜ë¼(ë‹¤ë¥¸ ë¬¸ì¥ ê¸ˆì§€).

JSON ìŠ¤í‚¤ë§ˆ:
{{
  "summary_5lines": [string, string, string, string, string],
  "routes": {{
    "A": {{
      "title": "ì•ˆì •",
      "reasons": [string, string, string],
      "actions": [string, string, string, string, string],
      "risks": [string, string]
    }},
    "B": {{
      "title": "ì ì •",
      "reasons": [string, string, string],
      "actions": [string, string, string, string, string],
      "risks": [string, string]
    }},
    "C": {{
      "title": "ë„ì „",
      "reasons": [string, string, string],
      "actions": [string, string, string, string, string],
      "risks": [string, string]
    }}
  }},
  "roadmap": [
    {{
      "week": number,
      "goal": string,
      "tasks": [string, string, string],
      "deliverable": string
    }}
  ],
  "evidence": [
    {{
      "title": string,
      "note": string
    }}
  ]
}}

[ì‚¬ìš©ì ì…ë ¥(JSON)]
{json.dumps(payload_json, ensure_ascii=False)}

[ê·¼ê±° ë¬¸ì„œ]
{json.dumps(context_docs, ensure_ascii=False)}
""".strip()

    body = {
        "model": model,
        "input": [
            {
                "role": "user",
                "content": [{"type": "input_text", "text": prompt}],
            }
        ],
        # Responses API supports JSON object response formats (structured outputs),
        # the model must be instructed to output JSON. (See response format docs)  # cite in write-up, not in code.
        "text": {"format": {"type": "json_object"}},
    }

    r = requests.post(url, headers=headers, json=body, timeout=75)
    r.raise_for_status()
    data = r.json()

    # Collect output text
    text_out = ""
    for out_item in data.get("output", []):
        for c in out_item.get("content", []):
            if c.get("type") in ("output_text", "text") and c.get("text"):
                text_out += c["text"]

    text_out = text_out.strip()
    if not text_out:
        raise ValueError("OpenAI ì‘ë‹µ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

    # Parse JSON robustly
    try:
        return json.loads(text_out)
    except json.JSONDecodeError:
        start = text_out.find("{")
        end = text_out.rfind("}")
        if start != -1 and end != -1 and end > start:
            return json.loads(text_out[start : end + 1])
        raise


# =========================================================
# Rule-based fallback
# =========================================================
def rule_based_plan(payload: Dict[str, Any]) -> Dict[str, Any]:
    route = payload.get("route", "ìˆ˜ì‹œ")
    route_detail = payload.get("route_detail", "")
    major_group = payload.get("major_group", "")
    band = payload.get("band_label", "ì ì •")

    summary = [
        f"í¬ë§ ì „í˜•ì€ '{route}{(' - ' + route_detail) if route_detail else ''}'ì´ë©°, ì…ë ¥ ì¡°ê±´ ê¸°ë°˜ êµ¬ê°„ì€ '{band}'ì…ë‹ˆë‹¤.",
        f"ê´€ì‹¬ ì „ê³µêµ°ì€ '{major_group}'ì´ê³ , ì„±í–¥/ì œì•½ì„ ì „í˜• íŠ¹ì„±ê³¼ ë§¤ì¹­í–ˆìŠµë‹ˆë‹¤.",
        "ë°ì´í„° ì»¤ë²„ë¦¬ì§€ ë‚´ì—ì„œëŠ” ì—°ë„/ì¶œì²˜ ê·¼ê±°ë¥¼ ì œì‹œí•˜ê³ , ë°–ì—ì„œëŠ” ì „ëµ ê°€ì´ë“œ(ì •ì„±)ë¡œ ì „í™˜í•©ë‹ˆë‹¤.",
        "ì¶”ì²œì€ ë‹¨ì •ì´ ì•„ë‹ˆë¼ A/B/C ë¹„êµ êµ¬ì¡°ë¡œ ì œê³µí•©ë‹ˆë‹¤.",
        "8ì£¼ ë¡œë“œë§µì€ ì „í˜•/í˜„ì¬ ë‹¨ê³„ ê¸°ì¤€ìœ¼ë¡œ ì£¼ì°¨ë³„ ëª©í‘œÂ·í•  ì¼Â·ì‚°ì¶œë¬¼ì„ ê³ ì • ì¶œë ¥í•©ë‹ˆë‹¤.",
    ]

    def mk_route(title: str) -> Dict[str, Any]:
        return {
            "title": title,
            "reasons": [
                "ì‚¬ìš©ì ì…ë ¥(ì„±ì /ì„±í–¥/ì œì•½)ê³¼ ì „í˜• íŠ¹ì„±ì˜ ì •í•©ì„±ì„ ê¸°ì¤€ìœ¼ë¡œ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.",
                "ë¶ˆí™•ì‹¤ ìš”ì†ŒëŠ” ë¦¬ìŠ¤í¬ë¡œ ë¶„ë¦¬í•˜ê³  ëŒ€ì•ˆì„ í•¨ê»˜ ì œì‹œí•©ë‹ˆë‹¤.",
                "ì‹¤í–‰ ê°€ëŠ¥ì„±ì„ ë†’ì´ê¸° ìœ„í•´ í•  ì¼ì„ ì•¡ì…˜ ë‹¨ìœ„ë¡œ ìª¼ê°°ìŠµë‹ˆë‹¤.",
            ],
            "actions": [
                "ì „í˜• ìš”ê±´ ì²´í¬ë¦¬ìŠ¤íŠ¸ ì‘ì„±(í•„ìˆ˜/ì„ íƒ ë¶„ë¦¬)",
                "í•µì‹¬ ìŠ¤í† ë¦¬ 3ê°œë¥¼ STARë¡œ ì •ë¦¬(í™œë™-ì—­í• -ì„±ê³¼-ë°°ì›€)",
                "ì§€ì› ì¡°í•© 3ê°œ(A/B/C)ë¡œ ë¶„ì‚° ì„¤ê³„",
                "ì£¼ 1íšŒ í”¼ë“œë°± ë£¨í”„(ì„ ìƒë‹˜/ì„ ë°°/AI)ë¡œ ìˆ˜ì •",
                "ë¦¬ìŠ¤í¬ ëŒ€ë¹„ ëŒ€ì•ˆ ì „í˜• 1ê°œ í™•ë³´",
            ],
            "risks": [
                "ë°ì´í„° ë²”ìœ„ ë°–ì—ì„œëŠ” ìˆ˜ì¹˜ ì˜ˆì¸¡ì„ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
                "ì „í˜•ë³„ ì‚°ì¶œë¬¼/ì¼ì •ì´ ì´‰ë°•í•´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            ],
        }

    routes = {"A": mk_route("ì•ˆì •"), "B": mk_route("ì ì •"), "C": mk_route("ë„ì „")}

    roadmap = []
    for w in range(1, 9):
        if route == "ì •ì‹œ":
            goal = "ì‹¤ì „ ì ìˆ˜ ì•ˆì •í™”" if w <= 3 else ("ì•½ì  ë³´ì™„ ì§‘ì¤‘" if w <= 6 else "ì‹¤ì „ ë£¨í‹´ ê³ ì •")
            tasks = [
                "ê¸°ì¶œ/ëª¨ì˜ 1íšŒë¶„ í’€ì´",
                "ì˜¤ë‹µ ì›ì¸ ë¶„ë¥˜(ê°œë…/ì‹œê°„/ì‹¤ìˆ˜)",
                "ì·¨ì•½ ë‹¨ì› 1ê°œ ë³´ì™„",
            ]
            deliverable = f"Week {w}: ì˜¤ë‹µ ë¶„ë¥˜í‘œ + ì·¨ì•½ ë‹¨ì› ê³„íš"
        else:
            goal = "ì§€ì›ì „ëµ í™•ì •" if w <= 2 else ("ìì†Œì„œ/í™œë™ ì •ë¦¬" if w <= 5 else "ë©´ì ‘/ë…¼ìˆ  ëŒ€ë¹„")
            tasks = [
                "ì „í˜• ìš”ê°• ì²´í¬ + ì œì¶œë¬¼ ëª©ë¡í™”",
                "í™œë™ 3ê°œ STAR ì •ë¦¬",
                "ìì†Œì„œ/ë©´ì ‘ ì§ˆë¬¸ 5ê°œ ì´ˆì•ˆ ì‘ì„±",
            ]
            deliverable = f"Week {w}: {route_detail or 'ìˆ˜ì‹œ'} ì‚°ì¶œë¬¼ 1ì¢… ì´ˆì•ˆ"
        roadmap.append({"week": w, "goal": goal, "tasks": tasks, "deliverable": deliverable})

    evidence = [{"title": "ì¼ë°˜ ì „ëµ ê°€ì´ë“œ", "note": "í‚¤ ë¯¸ì…ë ¥/ë°ì´í„° ë²”ìœ„ ë°– ì‹œ ë£°ë² ì´ìŠ¤ë¡œ ì œê³µ"}]
    return {"summary_5lines": summary, "routes": routes, "roadmap": roadmap, "evidence": evidence}


# =========================================================
# Session State
# =========================================================
if "df_data" not in st.session_state:
    st.session_state.df_data = pd.DataFrame()
if "result" not in st.session_state:
    st.session_state.result = None
if "payload" not in st.session_state:
    st.session_state.payload = None
if "evidence" not in st.session_state:
    st.session_state.evidence = []
if "score_breakdown" not in st.session_state:
    st.session_state.score_breakdown = None
if "abc" not in st.session_state:
    st.session_state.abc = None


# =========================================================
# Header
# =========================================================
st.title("ğŸ§­ Y-Compass (ì™€ì´ì»´í¼ìŠ¤)")
st.caption("ì—°ì„¸ëŒ€ AX ìº í”„ Track 1 â€” ì†Œê·¸ë£¹ ì±Œë¦°ì§€ | ê·¼ê±° ê¸°ë°˜ AI ì§„í•™ ì¹´ìš´ì…€ëŸ¬ (MVP+)")

# =========================================================
# Sidebar
# =========================================================
with st.sidebar:
    st.header("ğŸ”‘ OpenAI (ì„ íƒ)")
    openai_key_default = st.secrets.get("OPENAI_API_KEY", "")
    openai_api_key = st.text_input("OpenAI API Key", value=openai_key_default, type="password", placeholder="sk-...")
    openai_model = st.text_input("ëª¨ë¸", value="gpt-4.1-mini")

    st.divider()
    st.header("âš™ï¸ ì ìˆ˜ ê°€ì¤‘ì¹˜(ì„¤ëª…ê°€ëŠ¥ì„±)")
    st.caption("ì´ì ì€ 0~100. ì œì•½ì€ ê°ì ì´ë©°, ê¸°ì—¬ë„(breakdown)ë¥¼ ê³µê°œí•©ë‹ˆë‹¤.")
    w_acad = st.slider("í•™ì—…(ì„±ì )", 0.0, 1.0, 0.45, 0.05)
    w_extra = st.slider("ë¹„êµê³¼", 0.0, 1.0, 0.25, 0.05)
    w_const = st.slider("ì œì•½(ê°ì )", 0.0, 1.0, 0.20, 0.05)
    w_fit = st.slider("ì „í˜•-ì„±í–¥ ì í•©ë„", 0.0, 1.0, 0.10, 0.05)
    weights = ScoreWeights(w_acad, w_extra, w_const, w_fit)

    st.divider()
    st.header("ğŸ’³ ìƒìš©í™”(í‹°ì–´) ì´ˆì•ˆ")
    tier = st.selectbox("ìš”ê¸ˆì œ(ë°ëª¨)", ["Free", "Basic", "Pro"])
    tier_desc = {
        "Free": "ì§„ë‹¨ + A/B/C ìš”ì•½ + 2ì£¼ ë¯¸ë‹ˆ ì²´í¬ë¦¬ìŠ¤íŠ¸",
        "Basic": "A/B/C ìƒì„¸ + 8ì£¼ ë¡œë“œë§µ + ê·¼ê±° ë³´ê¸°",
        "Pro": "ì „í˜•ë³„ ì‹¬í™”(ìì†Œì„œ/ë©´ì ‘ í¬ì¸íŠ¸) + PDF/ì €ì¥/ë²„ì „ê´€ë¦¬(ì»¨ì…‰)",
    }
    st.write(f"**{tier}**: {tier_desc[tier]}")

    st.divider()
    today = st.date_input("í˜„ì¬ ì‹œì (ë¡œë“œë§µ ê¸°ì¤€)", value=date.today())

tabs = st.tabs(["ğŸ—ƒï¸ ë°ì´í„° ì—…ë¡œë“œ", "ğŸ“ ì§„ë‹¨ ì…ë ¥", "ğŸ“Œ ê²°ê³¼", "ğŸ“ ë¦¬í¬íŠ¸/ê¸°íšì„œ"])

# =========================================================
# Tab 1: Data Upload
# =========================================================
with tabs[0]:
    st.subheader("ğŸ—ƒï¸ ì…ì‹œ ë°ì´í„° ì—…ë¡œë“œ (CSV)")
    st.write("ì—…ë¡œë“œëœ ë°ì´í„°ëŠ” **ê·¼ê±°(ì¶œì²˜/ì—°ë„) + ê°€ëŠ¥ì„± ê·¸ë˜í”„ + ì ìˆ˜ ì‚°ì •(í•™ì—… ë¹„êµ)**ì— ë°˜ì˜ë©ë‹ˆë‹¤.")

    template = (
        "university,major,route,route_detail,year,metric,threshold,source,note\n"
        "ì—°ì„¸ëŒ€,ê²½ì˜í•™ê³¼,ìˆ˜ì‹œ,í•™ìƒë¶€ì¢…í•©,2022,gpa,2.0,ì…í•™ì²˜,ì˜ˆì‹œ\n"
        "ì—°ì„¸ëŒ€,ê²½ì˜í•™ê³¼,ìˆ˜ì‹œ,í•™ìƒë¶€ì¢…í•©,2023,gpa,2.1,ì…í•™ì²˜,ì˜ˆì‹œ\n"
        "ì—°ì„¸ëŒ€,ê²½ì˜í•™ê³¼,ìˆ˜ì‹œ,í•™ìƒë¶€ì¢…í•©,2024,gpa,2.2,ì…í•™ì²˜,ì˜ˆì‹œ\n"
        "ì—°ì„¸ëŒ€,ê²½ì˜í•™ê³¼,ì •ì‹œ,,2024,mock,1.6,ì…í•™ì²˜,ì˜ˆì‹œ\n"
    )

    col_a, col_b = st.columns([1.2, 1.0], gap="large")
    with col_a:
        with st.expander("CSV í…œí”Œë¦¿(ê¶Œì¥ ì»¬ëŸ¼) ë³´ê¸°", expanded=True):
            st.code(template, language="text")

    with col_b:
        st.download_button(
            "â¬‡ï¸ CSV í…œí”Œë¦¿ ë‹¤ìš´ë¡œë“œ",
            data=template.encode("utf-8"),
            file_name="y_compass_admissions_template.csv",
            mime="text/csv",
        )

    uploaded = st.file_uploader("CSV ì—…ë¡œë“œ", type=["csv"])
    if uploaded is not None:
        try:
            df_raw = pd.read_csv(uploaded)
            df = normalize_df(df_raw)
            st.session_state.df_data = df
            st.success(f"ì—…ë¡œë“œ ì„±ê³µ! rows={len(df):,}")
            st.dataframe(df.head(30), use_container_width=True)
        except Exception as e:
            st.error("CSV íŒŒì‹±/ì •ê·œí™” ì‹¤íŒ¨")
            st.caption(str(e))

    if st.session_state.df_data is not None and not st.session_state.df_data.empty:
        st.divider()
        st.markdown("#### ë°ì´í„° ì»¤ë²„ë¦¬ì§€ ì ê²€(ë¹ ë¥¸ í•„í„°)")
        df = st.session_state.df_data
        u = st.selectbox("ëŒ€í•™", sorted(df["university"].unique().tolist()))
        majors = sorted(df[df["university"] == u]["major"].unique().tolist())
        m = st.selectbox("í•™ê³¼", majors)
        r = st.selectbox("ì „í˜•(ìˆ˜ì‹œ/ì •ì‹œ)", ["ìˆ˜ì‹œ", "ì •ì‹œ"])
        rd = ""
        if r == "ìˆ˜ì‹œ":
            rd_list = sorted(
                df[(df["university"] == u) & (df["major"] == m) & (df["route"] == "ìˆ˜ì‹œ")]["route_detail"]
                .fillna("")
                .unique()
                .tolist()
            )
            rd = st.selectbox("ìˆ˜ì‹œ ì„¸ë¶€", rd_list)
        metric = st.selectbox("ê¸°ì¤€ì„  ìœ í˜•(metric)", ["gpa", "mock"])

        matched = match_rows(df, u, m, r, rd, metric)
        st.write(f"ë§¤ì¹­ ê²°ê³¼: {len(matched)} rows")
        st.dataframe(matched, use_container_width=True)

# =========================================================
# Tab 2: Intake
# =========================================================
with tabs[1]:
    st.subheader("ğŸ“ ì§„ë‹¨ ì…ë ¥ (3ë¶„)")
    st.caption("í¬ë§ ì „í˜• ì…ë ¥ â†’ ì„±ì /ì„±í–¥/ì œì•½ ê¸°ë°˜ ì ìˆ˜í™” â†’ ë°ì´í„° ê¸°ë°˜ì´ë©´ ê·¼ê±°/ê·¸ë˜í”„ê¹Œì§€ ìƒì„±")

    df_all = st.session_state.df_data if st.session_state.df_data is not None else pd.DataFrame()
    use_df = not df_all.empty

    with st.form("intake", clear_on_submit=False):
        c1, c2 = st.columns(2, gap="large")

        with c1:
            st.markdown("#### 1) í¬ë§ ì „í˜• ì…ë ¥(í”¼ë“œë°± ë°˜ì˜ í•µì‹¬)")
            grade_status = st.selectbox("í•™ë…„/ìƒíƒœ", ["ê³ 3", "Nìˆ˜(ì¬ìˆ˜/ì‚¼ìˆ˜)", "ê³ 2(ë¯¸ë¦¬ë³´ê¸°)"])
            route = st.selectbox("ìˆ˜ì‹œ/ì •ì‹œ", ADMISSION_ROUTE)
            route_detail = ""
            if route == "ìˆ˜ì‹œ":
                route_detail = st.selectbox("ìˆ˜ì‹œ ì„¸ë¶€ ì „í˜•", SUSI_DETAIL)

            desired_university = st.text_input("í¬ë§ ëŒ€í•™(ê¶Œì¥)", placeholder="ì˜ˆ: ì—°ì„¸ëŒ€")
            desired_major = st.text_input("í¬ë§ í•™ê³¼(ê¶Œì¥)", placeholder="ì˜ˆ: ê²½ì˜í•™ê³¼")
            desired_text = st.text_input("í¬ë§ ì „í˜•/í•™ê³¼/ëŒ€í•™(ììœ  ì…ë ¥)", placeholder="ì˜ˆ: ì—°ì„¸ëŒ€ ê²½ì˜í•™ê³¼ í•™ìƒë¶€ì¢…í•©")

            st.markdown("#### 2) ì„±ì  ì…ë ¥(êµ¬ê°„)")
            gpa_band = st.selectbox("ë‚´ì‹  ë“±ê¸‰", ["ëª¨ë¦„/ì…ë ¥ì•ˆí•¨", "1.x", "2.x", "3.x", "4.x", "5.x", "ì§ì ‘ì…ë ¥"])
            gpa_direct = st.text_input("ë‚´ì‹  ì§ì ‘ ì…ë ¥(ì„ íƒ)", placeholder="ì˜ˆ: 2.3") if gpa_band == "ì§ì ‘ì…ë ¥" else ""
            mock_band = st.selectbox("ëª¨ì˜ê³ ì‚¬ ë“±ê¸‰/í™˜ì‚°", ["ëª¨ë¦„/ì…ë ¥ì•ˆí•¨", "1.x", "2.x", "3.x", "4.x", "5.x", "ì§ì ‘ì…ë ¥"])
            mock_direct = st.text_input("ëª¨ì˜ ì§ì ‘ ì…ë ¥(ì„ íƒ)", placeholder="ì˜ˆ: 2.1") if mock_band == "ì§ì ‘ì…ë ¥" else ""

        with c2:
            st.markdown("#### 3) ì„±í–¥/ë¹„êµê³¼/ì œì•½")
            major_group = st.selectbox("ê´€ì‹¬ ì „ê³µêµ°", MAJOR_GROUPS)
            activity_pref = st.multiselect("ì„ í˜¸ í™œë™/ê°•ì ", ACTIVITY_PREF, default=[ACTIVITY_PREF[0]])
            extracurricular = st.select_slider("ë¹„êµê³¼ ê°•ë„(ìê°€í‰ê°€)", options=EXTRACURRICULAR_LEVELS, value="ë³´í†µ")
            priorities = st.multiselect("ëª©í‘œ ìš°ì„ ìˆœìœ„(ìµœëŒ€ 2)", GOAL_PRIORITY, default=[GOAL_PRIORITY[0], GOAL_PRIORITY[1]])
            constraints = st.multiselect("ì œì•½", CONSTRAINTS, default=[])

            current_stage = st.selectbox("í˜„ì¬ ë‹¨ê³„(ë¡œë“œë§µ ê¸°ì¤€)", CURRENT_STAGE)
            notes = st.text_area("ì¶”ê°€ ë©”ëª¨(ì„ íƒ)", placeholder="ì˜ˆ: ë…¼ìˆ  ë³‘í–‰ / í†µí•™ ì œì•½ / ë©´ì ‘ì´ ë¶ˆì•ˆ")
            st.info("ê°œì¸ì •ë³´(í•™êµ/ì‹¤ëª…/ì—°ë½ì²˜ ë“±) ì…ë ¥ ê¸ˆì§€. ì¶”ì²œì€ ì°¸ê³ ìš©ì…ë‹ˆë‹¤.")

        go = st.form_submit_button("ê²°ê³¼ ìƒì„±", type="primary")

    if go:
        gpa_val = band_to_float(gpa_direct if gpa_band == "ì§ì ‘ì…ë ¥" else gpa_band)
        mock_val = band_to_float(mock_direct if mock_band == "ì§ì ‘ì…ë ¥" else mock_band)

        metric = "mock" if route == "ì •ì‹œ" else "gpa"
        user_metric_value = mock_val if metric == "mock" else gpa_val

        # Allow fallback parsing from free text
        uni = _nonempty(desired_university)
        mj = _nonempty(desired_major)
        if not uni and _nonempty(desired_text):
            uni = _nonempty(desired_text).split()[0]
        if not mj and _nonempty(desired_text):
            # heuristic: second token as major if exists
            toks = _nonempty(desired_text).split()
            if len(toks) >= 2:
                mj = toks[1]

        matched = pd.DataFrame()
        if use_df and uni and mj:
            matched = match_rows(df_all, uni, mj, route, route_detail, metric)

        is_data_based = (matched is not None) and (not matched.empty)

        ref_series = matched.sort_values("year")["threshold"] if is_data_based else None
        acad_s, acad_msg, anchor = academics_score(user_metric_value, ref_series)

        extra_s = extracurricular_score(extracurricular)
        penalty = constraints_penalty(constraints)
        fit_s = preference_fit_score(activity_pref, route, route_detail)

        tot, breakdown = total_score(weights, acad_s, extra_s, penalty, fit_s)
        band = score_to_band(tot)
        abc = abc_scores(tot, constraints, priorities[:2])

        payload = {
            "today": str(today),
            "grade_status": grade_status,
            "route": route,
            "route_detail": route_detail,
            "desired_university": uni,
            "desired_major": mj,
            "desired_text": desired_text,
            "major_group": major_group,
            "gpa_value": gpa_val,
            "mock_value": mock_val,
            "metric_used": metric,
            "metric_value": user_metric_value,
            "activity_pref": activity_pref,
            "extracurricular_level": extracurricular,
            "priorities": priorities[:2],
            "constraints": constraints,
            "current_stage": current_stage,
            "notes": notes,
            "band_label": band,
            "coverage_is_data": is_data_based,
            "score_total": float(tot),
            "score_breakdown": breakdown,
            "abc_scores": abc,
            "scoring_notes": {
                "academics": acad_msg,
                "fit": "ì „í˜•-ì„±í–¥ ì í•©ë„ëŠ” ì„ íƒ ì„±í–¥ê³¼ ì „í˜• íŠ¹ì„± ë§¤ì¹­ìœ¼ë¡œ ì‚°ì¶œí–ˆìŠµë‹ˆë‹¤.",
                "constraints": "ì œì•½ì€ ê°ì ìœ¼ë¡œ ì ìš©ë˜ë©°(ê°€ì¤‘ì¹˜ ë°˜ì˜), ë§ì„ìˆ˜ë¡ ë¦¬ìŠ¤í¬ê°€ ì»¤ì§‘ë‹ˆë‹¤.",
            },
            "data_anchor_threshold": anchor,
        }

        st.session_state.payload = payload
        st.session_state.score_breakdown = breakdown
        st.session_state.abc = abc

        # Evidence docs (RAG context)
        evidence_docs: List[Dict[str, str]] = []
        if is_data_based:
            tail = matched.sort_values("year").tail(12)
            for _, row in tail.iterrows():
                title = f"{row['university']} {row['major']} | {row['route']}{(' - ' + row['route_detail']) if row['route_detail'] else ''} | {int(row['year'])}"
                note = (
                    f"metric={row['metric']} threshold={row['threshold']} | "
                    f"source={row.get('source','')} | note={row.get('note','')}"
                )
                evidence_docs.append({"title": title, "note": note})
        else:
            evidence_docs.append(
                {
                    "title": "ë°ì´í„° ë¯¸ë³´ìœ (ê°€ì´ë“œ ê¸°ë°˜)",
                    "note": "í•´ë‹¹ ëŒ€í•™/í•™ê³¼/ì „í˜•ì˜ ì—…ë¡œë“œ ë°ì´í„°ê°€ ì—†ì–´ ìˆ˜ì¹˜ ê¸°ë°˜ ì˜ˆì¸¡ì„ ì œê³µí•˜ì§€ ì•Šê³ , ì „í˜• íŠ¹ì„± ê¸°ë°˜ ì „ëµ ê°€ì´ë“œë¡œ ì•ˆë‚´í•©ë‹ˆë‹¤.",
                }
            )

        st.session_state.evidence = evidence_docs

        # Generate plan
        with st.spinner("A/B/C ì¶”ì²œ + 8ì£¼ ë¡œë“œë§µ ìƒì„± ì¤‘..."):
            try:
                if _nonempty(openai_api_key):
                    plan = openai_generate_plan(
                        api_key=openai_api_key.strip(),
                        model=openai_model.strip(),
                        payload_json=payload,
                        context_docs=evidence_docs,
                    )
                else:
                    plan = rule_based_plan(payload)

                plan["_meta"] = {
                    "coverage_is_data": is_data_based,
                    "score_total": payload["score_total"],
                    "score_breakdown": payload["score_breakdown"],
                    "abc_scores": payload["abc_scores"],
                    "academics_msg": acad_msg,
                }

                st.session_state.result = plan
                st.success("ì™„ë£Œ! 'ğŸ“Œ ê²°ê³¼' íƒ­ì—ì„œ í™•ì¸í•´ì¤˜.")
            except Exception as e:
                st.session_state.result = None
                st.error("ìƒì„± ì‹¤íŒ¨(í‚¤/ëª¨ë¸/ë„¤íŠ¸ì›Œí¬/JSON í˜•ì‹) í™•ì¸")
                st.caption(str(e))

# =========================================================
# Charts (Altair helpers)
# =========================================================
def chart_threshold_vs_user(chart_df: pd.DataFrame) -> alt.Chart:
    """
    chart_df: columns = ['year','threshold','user_value']
    Lower is better -> reverse Y axis.
    """
    base = alt.Chart(chart_df).encode(
        x=alt.X("year:O", title="ì—°ë„"),
        y=alt.Y("value:Q", title="ë“±ê¸‰(ë‚®ì„ìˆ˜ë¡ ìœ ë¦¬)", scale=alt.Scale(reverse=True)),
        color=alt.Color("series:N", title=""),
        tooltip=[
            alt.Tooltip("year:O", title="ì—°ë„"),
            alt.Tooltip("series:N", title="í•­ëª©"),
            alt.Tooltip("value:Q", title="ê°’", format=".2f"),
        ],
    )

    long_df = chart_df.melt(id_vars=["year"], value_vars=["threshold", "user_value"], var_name="series", value_name="value")
    long_df["series"] = long_df["series"].replace({"threshold": "ê¸°ì¤€ì„ (threshold)", "user_value": "ë‚´ ì„±ì (user)"})

    line = base.mark_line(point=True).transform_lookup(
        lookup="year",
        from_=alt.LookupData(long_df, "year", ["series", "value"]),
    )

    # transform_lookup + base encodes series/value, but lookup duplicates; simpler:
    line = alt.Chart(long_df).mark_line(point=True).encode(
        x=alt.X("year:O", title="ì—°ë„"),
        y=alt.Y("value:Q", title="ë“±ê¸‰(ë‚®ì„ìˆ˜ë¡ ìœ ë¦¬)", scale=alt.Scale(reverse=True)),
        color=alt.Color("series:N", title=""),
        tooltip=[
            alt.Tooltip("year:O", title="ì—°ë„"),
            alt.Tooltip("series:N", title="í•­ëª©"),
            alt.Tooltip("value:Q", title="ê°’", format=".2f"),
        ],
    )

    return line.properties(height=260)


def chart_breakdown(breakdown: Dict[str, float]) -> alt.Chart:
    keys = ["í•™ì—…(ì„±ì )", "ë¹„êµê³¼", "ì í•©ë„(ì„±í–¥â†”ì „í˜•)", "ì œì•½(ê°ì )"]
    rows = [{"ìš”ì†Œ": k, "ê¸°ì—¬ë„": float(breakdown.get(k, 0.0))} for k in keys]
    df = pd.DataFrame(rows)

    return (
        alt.Chart(df)
        .mark_bar()
        .encode(
            x=alt.X("ê¸°ì—¬ë„:Q", title="ê¸°ì—¬ë„(ê°€ì¤‘ì¹˜ ë°˜ì˜)"),
            y=alt.Y("ìš”ì†Œ:N", title=""),
            tooltip=[alt.Tooltip("ìš”ì†Œ:N"), alt.Tooltip("ê¸°ì—¬ë„:Q", format=".2f")],
        )
        .properties(height=220)
    )


def chart_abc_scores(abc: Dict[str, Dict[str, Any]]) -> alt.Chart:
    df = pd.DataFrame(
        [
            {"ê²½ë¡œ": "A(ì•ˆì •)", "ì ìˆ˜": abc["A"]["score"], "êµ¬ê°„": abc["A"]["band"]},
            {"ê²½ë¡œ": "B(ì ì •)", "ì ìˆ˜": abc["B"]["score"], "êµ¬ê°„": abc["B"]["band"]},
            {"ê²½ë¡œ": "C(ë„ì „)", "ì ìˆ˜": abc["C"]["score"], "êµ¬ê°„": abc["C"]["band"]},
        ]
    )
    return (
        alt.Chart(df)
        .mark_bar()
        .encode(
            x=alt.X("ê²½ë¡œ:N", title="ê²½ë¡œ(A/B/C)"),
            y=alt.Y("ì ìˆ˜:Q", title="ì ìˆ˜(0~100)", scale=alt.Scale(domain=[0, 100])),
            tooltip=[alt.Tooltip("ê²½ë¡œ:N"), alt.Tooltip("ì ìˆ˜:Q", format=".1f"), alt.Tooltip("êµ¬ê°„:N")],
        )
        .properties(height=260)
    )

# =========================================================
# Tab 3: Results
# =========================================================
with tabs[2]:
    st.subheader("ğŸ“Œ ê²°ê³¼")

    if st.session_state.result is None or st.session_state.payload is None:
        st.info("ë¨¼ì € 'ğŸ“ ì§„ë‹¨ ì…ë ¥'ì—ì„œ ê²°ê³¼ë¥¼ ìƒì„±í•´ì¤˜.")
    else:
        payload = st.session_state.payload
        plan = st.session_state.result
        meta = plan.get("_meta", {})

        # --- Section 1
        st.markdown("## ì„¹ì…˜ 1 â€” ë‚´ê°€ ì›í•˜ëŠ” ì „í˜• ê°€ëŠ¥ì„± ì¹´ë“œ")

        col1, col2, col3 = st.columns([1.2, 1.2, 2.4], gap="large")

        with col1:
            with st.container(border=True):
                st.markdown('<div class="card-title">ì»¤ë²„ë¦¬ì§€</div>', unsafe_allow_html=True)
                st.markdown(coverage_badge_html(payload["coverage_is_data"]), unsafe_allow_html=True)
                st.markdown('<div class="small">ë°ì´í„° ê¸°ë°˜ì´ë©´ ì—°ë„/ì¶œì²˜ ê·¼ê±° ë° ê·¸ë˜í”„ ì œê³µ</div>', unsafe_allow_html=True)

        with col2:
            with st.container(border=True):
                st.markdown('<div class="card-title">ê°€ëŠ¥ì„± êµ¬ê°„(ì•ˆì •/ì ì •/ë„ì „)</div>', unsafe_allow_html=True)
                st.markdown(band_badge_html(payload["band_label"]), unsafe_allow_html=True)
                st.metric("ì´ì (0~100)", f"{payload['score_total']:.1f}", help="ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì„¤ëª…ê°€ëŠ¥ ì ìˆ˜")
                if payload.get("metric_value") is None:
                    st.caption("ì„±ì  ë¯¸ì…ë ¥ â†’ í•™ì—… ì ìˆ˜ëŠ” ì¤‘ë¦½ ì²˜ë¦¬")
                else:
                    st.caption(f"ì‚¬ìš© ì§€í‘œ: {payload['metric_used']} | ì…ë ¥ê°’: {payload['metric_value']:.2f}")

        with col3:
            with st.container(border=True):
                st.markdown('<div class="card-title">ì™œ ì´ êµ¬ê°„ì¸ê°€? (ì„¤ëª…ê°€ëŠ¥ ì ìˆ˜í™”)</div>', unsafe_allow_html=True)
                st.write(meta.get("academics_msg", ""))

                bd = payload["score_breakdown"]
                st.altair_chart(chart_breakdown(bd), use_container_width=True)

        st.divider()

        # --- Mini chart & table when data-based
        df_all = st.session_state.df_data if st.session_state.df_data is not None else pd.DataFrame()
        if payload["coverage_is_data"] and not df_all.empty:
            st.markdown("### ê·¼ê±° ì‹œê°í™”(ì—°ë„ë³„ ê¸°ì¤€ì„  vs ë‚´ ì„±ì )")
            metric = payload["metric_used"]
            uni = payload.get("desired_university", "")
            mj = payload.get("desired_major", "")
            route = payload.get("route", "ìˆ˜ì‹œ")
            rd = payload.get("route_detail", "")

            matched = match_rows(df_all, uni, mj, route, rd, metric)
            if matched is not None and not matched.empty and payload.get("metric_value") is not None:
                chart_df = matched.sort_values("year")[["year", "threshold"]].copy()
                chart_df["user_value"] = float(payload["metric_value"])

                st.dataframe(chart_df, use_container_width=True)

                st.altair_chart(chart_threshold_vs_user(chart_df), use_container_width=True)
                st.caption("â€» ë“±ê¸‰ ê¸°ì¤€: **ë‚®ì„ìˆ˜ë¡ ìœ ë¦¬**. (ê·¸ë˜í”„ëŠ” ì°¸ê³ ìš©ì´ë©°, ë‹¨ì •ì  í•©ê²© ì˜ˆì¸¡ì´ ì•„ë‹˜)")
            elif matched is not None and not matched.empty:
                st.info("ë§¤ì¹­ ë°ì´í„°ëŠ” ìˆìœ¼ë‚˜, ì„±ì  ì…ë ¥ì´ ì—†ì–´ ë¹„êµ ê·¸ë˜í”„ë¥¼ ë§Œë“¤ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.info("ì‹œê°í™”í•  ë§¤ì¹­ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤(í•™ê³¼ëª…/ì „í˜• í‚¤ì›Œë“œ í™•ì¸).")
        else:
            st.markdown("### ê·¼ê±° ì‹œê°í™”")
            st.info("í˜„ì¬ëŠ” **ê°€ì´ë“œ ê¸°ë°˜**ì´ê±°ë‚˜(ë°ì´í„° ë¯¸ë³´ìœ ), ë°ì´í„° ì—…ë¡œë“œê°€ ì—†ì–´ ê·¸ë˜í”„ë¥¼ í‘œì‹œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        st.divider()

        # --- A/B/C Score Chart (ìš”êµ¬ì‚¬í•­ 3)
        st.markdown("## ì„¹ì…˜ 2 â€” A/B/C ì¶”ì²œ ì ìˆ˜í™”(ì„¤ëª…ê°€ëŠ¥ì„± ê°•í™”)")
        abc = payload.get("abc_scores") or {}
        if abc:
            st.altair_chart(chart_abc_scores(abc), use_container_width=True)
            st.caption("A/B/C ì ìˆ˜ëŠ” **ì´ì (ê¸°ë³¸ ì í•©ë„)**ë¥¼ ê¸°ì¤€ìœ¼ë¡œ, ì œì•½/ëª©í‘œ ìš°ì„ ìˆœìœ„ë¥¼ ë°˜ì˜í•´ *ê²½ë¡œ ë‚œì´ë„*ë¥¼ ì¡°ì •í•´ ì‚°ì¶œí•©ë‹ˆë‹¤.")
        else:
            st.warning("A/B/C ì ìˆ˜í™” ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

        st.divider()

        # --- A/B/C cards
        st.markdown("## ì„¹ì…˜ 3 â€” AI ì¶”ì²œ ì „í˜•/ì „ëµ TOP3 (A/B/C)")
        routes = plan.get("routes", {})
        cols = st.columns(3, gap="large")
        keys = ["A", "B", "C"]
        title_map = {"A": "A: ì•ˆì •", "B": "B: ì ì •", "C": "C: ë„ì „"}

        for i, k in enumerate(keys):
            r = routes.get(k, {})
            with cols[i]:
                with st.container(border=True):
                    st.markdown(f"### {title_map[k]}")
                    if abc and k in abc:
                        st.caption(f"ì ìˆ˜: {abc[k]['score']:.1f} / 100 Â· êµ¬ê°„: {abc[k]['band']}")
                    else:
                        st.caption(r.get("title", ""))

                    st.markdown("**ì¶”ì²œ ì´ìœ (3)**")
                    for x in (r.get("reasons") or [])[:3]:
                        st.write(f"- {x}")

                    st.markdown("**ì¤€ë¹„ ì•¡ì…˜(5)**")
                    for x in (r.get("actions") or [])[:5]:
                        st.write(f"- {x}")

                    st.markdown("**ë¦¬ìŠ¤í¬/ê°€ì •(2)**")
                    for x in (r.get("risks") or [])[:2]:
                        st.write(f"- {x}")

        st.divider()

        # --- 8-week Roadmap
        st.markdown("## ì„¹ì…˜ 4 â€” 8ì£¼ ë¡œë“œë§µ")
        roadmap = plan.get("roadmap", [])
        if not roadmap:
            st.warning("ë¡œë“œë§µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        else:
            for item in roadmap[:8]:
                w = item.get("week")
                with st.expander(f"Week {w} â€” {item.get('goal','')}", expanded=(w == 1)):
                    st.markdown("**í•  ì¼(2~3)**")
                    for t in (item.get("tasks") or [])[:3]:
                        st.write(f"- {t}")
                    st.markdown("**ì‚°ì¶œë¬¼**")
                    st.write(item.get("deliverable", ""))

        st.divider()

        # --- Evidence
        st.markdown("### ê·¼ê±° ë³´ê¸°(ì¶œì²˜)")
        evs = plan.get("evidence", []) or st.session_state.evidence or []
        if evs:
            for ev in evs[:15]:
                with st.expander(ev.get("title", "ê·¼ê±°")):
                    st.write(ev.get("note", ""))
        else:
            st.caption("í‘œì‹œí•  ê·¼ê±°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        st.divider()

        # --- Download
        st.markdown("### ê²°ê³¼ ì €ì¥(ì œì¶œ/ì‹œì—°ìš©)")
        report = {
            "payload": payload,
            "summary_5lines": plan.get("summary_5lines", []),
            "routes": plan.get("routes", {}),
            "roadmap": plan.get("roadmap", []),
            "evidence": plan.get("evidence", []),
            "meta": plan.get("_meta", {}),
        }
        st.download_button(
            "ğŸ“„ ê²°ê³¼ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ (.json)",
            data=json.dumps(report, ensure_ascii=False, indent=2),
            file_name="y_compass_report.json",
            mime="application/json",
        )

# =========================================================
# Tab 4: Report / Spec
# =========================================================
with tabs[3]:
    st.subheader("ğŸ“ ê¸°íšì„œ/ë¦¬í¬íŠ¸ (Report Ver.)")

    st.markdown(
        """
## 1. ê°œìš”
**ì•± ì´ë¦„:** Y-Compass(ì™€ì´ì»´í¼ìŠ¤) â€” Y(ì—°ì„¸ëŒ€ ë…¸í•˜ìš°) + Compass(ë°©í–¥ ì¡ê¸°)  
**ì•± í•œì¤„ ì„¤ëª…:** â€œëŒ€í•™ ì§„í•™ì´ ë§‰ë§‰í•œ 10ëŒ€ì—ê²Œ, ê·¼ê±° ê¸°ë°˜ ì „í˜•/ì „ê³µ í›„ë³´ 3ê°œ(A/B/C)ì™€ 8ì£¼ ì¤€ë¹„ ë¡œë“œë§µì„ ì œê³µí•˜ëŠ” AI ì§„í•™ ì¹´ìš´ì…€ëŸ¬â€

### Problem Statement
- **ì •ë³´ ê³¼ì‰/ë¶„ì‚°:** ì „í˜•Â·ì „ê³µ ì •ë³´ê°€ í©ì–´ì ¸ ìˆì–´ ë¬´ì—‡ë¶€í„° í™•ì¸í•´ì•¼ í• ì§€ ì–´ë ¤ì›€  
- **ë¹„ìš©/ì ‘ê·¼ì„±:** ì „ë¬¸ ì»¨ì„¤íŒ…ì€ ë¹„ìš© ë¶€ë‹´ì´ í¬ê³  ì§€ì—­Â·ì‹œê°„ ì œì•½ìœ¼ë¡œ ì ‘ê·¼ì„±ì´ ë‚®ìŒ  
- **ì‹ ë¢°ì„± ë¶€ì¡±:** ê²½í—˜ë‹´ ì¤‘ì‹¬ ì¡°ì–¸ì´ ë§ì•„ ê·¼ê±°Â·ì¶œì²˜ê°€ ë¶ˆíˆ¬ëª…

**í•´ê²° ì „ëµ:** ì§§ì€ ì…ë ¥ â†’ ê·¼ê±° ê¸°ë°˜ ì¶”ì²œ(ì¶œì²˜ ì œì‹œ) â†’ ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ë¡œë“œë§µ
"""
    )

    st.markdown("## 2. í•µì‹¬ ê¸°ëŠ¥(3)")
    st.markdown(
        """
1) **8ë¬¸í•­ ì§„í•™ ìƒí™© ìŠ¤ìº”(Intake & Profiling)**: ìƒí™© ìš”ì•½ 5ì¤„ + ê°•ì /ì œì•½ íƒœê·¸  
2) **ê·¼ê±° ê¸°ë°˜ í›„ë³´ 3ê°œ ì¶”ì²œ(A/B/C)**: ì¶”ì²œ ì´ìœ /ì•¡ì…˜/ë¦¬ìŠ¤í¬ + ê·¼ê±°(ì¶œì²˜)  
3) **8ì£¼ ë¡œë“œë§µ**: ì „í˜•+ì‹œì  ë°˜ì˜, ì£¼ì°¨ë³„ ëª©í‘œ1 + í•  ì¼2~3 + ì‚°ì¶œë¬¼1
"""
    )

    st.markdown("## 3. Technical Spec (í”¼ë“œë°± ë°˜ì˜)")
    st.table(
        [
            {
                "êµ¬ë¶„": "Input Data",
                "ìƒì„¸ ì •ì˜": "ì‚¬ìš©ì í¬ë§ ì „í˜•(ì§ì ‘ ì„ íƒ/ì…ë ¥) + ìˆ˜ì‹œ/ì •ì‹œ ëŒ€ë¶„ë¥˜ + ìˆ˜ì‹œ ì„¸ë¶€ ì „í˜• ë¶„ê¸° + ì„±ì (ë‚´ì‹ /ëª¨ì˜ êµ¬ê°„) + (ì„ íƒ)ëŒ€í•™/í•™ê³¼ í‚¤",
            },
            {
                "êµ¬ë¶„": "AI Prompting",
                "ìƒì„¸ ì •ì˜": "ì „í˜• ì¡´ì¤‘ + ê°€ëŠ¥ì„±/ë¦¬ìŠ¤í¬/ëŒ€ì•ˆ ì œì‹œ. ê³¼ê±° ì…ì‹œ ê²°ê³¼ëŠ” ì—°ë„/ë²”ìœ„/í•œê³„ ëª…ì‹œ, í™•ë¥  ë‹¨ì • ê¸ˆì§€(ì•ˆì •/ì ì •/ë„ì „). ë°ì´í„° ì—†ëŠ” ê²½ìš° ìˆ˜ì¹˜ ì˜ˆì¸¡ ê¸ˆì§€â†’ì „í˜• íŠ¹ì„± ê¸°ë°˜ ê°€ì´ë“œ.",
            },
            {
                "êµ¬ë¶„": "Output Format",
                "ìƒì„¸ ì •ì˜": "ì„¹ì…˜1: ê°€ëŠ¥ì„± ì¹´ë“œ(ì»¤ë²„ë¦¬ì§€ ë°°ì§€+ì ìˆ˜ breakdown) / ì„¹ì…˜2: A/B/C ì ìˆ˜í™” ì°¨íŠ¸ / ì„¹ì…˜3: A/B/C ì¹´ë“œ / ì„¹ì…˜4: 8ì£¼ ë¡œë“œë§µ + ê·¼ê±°(expander)",
            },
        ]
    )

    st.markdown("## 4. ìƒìš©í™” í‹°ì–´(ì´ˆì•ˆ)")
    st.table(
        [
            {"Tier": "Free", "ì œê³µ": "ì§„ë‹¨ + A/B/C ìš”ì•½ + 2ì£¼ ë¯¸ë‹ˆ ì²´í¬ë¦¬ìŠ¤íŠ¸"},
            {"Tier": "Basic", "ì œê³µ": "A/B/C ìƒì„¸ + 8ì£¼ ë¡œë“œë§µ + ê·¼ê±° ë³´ê¸°"},
            {"Tier": "Pro", "ì œê³µ": "ì „í˜•ë³„ ì‹¬í™”(ìì†Œì„œ/ë©´ì ‘ í¬ì¸íŠ¸) + ë¦¬í¬íŠ¸/PDF + ì €ì¥/ë²„ì „ê´€ë¦¬(ì»¨ì…‰)"},
        ]
    )

    st.markdown("## 5. KPI(ì˜ˆì‹œ 3ê°œ)")
    st.markdown(
        """
- **Time-to-Plan**: ì…ë ¥ ì‹œì‘â†’8ì£¼ í”Œëœ ìƒì„±ê¹Œì§€ ê±¸ë¦° ì‹œê°„(ë¶„)  
- **Plan Save Rate**: ê²°ê³¼ ì €ì¥/ë‹¤ìš´ë¡œë“œ ë¹„ìœ¨(%)  
- **Perceived Trust**: â€œê·¼ê±°(ì¶œì²˜) ì œì‹œê°€ ë„ì›€ì´ ëë‹¤â€ ë§Œì¡±ë„(5ì  ì²™ë„)
"""
    )

st.caption("â€» ë³¸ ì•±ì€ ì°¸ê³ ìš© ì»¨ì„¤íŒ… ë„êµ¬ì´ë©°, í™•ë¥  ë‹¨ì •/í•©ê²© ë³´ì¥ì€ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
