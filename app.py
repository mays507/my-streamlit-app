"""
Y-Compass (ì™€ì´ì»´í¼ìŠ¤) â€” Streamlit MVP+ (ì‹¬ì‚¬ì ì„¤ë“ë ¥ ê°•í™” ë²„ì „)

í•µì‹¬ ê³ ë„í™”(ìš”êµ¬ì‚¬í•­ ë°˜ì˜)
1) CSV ì—…ë¡œë“œ ê¸°ë°˜ ë°ì´í„° ì»¤ë²„ë¦¬ì§€ í™•ì¥:
   - ëŒ€í•™/í•™ê³¼/ì „í˜•/ì—°ë„/ê¸°ì¤€ì„ (ë‚´ì‹ /ëª¨ì˜) ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ë©´
   - ìë™ìœ¼ë¡œ ê·¼ê±° ì»¨í…ìŠ¤íŠ¸(evidence) ìƒì„± + ê°€ëŠ¥ì„± ì¹´ë“œ/ê·¸ë˜í”„ì— ë°˜ì˜

2) "ë°ì´í„° ê¸°ë°˜"ì¼ ë•Œ ì—°ë„ë³„ ë¯¸ë‹ˆ í‘œ/ê·¸ë˜í”„ ì‹œê°í™”:
   - ì‚¬ìš©ì ì„±ì (ë‚´ì‹ /ëª¨ì˜) vs ì—°ë„ë³„ ê¸°ì¤€ì„ (ì—…ë¡œë“œ ë°ì´í„°)
   - ë°ì´í„° ë²”ìœ„ ë°–ì´ë©´ "ê°€ì´ë“œ ê¸°ë°˜"ìœ¼ë¡œ ì „í™˜

3) A/B/C ì¶”ì²œì˜ "ì„¤ëª…ê°€ëŠ¥ì„±" ê°•í™”:
   - ì„±ì /ë¹„êµê³¼/ì œì•½/ëª©í‘œ ìš°ì„ ìˆœìœ„ë¥¼ ê°€ì¤‘ì¹˜ ì ìˆ˜ë¡œ ì‚°ì¶œ
   - ì•ˆì •/ì ì •/ë„ì „ êµ¬ê°„ + ì ìˆ˜ ê·¼ê±°(ê¸°ì—¬ë„ breakdown) í‘œì‹œ

OpenAI API(ì„ íƒ):
- í‚¤ê°€ ìˆìœ¼ë©´ Responses APIë¡œ A/B/C + 8ì£¼ ë¡œë“œë§µ ìƒì„±(ê·¼ê±° ë¬¸ì„œ ê¸°ë°˜)
- í‚¤ê°€ ì—†ìœ¼ë©´ rule-basedë¡œ ë™ì‘(ë°ëª¨ ê°€ëŠ¥)

CSV í…œí”Œë¦¿(ê¶Œì¥ ì»¬ëŸ¼)
- university (ì˜ˆ: ì—°ì„¸ëŒ€)
- major (ì˜ˆ: ê²½ì˜í•™ê³¼)
- route (ìˆ˜ì‹œ/ì •ì‹œ)
- route_detail (ìˆ˜ì‹œì¼ ë•Œ: í•™ìƒë¶€êµê³¼/í•™ìƒë¶€ì¢…í•©/ë…¼ìˆ /íŠ¹ê¸°ì ë“±, ì •ì‹œëŠ” ë¹„ì›Œë„ ë¨)
- year (ì˜ˆ: 2022)
- metric (gpa ë˜ëŠ” mock)  # ê¸°ì¤€ì„  ìœ í˜•: ë‚´ì‹ (gpa) / ëª¨ì˜(mock)
- threshold (ì˜ˆ: 1.7)     # ê¸°ì¤€ì„ (ë‚®ì„ìˆ˜ë¡ ì¢‹ë‹¤ê³  ê°€ì •: ë“±ê¸‰)
- source (ì˜ˆ: ëŒ€í•™ì•Œë¦¬ë¯¸/ì…í•™ì²˜)
- note (ì„ íƒ)

âš ï¸ ì´ ì•±ì€ "í™•ë¥  ë‹¨ì •" ê¸ˆì§€. ì•ˆì •/ì ì •/ë„ì „ êµ¬ê°„ìœ¼ë¡œë§Œ í‘œí˜„.
"""

from __future__ import annotations

import json
from dataclasses import dataclass
from datetime import date
from typing import Any, Dict, List, Optional, Tuple

import pandas as pd
import requests
import streamlit as st


# =========================================================
# Page Config
# =========================================================
st.set_page_config(page_title="ğŸ§­ Y-Compass", page_icon="ğŸ§­", layout="wide")


# =========================================================
# Options
# =========================================================
ADMISSION_ROUTE = ["ìˆ˜ì‹œ", "ì •ì‹œ"]
SUSI_DETAIL = ["í•™ìƒë¶€êµê³¼", "í•™ìƒë¶€ì¢…í•©", "ë…¼ìˆ ", "íŠ¹ê¸°ì(í•´ë‹¹ ì‹œ)"]
MAJOR_GROUPS = ["ì¸ë¬¸", "ì‚¬íšŒ", "ìƒê²½", "ìì—°", "ê³µí•™", "ì˜ˆì²´ëŠ¥", "ìœµí•©/ììœ ì „ê³µ"]
ACTIVITY_PREF = ["ì‚¬ëŒ(ì†Œí†µ/ë¦¬ë”ì‹­)", "ë°ì´í„°(ë¶„ì„/ì •ëŸ‰)", "ê¸€(ì—ì„¸ì´/ìŠ¤í† ë¦¬)", "í˜„ì¥(í™œë™/í”„ë¡œì íŠ¸)"]
GOAL_PRIORITY = ["í•©ê²© ì•ˆì •ì„±", "ì ì„±/í¥ë¯¸", "ì·¨ì—…/ì§„ë¡œ ì—°ê³„", "ì¥í•™/ë¹„ìš©", "ì§€ì—­/ìƒí™œí™˜ê²½"]
CONSTRAINTS = ["ì§€ì—­(í†µí•™/ê±°ì£¼)", "ì˜ˆì‚°(ë¹„ìš©)", "ì‹œê°„(ë³‘í–‰ ì¼ì •)", "ê°€ì¡±/ëŒë´„", "ê¸°íƒ€"]
CURRENT_STAGE = ["ë‚´ì‹ /ìˆ˜ëŠ¥ ì¤€ë¹„", "ìê¸°ì†Œê°œì„œ/í•™ìƒë¶€ ì •ë¦¬", "ë©´ì ‘ ì¤€ë¹„", "ë…¼ìˆ  ì¤€ë¹„", "ì§€ì›ì „ëµ ìµœì¢… ì ê²€"]

EXTRACURRICULAR_LEVELS = ["ë‚®ìŒ", "ë³´í†µ", "ë†’ìŒ"]


# =========================================================
# Utilities
# =========================================================
def _nonempty(s: Optional[str]) -> str:
    return s.strip() if isinstance(s, str) and s.strip() else ""


def band_to_float(band: str) -> Optional[float]:
    """
    Convert UI band string to float-ish threshold.
    - "1.x" -> 1.5
    - "2.x" -> 2.5
    - "ì§ì ‘ì…ë ¥(ì˜ˆ: 2.3)" -> parse as float
    - "ëª¨ë¦„/ì…ë ¥ì•ˆí•¨" -> None
    """
    band = _nonempty(band)
    if not band or "ëª¨ë¦„" in band:
        return None
    if band.endswith(".x"):
        try:
            return float(band.replace(".x", "")) + 0.5
        except Exception:
            return None
    try:
        return float(band)
    except Exception:
        return None


def coverage_badge(is_data_based: bool) -> str:
    return "ë°ì´í„° ê¸°ë°˜ âœ…" if is_data_based else "ê°€ì´ë“œ ê¸°ë°˜ ğŸŸ¡"


def safe_int(x: Any) -> Optional[int]:
    try:
        return int(x)
    except Exception:
        return None


def safe_float(x: Any) -> Optional[float]:
    try:
        v = float(x)
        if pd.isna(v):
            return None
        return v
    except Exception:
        return None


# =========================================================
# Data Handling: CSV -> normalized dataframe
# =========================================================
REQUIRED_COLS = ["university", "major", "route", "year", "metric", "threshold"]
OPTIONAL_COLS = ["route_detail", "source", "note"]


def normalize_df(df: pd.DataFrame) -> pd.DataFrame:
    # lower columns
    df = df.copy()
    df.columns = [c.strip().lower() for c in df.columns]

    missing = [c for c in REQUIRED_COLS if c not in df.columns]
    if missing:
        raise ValueError(f"CSVì— í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë¨: {missing}")

    # ensure optionals exist
    for c in OPTIONAL_COLS:
        if c not in df.columns:
            df[c] = ""

    # normalize values
    df["university"] = df["university"].astype(str).str.strip()
    df["major"] = df["major"].astype(str).str.strip()
    df["route"] = df["route"].astype(str).str.strip()
    df["route_detail"] = df["route_detail"].astype(str).str.strip()
    df["metric"] = df["metric"].astype(str).str.strip().str.lower()

    df["year"] = df["year"].apply(safe_int)
    df["threshold"] = df["threshold"].apply(safe_float)

    df = df.dropna(subset=["year", "threshold"])
    df = df[df["metric"].isin(["gpa", "mock"])]

    # Clean route: accept variations
    df["route"] = df["route"].replace({"ìˆ˜ì‹œ ": "ìˆ˜ì‹œ", "ì •ì‹œ ": "ì •ì‹œ"})
    df = df[df["route"].isin(["ìˆ˜ì‹œ", "ì •ì‹œ"])]

    return df


def match_rows(
    df: pd.DataFrame,
    university: str,
    major_text: str,
    route: str,
    route_detail: str,
    metric: str,
    max_rows: int = 50,
) -> pd.DataFrame:
    """
    fuzzy-ish match:
    - exact university equals
    - major substring match (either direction)
    - route match
    - for susi: route_detail matches if provided in df; if df route_detail empty, allow fallback
    """
    if df is None or df.empty:
        return df

    uni = _nonempty(university)
    mj = _nonempty(major_text)

    sub = df[df["university"] == uni]
    if mj:
        sub = sub[
            sub["major"].apply(lambda x: (mj in str(x)) or (str(x) in mj))
        ]

    sub = sub[sub["route"] == route]
    sub = sub[sub["metric"] == metric]

    if route == "ìˆ˜ì‹œ":
        rd = _nonempty(route_detail)
        if rd:
            # prioritize exact route_detail matches, but allow blank route_detail as generic susi row
            exact = sub[sub["route_detail"] == rd]
            generic = sub[sub["route_detail"] == ""]
            sub = pd.concat([exact, generic], ignore_index=True).drop_duplicates()

    sub = sub.sort_values("year", ascending=True).head(max_rows)
    return sub


# =========================================================
# Explainable Scoring: Why A/B/C?
# =========================================================
@dataclass
class ScoreWeights:
    academics: float
    extracurricular: float
    constraints: float
    preference_fit: float


def extracurricular_score(level: str) -> float:
    return {"ë‚®ìŒ": 20.0, "ë³´í†µ": 60.0, "ë†’ìŒ": 90.0}.get(level, 60.0)


def constraints_penalty(constraints: List[str]) -> float:
    # each constraint adds penalty; cap
    p = 0.0
    for c in constraints:
        if "ì‹œê°„" in c:
            p += 18
        elif "ì˜ˆì‚°" in c:
            p += 15
        elif "ì§€ì—­" in c:
            p += 12
        else:
            p += 10
    return min(p, 45.0)


def preference_fit_score(activity_pref: List[str], route: str, route_detail: str) -> float:
    """
    crude but explainable:
    - í•™ìƒë¶€ì¢…í•©: ê¸€/í˜„ì¥/ì‚¬ëŒ ê°€ì‚°
    - í•™ìƒë¶€êµê³¼: ë°ì´í„°/ì„±ì  ì¤‘ì‹¬ ê°€ì‚°
    - ë…¼ìˆ : ê¸€/ë°ì´í„°(ë…¼ë¦¬) ê°€ì‚°
    - ì •ì‹œ: ë°ì´í„°/í•™ìŠµ ë£¨í‹´ ê°€ì‚°
    """
    s = 50.0
    pref = " ".join(activity_pref)

    if route == "ì •ì‹œ":
        if "ë°ì´í„°" in pref:
            s += 25
        if "ê¸€" in pref:
            s += 5
        if "ì‚¬ëŒ" in pref:
            s += 5

    if route == "ìˆ˜ì‹œ":
        if "í•™ìƒë¶€ì¢…í•©" in route_detail:
            if "ê¸€" in pref:
                s += 20
            if "í˜„ì¥" in pref:
                s += 15
            if "ì‚¬ëŒ" in pref:
                s += 10
        elif "í•™ìƒë¶€êµê³¼" in route_detail:
            if "ë°ì´í„°" in pref:
                s += 20
        elif "ë…¼ìˆ " in route_detail:
            if "ê¸€" in pref:
                s += 20
            if "ë°ì´í„°" in pref:
                s += 10

    return max(0.0, min(s, 100.0))


def academics_score(user_value: Optional[float], ref_series: Optional[pd.Series]) -> Tuple[float, str]:
    """
    Score 0..100. Lower grade is better.
    If ref not available: return neutral + guidance.
    If available: compare to median threshold (or last year).
    """
    if user_value is None:
        return 50.0, "ì„±ì  ì…ë ¥ì´ ì—†ì–´ í•™ì—… ì ìˆ˜ëŠ” ì¤‘ë¦½(50)ìœ¼ë¡œ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤."
    if ref_series is None or ref_series.empty:
        # no data coverage -> cannot score with reference
        # still score based on absolute roughness (1.0 best .. 9.0 worst)
        s = 100.0 - (user_value - 1.0) * 15.0
        return max(10.0, min(s, 90.0)), "ë°ì´í„° ì»¤ë²„ë¦¬ì§€ ë°–ì´ë¼ ì ˆëŒ€ê°’ ê¸°ë°˜(ê±°ì¹œ) ì ìˆ˜ë¡œ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤."

    # use last year's threshold as anchor (most recent)
    anchor = float(ref_series.dropna().iloc[-1])
    diff = user_value - anchor

    # diff <= -0.2 very favorable; diff around 0 ~ 0.4 ok; diff > 0.4 hard
    if diff <= -0.2:
        s = 90.0
        msg = f"ì…ë ¥ ì„±ì ({user_value:.1f})ì´ ìµœê·¼ ê¸°ì¤€ì„ ({anchor:.1f})ë³´ë‹¤ ìœ ë¦¬ â†’ í•™ì—… ì ìˆ˜â†‘"
    elif diff <= 0.4:
        s = 65.0
        msg = f"ì…ë ¥ ì„±ì ({user_value:.1f})ì´ ìµœê·¼ ê¸°ì¤€ì„ ({anchor:.1f}) ê·¼ì²˜ â†’ í•™ì—… ì ìˆ˜ ì¤‘ê°„"
    else:
        s = 35.0
        msg = f"ì…ë ¥ ì„±ì ({user_value:.1f})ì´ ìµœê·¼ ê¸°ì¤€ì„ ({anchor:.1f})ë³´ë‹¤ ë¶ˆë¦¬ â†’ í•™ì—… ì ìˆ˜â†“"
    return s, msg


def total_score(
    w: ScoreWeights,
    acad: float,
    extra: float,
    penalty: float,
    fit: float,
) -> Tuple[float, Dict[str, float]]:
    """
    Combine into 0..100 score with clear breakdown.
    constraints penalty subtracts.
    """
    # normalize weights to sum=1
    s = w.academics + w.extracurricular + w.constraints + w.preference_fit
    if s <= 0:
        w_norm = ScoreWeights(0.4, 0.25, 0.2, 0.15)
        s = 1.0
    else:
        w_norm = ScoreWeights(
            w.academics / s,
            w.extracurricular / s,
            w.constraints / s,
            w.preference_fit / s,
        )

    contrib_acad = acad * w_norm.academics
    contrib_extra = extra * w_norm.extracurricular
    contrib_fit = fit * w_norm.preference_fit

    # penalty applies with weight on constraints
    contrib_penalty = penalty * w_norm.constraints

    score = contrib_acad + contrib_extra + contrib_fit - contrib_penalty
    score = max(0.0, min(score, 100.0))

    breakdown = {
        "í•™ì—…(ì„±ì )": contrib_acad,
        "ë¹„êµê³¼": contrib_extra,
        "ì í•©ë„(ì„±í–¥â†”ì „í˜•)": contrib_fit,
        "ì œì•½(ê°ì )": -contrib_penalty,
        "ì´ì ": score,
    }
    return score, breakdown


def score_to_band(score: float) -> str:
    if score >= 75:
        return "ì•ˆì •"
    if score >= 55:
        return "ì ì •"
    return "ë„ì „"


# =========================================================
# OpenAI Responses API (optional)
# =========================================================
def openai_generate_plan(
    api_key: str,
    model: str,
    payload_json: Dict[str, Any],
    context_docs: List[Dict[str, str]],
) -> Dict[str, Any]:
    url = "https://api.openai.com/v1/responses"
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}

    prompt = f"""
ë„ˆëŠ” 'ëŒ€í•™ ì§„í•™ AI ì»¨ì„¤í„´íŠ¸'ë‹¤.

ì›ì¹™(ë§¤ìš° ì¤‘ìš”):
- ì‚¬ìš©ìê°€ ì„ íƒ/ì…ë ¥í•œ ì „í˜•ì„ ìš°ì„  ì¡´ì¤‘í•˜ë˜, ê°€ëŠ¥ì„±/ë¦¬ìŠ¤í¬/ëŒ€ì•ˆê¹Œì§€ í•¨ê»˜ ì œì‹œí•˜ë¼.
- ì‚¬ì‹¤(ì „í˜•ìš”ê°•/ë°ì´í„°)ì€ ì•„ë˜ [ê·¼ê±° ë¬¸ì„œ]ì— ìˆëŠ” ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ë¼.
- ê·¼ê±° ë¬¸ì„œì— ì—†ëŠ” ìˆ˜ì¹˜/ì‚¬ì‹¤ì€ ë‹¨ì •í•˜ì§€ ë§ê³  "ì¼ë°˜ ê°€ì´ë“œ"ë¡œ í‘œí˜„í•˜ë¼.
- í™•ë¥  ë‹¨ì • ê¸ˆì§€. ëŒ€ì‹  ì•ˆì •/ì ì •/ë„ì „ êµ¬ê°„ìœ¼ë¡œ í‘œí˜„í•˜ë¼.
- 8ì£¼ ë¡œë“œë§µì€ ì‚¬ìš©ìê°€ ì„ íƒí•œ ì „í˜•ê³¼ í˜„ì¬ ì‹œì (ì›”/ì£¼ì°¨)ì„ ê³ ë ¤í•´
  "ì£¼ì°¨ë³„ í•µì‹¬ ëª©í‘œ 1ê°œ + í•  ì¼ 2~3ê°œ + ì‚°ì¶œë¬¼ 1ê°œ"ë¡œ êµ¬ì¡°í™”í•˜ë¼.

ì¶œë ¥ì€ ë°˜ë“œì‹œ ì•„ë˜ JSON ìŠ¤í‚¤ë§ˆë¡œë§Œ ì‘ì„±í•˜ë¼(ë‹¤ë¥¸ ë¬¸ì¥ ê¸ˆì§€).

JSON ìŠ¤í‚¤ë§ˆ:
{{
  "summary_5lines": [string, string, string, string, string],
  "routes": {{
    "A": {{
      "title": "ì•ˆì •",
      "reasons": [string, string, string],
      "actions": [string, string, string, string, string],
      "risks": [string, string]
    }},
    "B": {{
      "title": "ì ì •",
      "reasons": [string, string, string],
      "actions": [string, string, string, string, string],
      "risks": [string, string]
    }},
    "C": {{
      "title": "ë„ì „",
      "reasons": [string, string, string],
      "actions": [string, string, string, string, string],
      "risks": [string, string]
    }}
  }},
  "roadmap": [
    {{
      "week": number,
      "goal": string,
      "tasks": [string, string, string],
      "deliverable": string
    }}
  ],
  "evidence": [
    {{
      "title": string,
      "note": string
    }}
  ]
}}

[ì‚¬ìš©ì ì…ë ¥(JSON)]
{json.dumps(payload_json, ensure_ascii=False)}

[ê·¼ê±° ë¬¸ì„œ]
{json.dumps(context_docs, ensure_ascii=False)}
""".strip()

    body = {
        "model": model,
        "input": [{"role": "user", "content": [{"type": "input_text", "text": prompt}]}],
        "text": {"format": {"type": "json_object"}},
    }

    r = requests.post(url, headers=headers, json=body, timeout=60)
    r.raise_for_status()
    data = r.json()

    text_out = ""
    for out_item in data.get("output", []):
        for c in out_item.get("content", []):
            if c.get("type") in ("output_text", "text") and c.get("text"):
                text_out += c["text"]
    text_out = text_out.strip()
    if not text_out:
        raise ValueError("OpenAI ì‘ë‹µ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

    try:
        return json.loads(text_out)
    except json.JSONDecodeError:
        start = text_out.find("{")
        end = text_out.rfind("}")
        if start != -1 and end != -1 and end > start:
            return json.loads(text_out[start : end + 1])
        raise


# =========================================================
# Rule-based fallback
# =========================================================
def rule_based_plan(payload: Dict[str, Any]) -> Dict[str, Any]:
    route = payload.get("route", "ìˆ˜ì‹œ")
    route_detail = payload.get("route_detail", "")
    major_group = payload.get("major_group", "")
    band = payload.get("band_label", "ì ì •")

    summary = [
        f"í¬ë§ ì „í˜•ì€ '{route}{(' - ' + route_detail) if route_detail else ''}'ì´ë©°, ì…ë ¥ ì„±ì /ì¡°ê±´ ê¸°ë°˜ìœ¼ë¡œ êµ¬ê°„ì€ '{band}'ì…ë‹ˆë‹¤.",
        f"ê´€ì‹¬ ì „ê³µêµ°ì€ '{major_group}'ì´ê³ , ì„ í˜¸ í™œë™ ì„±í–¥ì„ ì „í˜• íŠ¹ì„±ê³¼ ë§¤ì¹­í–ˆìŠµë‹ˆë‹¤.",
        "ë°ì´í„° ì»¤ë²„ë¦¬ì§€ ë‚´ì—ì„œëŠ” ì—°ë„/ì¶œì²˜ë¥¼ ê·¼ê±°ë¡œ ì œì‹œí•˜ê³ , ë°–ì—ì„œëŠ” ì¼ë°˜ ì „ëµ ê°€ì´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤.",
        "ì¶”ì²œì€ ë‹¨ì •ì´ ì•„ë‹Œ ëŒ€ì•ˆ ë¹„êµ(A/B/C) êµ¬ì¡°ë¡œ ì œê³µë©ë‹ˆë‹¤.",
        "ë§ˆì§€ë§‰ìœ¼ë¡œ 8ì£¼ ë¡œë“œë§µì„ ì£¼ì°¨ë³„ ëª©í‘œ/í•  ì¼/ì‚°ì¶œë¬¼ë¡œ êµ¬ì¡°í™”í•©ë‹ˆë‹¤.",
    ]

    def mk_route(title: str) -> Dict[str, Any]:
        return {
            "title": title,
            "reasons": [
                "ì‚¬ìš©ì ì…ë ¥(ì„±ì /ì„±í–¥/ì œì•½)ê³¼ ì „í˜• íŠ¹ì„±ì˜ ì •í•©ì„±ì„ ê¸°ì¤€ìœ¼ë¡œ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.",
                "ë¶ˆí™•ì‹¤ ìš”ì†ŒëŠ” ë¦¬ìŠ¤í¬ë¡œ ë¶„ë¦¬í•˜ê³  ëŒ€ì•ˆì„ í•¨ê»˜ ì œì‹œí•©ë‹ˆë‹¤.",
                "ì‹¤í–‰ ê°€ëŠ¥ì„±ì„ ë†’ì´ê¸° ìœ„í•´ í•  ì¼ì„ ì•¡ì…˜ ë‹¨ìœ„ë¡œ ìª¼ê°°ìŠµë‹ˆë‹¤.",
            ],
            "actions": [
                "ì „í˜• ìš”ê±´ ì²´í¬ë¦¬ìŠ¤íŠ¸ ì‘ì„±(í•„ìˆ˜/ì„ íƒ ë¶„ë¦¬)",
                "í•µì‹¬ ìŠ¤í† ë¦¬ 3ê°œë¥¼ STARë¡œ ì •ë¦¬(í™œë™-ì—­í• -ì„±ê³¼-ë°°ì›€)",
                "ì§€ì› ì¡°í•© 3ê°œ(A/B/C)ë¡œ ë¶„ì‚° ì„¤ê³„",
                "ì£¼ 1íšŒ í”¼ë“œë°± ë£¨í”„(ì„ ìƒë‹˜/ì„ ë°°/AI)ë¡œ ìˆ˜ì •",
                "ë¦¬ìŠ¤í¬ ëŒ€ë¹„ ëŒ€ì•ˆ ì „í˜• 1ê°œ í™•ë³´",
            ],
            "risks": [
                "ë°ì´í„° ë²”ìœ„ ë°–ì—ì„œëŠ” ìˆ˜ì¹˜ ì˜ˆì¸¡ì„ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
                "ì „í˜•ë³„ ì‚°ì¶œë¬¼/ì¼ì •ì´ ì´‰ë°•í•´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            ],
        }

    routes = {"A": mk_route("ì•ˆì •"), "B": mk_route("ì ì •"), "C": mk_route("ë„ì „")}

    roadmap = []
    for w in range(1, 9):
        if route == "ì •ì‹œ":
            goal = "ì‹¤ì „ ì ìˆ˜ ì•ˆì •í™”" if w <= 3 else ("ì•½ì  ë³´ì™„ ì§‘ì¤‘" if w <= 6 else "ì‹¤ì „ ë£¨í‹´ ê³ ì •")
            tasks = [
                "ê¸°ì¶œ/ëª¨ì˜ 1íšŒë¶„ í’€ì´",
                "ì˜¤ë‹µ ì›ì¸ ë¶„ë¥˜(ê°œë…/ì‹œê°„/ì‹¤ìˆ˜)",
                "ì·¨ì•½ ë‹¨ì› 1ê°œ ë³´ì™„",
            ]
            deliverable = f"Week {w}: ì˜¤ë‹µ ë¶„ë¥˜í‘œ + ì·¨ì•½ ë‹¨ì› ê³„íš"
        else:
            goal = "ì§€ì›ì „ëµ í™•ì •" if w <= 2 else ("ìì†Œì„œ/í™œë™ ì •ë¦¬" if w <= 5 else "ë©´ì ‘/ë…¼ìˆ  ëŒ€ë¹„")
            tasks = [
                "ì „í˜• ìš”ê°• ì²´í¬ + ì œì¶œë¬¼ ëª©ë¡í™”",
                "í™œë™ 3ê°œ STAR ì •ë¦¬",
                "ìì†Œì„œ/ë©´ì ‘ ì§ˆë¬¸ 5ê°œ ì´ˆì•ˆ ì‘ì„±",
            ]
            deliverable = f"Week {w}: {route_detail or 'ìˆ˜ì‹œ'} ì‚°ì¶œë¬¼ 1ì¢… ì´ˆì•ˆ"
        roadmap.append({"week": w, "goal": goal, "tasks": tasks, "deliverable": deliverable})

    evidence = [{"title": "ì¼ë°˜ ì „ëµ ê°€ì´ë“œ", "note": "í‚¤ ë¯¸ì…ë ¥/ë°ì´í„° ë²”ìœ„ ë°– ì‹œ ë£°ë² ì´ìŠ¤ë¡œ ì œê³µ"}]
    return {"summary_5lines": summary, "routes": routes, "roadmap": roadmap, "evidence": evidence}


# =========================================================
# App State
# =========================================================
if "df_data" not in st.session_state:
    st.session_state.df_data = pd.DataFrame()
if "result" not in st.session_state:
    st.session_state.result = None
if "payload" not in st.session_state:
    st.session_state.payload = None
if "evidence" not in st.session_state:
    st.session_state.evidence = []
if "score_breakdown" not in st.session_state:
    st.session_state.score_breakdown = None


# =========================================================
# Header
# =========================================================
st.title("ğŸ§­ Y-Compass (ì™€ì´ì»´í¼ìŠ¤)")
st.caption("ì—°ì„¸ëŒ€ AX ìº í”„ Track 1 â€” ì†Œê·¸ë£¹ ì±Œë¦°ì§€ | ê·¼ê±° ê¸°ë°˜ AI ì§„í•™ ì¹´ìš´ì…€ëŸ¬ (MVP+)")


# =========================================================
# Sidebar: API + Weights + Pricing (ì‹¬ì‚¬ì ê´€ì )
# =========================================================
with st.sidebar:
    st.header("ğŸ”‘ OpenAI (ì„ íƒ)")
    openai_key_default = st.secrets.get("OPENAI_API_KEY", "")
    openai_api_key = st.text_input("OpenAI API Key", value=openai_key_default, type="password", placeholder="sk-...")
    openai_model = st.text_input("ëª¨ë¸", value="gpt-4.1-mini")

    st.divider()
    st.header("âš™ï¸ ì ìˆ˜ ê°€ì¤‘ì¹˜(ì„¤ëª…ê°€ëŠ¥ì„±)")
    st.caption("A/B/C êµ¬ê°„ì€ ì ìˆ˜ë¡œ ì‚°ì¶œë˜ë©°, ê° ìš”ì†Œì˜ ê¸°ì—¬ë„ë¥¼ ê³µê°œí•©ë‹ˆë‹¤.")
    w_acad = st.slider("í•™ì—…(ì„±ì )", 0.0, 1.0, 0.45, 0.05)
    w_extra = st.slider("ë¹„êµê³¼", 0.0, 1.0, 0.25, 0.05)
    w_const = st.slider("ì œì•½(ê°ì )", 0.0, 1.0, 0.20, 0.05)
    w_fit = st.slider("ì „í˜•-ì„±í–¥ ì í•©ë„", 0.0, 1.0, 0.10, 0.05)

    weights = ScoreWeights(w_acad, w_extra, w_const, w_fit)

    st.divider()
    st.header("ğŸ’³ ìƒìš©í™”(í‹°ì–´) ì´ˆì•ˆ")
    tier = st.selectbox("ìš”ê¸ˆì œ(ë°ëª¨)", ["Free", "Basic", "Pro"])
    tier_desc = {
        "Free": "ì§„ë‹¨ + A/B/C ìš”ì•½ + 2ì£¼ ë¯¸ë‹ˆ ì²´í¬ë¦¬ìŠ¤íŠ¸",
        "Basic": "A/B/C ìƒì„¸ + 8ì£¼ ë¡œë“œë§µ + ê·¼ê±° ë³´ê¸°",
        "Pro": "ì „í˜•ë³„ ì‹¬í™”(ìì†Œì„œ/ë©´ì ‘ í¬ì¸íŠ¸) + PDF/ì €ì¥/ë²„ì „ê´€ë¦¬(ì»¨ì…‰)",
    }
    st.write(f"**{tier}**: {tier_desc[tier]}")

    st.divider()
    today = st.date_input("í˜„ì¬ ì‹œì (ë¡œë“œë§µ ê¸°ì¤€)", value=date.today())


tabs = st.tabs(["ğŸ—ƒï¸ ë°ì´í„° ì—…ë¡œë“œ", "ğŸ“ ì§„ë‹¨ ì…ë ¥", "ğŸ“Œ ê²°ê³¼", "ğŸ“ ë¦¬í¬íŠ¸/ê¸°íšì„œ"])


# =========================================================
# Tab 1: Data Upload
# =========================================================
with tabs[0]:
    st.subheader("ğŸ—ƒï¸ ì…ì‹œ ë°ì´í„° ì—…ë¡œë“œ (CSV)")
    st.write("ì—¬ê¸° ì—…ë¡œë“œëœ ë°ì´í„°ê°€ **ê·¼ê±°(ì¶œì²˜/ì—°ë„) + ê°€ëŠ¥ì„± ê·¸ë˜í”„ + ì ìˆ˜ ì‚°ì •**ì— ë°˜ì˜ë©ë‹ˆë‹¤.")

    with st.expander("CSV í…œí”Œë¦¿(ê¶Œì¥) ë³´ê¸°", expanded=True):
        st.code(
            "university,major,route,route_detail,year,metric,threshold,source,note\n"
            "ì—°ì„¸ëŒ€,ê²½ì˜í•™ê³¼,ìˆ˜ì‹œ,í•™ìƒë¶€ì¢…í•©,2022,gpa,2.0,ì…í•™ì²˜,ì˜ˆì‹œ\n"
            "ì—°ì„¸ëŒ€,ê²½ì˜í•™ê³¼,ìˆ˜ì‹œ,í•™ìƒë¶€ì¢…í•©,2023,gpa,2.1,ì…í•™ì²˜,ì˜ˆì‹œ\n"
            "ì—°ì„¸ëŒ€,ê²½ì˜í•™ê³¼,ì •ì‹œ,,2024,mock,1.6,ì…í•™ì²˜,ì˜ˆì‹œ\n",
            language="text",
        )

    uploaded = st.file_uploader("CSV ì—…ë¡œë“œ", type=["csv"])
    if uploaded is not None:
        try:
            df_raw = pd.read_csv(uploaded)
            df = normalize_df(df_raw)
            st.session_state.df_data = df
            st.success(f"ì—…ë¡œë“œ ì„±ê³µ! rows={len(df):,}")
            st.dataframe(df.head(30), use_container_width=True)
        except Exception as e:
            st.error("CSV íŒŒì‹±/ì •ê·œí™” ì‹¤íŒ¨")
            st.caption(str(e))

    if st.session_state.df_data is not None and not st.session_state.df_data.empty:
        st.divider()
        st.markdown("#### ë°ì´í„° ì»¤ë²„ë¦¬ì§€ ì ê²€(ë¹ ë¥¸ í•„í„°)")
        df = st.session_state.df_data
        u = st.selectbox("ëŒ€í•™", sorted(df["university"].unique().tolist()))
        majors = sorted(df[df["university"] == u]["major"].unique().tolist())
        m = st.selectbox("í•™ê³¼", majors)
        r = st.selectbox("ì „í˜•(ìˆ˜ì‹œ/ì •ì‹œ)", ["ìˆ˜ì‹œ", "ì •ì‹œ"])
        rd = ""
        if r == "ìˆ˜ì‹œ":
            rd = st.selectbox("ìˆ˜ì‹œ ì„¸ë¶€", sorted(df[(df["university"] == u) & (df["major"] == m) & (df["route"] == "ìˆ˜ì‹œ")]["route_detail"].unique().tolist()))
        metric = st.selectbox("ê¸°ì¤€ì„  ìœ í˜•(metric)", ["gpa", "mock"])

        matched = match_rows(df, u, m, r, rd, metric)
        st.write(f"ë§¤ì¹­ ê²°ê³¼: {len(matched)} rows")
        st.dataframe(matched, use_container_width=True)


# =========================================================
# Tab 2: Intake
# =========================================================
with tabs[1]:
    st.subheader("ğŸ“ ì§„ë‹¨ ì…ë ¥ (3ë¶„)")
    st.caption("í¬ë§ ì „í˜• ì…ë ¥ â†’ ì„±ì /ì„±í–¥/ì œì•½ ê¸°ë°˜ ì ìˆ˜í™” â†’ ë°ì´í„° ê¸°ë°˜ì´ë©´ ê·¼ê±°/ê·¸ë˜í”„ê¹Œì§€ ìƒì„±")

    df_all = st.session_state.df_data if st.session_state.df_data is not None else pd.DataFrame()
    use_df = not df_all.empty

    with st.form("intake", clear_on_submit=False):
        c1, c2 = st.columns(2, gap="large")

        with c1:
            st.markdown("#### 1) í¬ë§ ì „í˜• ì…ë ¥(í”¼ë“œë°± ë°˜ì˜ í•µì‹¬)")
            grade_status = st.selectbox("í•™ë…„/ìƒíƒœ", ["ê³ 3", "Nìˆ˜(ì¬ìˆ˜/ì‚¼ìˆ˜)", "ê³ 2(ë¯¸ë¦¬ë³´ê¸°)"])
            route = st.selectbox("ìˆ˜ì‹œ/ì •ì‹œ", ADMISSION_ROUTE)
            route_detail = ""
            if route == "ìˆ˜ì‹œ":
                route_detail = st.selectbox("ìˆ˜ì‹œ ì„¸ë¶€ ì „í˜•", SUSI_DETAIL)

            desired_university = st.text_input("í¬ë§ ëŒ€í•™(ê¶Œì¥)", placeholder="ì˜ˆ: ì—°ì„¸ëŒ€")
            desired_major = st.text_input("í¬ë§ í•™ê³¼(ê¶Œì¥)", placeholder="ì˜ˆ: ê²½ì˜í•™ê³¼")
            desired_text = st.text_input("í¬ë§ ì „í˜•/í•™ê³¼/ëŒ€í•™(ììœ  ì…ë ¥)", placeholder="ì˜ˆ: ì—°ì„¸ëŒ€ ê²½ì˜í•™ê³¼ í•™ìƒë¶€ì¢…í•©")

            st.markdown("#### 2) ì„±ì  ì…ë ¥(êµ¬ê°„)")
            gpa_band = st.selectbox("ë‚´ì‹  ë“±ê¸‰", ["ëª¨ë¦„/ì…ë ¥ì•ˆí•¨", "1.x", "2.x", "3.x", "4.x", "5.x", "ì§ì ‘ì…ë ¥"])
            gpa_direct = st.text_input("ë‚´ì‹  ì§ì ‘ ì…ë ¥(ì„ íƒ)", placeholder="ì˜ˆ: 2.3") if gpa_band == "ì§ì ‘ì…ë ¥" else ""
            mock_band = st.selectbox("ëª¨ì˜ê³ ì‚¬ ë“±ê¸‰/í™˜ì‚°", ["ëª¨ë¦„/ì…ë ¥ì•ˆí•¨", "1.x", "2.x", "3.x", "4.x", "5.x", "ì§ì ‘ì…ë ¥"])
            mock_direct = st.text_input("ëª¨ì˜ ì§ì ‘ ì…ë ¥(ì„ íƒ)", placeholder="ì˜ˆ: 2.1") if mock_band == "ì§ì ‘ì…ë ¥" else ""

        with c2:
            st.markdown("#### 3) ì„±í–¥/ë¹„êµê³¼/ì œì•½")
            major_group = st.selectbox("ê´€ì‹¬ ì „ê³µêµ°", MAJOR_GROUPS)
            activity_pref = st.multiselect("ì„ í˜¸ í™œë™/ê°•ì ", ACTIVITY_PREF, default=[ACTIVITY_PREF[0]])
            extracurricular = st.select_slider("ë¹„êµê³¼ ê°•ë„(ìê°€í‰ê°€)", options=EXTRACURRICULAR_LEVELS, value="ë³´í†µ")
            priorities = st.multiselect("ëª©í‘œ ìš°ì„ ìˆœìœ„(ìµœëŒ€ 2)", GOAL_PRIORITY, default=[GOAL_PRIORITY[0], GOAL_PRIORITY[1]])
            constraints = st.multiselect("ì œì•½", CONSTRAINTS, default=[])

            current_stage = st.selectbox("í˜„ì¬ ë‹¨ê³„(ë¡œë“œë§µ ê¸°ì¤€)", CURRENT_STAGE)
            notes = st.text_area("ì¶”ê°€ ë©”ëª¨(ì„ íƒ)", placeholder="ì˜ˆ: ë…¼ìˆ  ë³‘í–‰ / í†µí•™ ì œì•½ / ë©´ì ‘ì´ ë¶ˆì•ˆ")

            st.info("ê°œì¸ì •ë³´(í•™êµ/ì‹¤ëª…/ì—°ë½ì²˜ ë“±) ì…ë ¥ ê¸ˆì§€. ì¶”ì²œì€ ì°¸ê³ ìš©ì…ë‹ˆë‹¤.")

        go = st.form_submit_button("ê²°ê³¼ ìƒì„±", type="primary")

    if go:
        # parse numeric
        gpa_val = band_to_float(gpa_direct if gpa_band == "ì§ì ‘ì…ë ¥" else gpa_band)
        mock_val = band_to_float(mock_direct if mock_band == "ì§ì ‘ì…ë ¥" else mock_band)

        # pick metric by route
        metric = "mock" if route == "ì •ì‹œ" else "gpa"
        user_metric_value = mock_val if metric == "mock" else gpa_val

        university = _nonempty(desired_university) or (_nonempty(desired_text).split()[0] if _nonempty(desired_text) else "")
        major = _nonempty(desired_major) or ""

        # match data rows if available
        matched = pd.DataFrame()
        if use_df and university and major:
            matched = match_rows(df_all, university, major, route, route_detail, metric)

        is_data_based = (matched is not None) and (not matched.empty)

        # academics score uses ref series if data-based
        ref_series = matched.sort_values("year")["threshold"] if is_data_based else None
        acad_s, acad_msg = academics_score(user_metric_value, ref_series)

        extra_s = extracurricular_score(extracurricular)
        penalty = constraints_penalty(constraints)
        fit_s = preference_fit_score(activity_pref, route, route_detail)

        tot, breakdown = total_score(weights, acad_s, extra_s, penalty, fit_s)
        band = score_to_band(tot)

        payload = {
            "today": str(today),
            "grade_status": grade_status,
            "route": route,
            "route_detail": route_detail,
            "desired_university": university,
            "desired_major": major,
            "desired_text": desired_text,
            "major_group": major_group,
            "gpa_value": gpa_val,
            "mock_value": mock_val,
            "metric_used": metric,
            "metric_value": user_metric_value,
            "activity_pref": activity_pref,
            "extracurricular_level": extracurricular,
            "priorities": priorities[:2],
            "constraints": constraints,
            "current_stage": current_stage,
            "notes": notes,
            "band_label": band,
            "coverage": coverage_badge(is_data_based),
            "score_total": float(tot),
            "score_breakdown": breakdown,
            "scoring_notes": {
                "academics": acad_msg,
                "fit": "ì „í˜•-ì„±í–¥ ì í•©ë„ëŠ” ì„ íƒ ì„±í–¥ê³¼ ì „í˜• íŠ¹ì„± ë§¤ì¹­ìœ¼ë¡œ ì‚°ì¶œí–ˆìŠµë‹ˆë‹¤.",
                "constraints": "ì œì•½ì€ ê°ì ìœ¼ë¡œ ì ìš©ë˜ë©°(ê°€ì¤‘ì¹˜ ë°˜ì˜), ë§ì„ìˆ˜ë¡ ë¦¬ìŠ¤í¬ê°€ ì»¤ì§‘ë‹ˆë‹¤.",
            },
        }
        st.session_state.payload = payload
        st.session_state.score_breakdown = breakdown

        # Build evidence (RAG context)
        evidence_docs: List[Dict[str, str]] = []
        if is_data_based:
            # compact the matched rows as evidence
            for _, row in matched.sort_values("year").tail(10).iterrows():
                title = f"{row['university']} {row['major']} | {row['route']}{(' - ' + row['route_detail']) if row['route_detail'] else ''} | {int(row['year'])}"
                note = f"metric={row['metric']} threshold={row['threshold']} | source={row.get('source','')} | note={row.get('note','')}"
                evidence_docs.append({"title": title, "note": note})
        else:
            evidence_docs.append(
                {
                    "title": "ë°ì´í„° ë¯¸ë³´ìœ (ê°€ì´ë“œ ê¸°ë°˜)",
                    "note": "í•´ë‹¹ ëŒ€í•™/í•™ê³¼/ì „í˜•ì˜ ì—…ë¡œë“œ ë°ì´í„°ê°€ ì—†ì–´ ìˆ˜ì¹˜ ê¸°ë°˜ ì˜ˆì¸¡ì„ ì œê³µí•˜ì§€ ì•Šê³ , ì „í˜• íŠ¹ì„± ê¸°ë°˜ ì „ëµ ê°€ì´ë“œë¡œ ì•ˆë‚´í•©ë‹ˆë‹¤.",
                }
            )

        st.session_state.evidence = evidence_docs

        # Generate plan (OpenAI if key else rule-based)
        with st.spinner("A/B/C ì¶”ì²œ + 8ì£¼ ë¡œë“œë§µ ìƒì„± ì¤‘..."):
            try:
                if _nonempty(openai_api_key):
                    plan = openai_generate_plan(
                        api_key=openai_api_key.strip(),
                        model=openai_model.strip(),
                        payload_json=payload,
                        context_docs=evidence_docs,
                    )
                else:
                    plan = rule_based_plan(payload)
                plan["_meta"] = {
                    "coverage": payload["coverage"],
                    "score_total": payload["score_total"],
                    "score_breakdown": payload["score_breakdown"],
                    "academics_msg": acad_msg,
                }
                st.session_state.result = plan
                st.success("ì™„ë£Œ! 'ğŸ“Œ ê²°ê³¼' íƒ­ì—ì„œ í™•ì¸í•´ì¤˜.")
            except Exception as e:
                st.session_state.result = None
                st.error("ìƒì„± ì‹¤íŒ¨(í‚¤/ëª¨ë¸/ë„¤íŠ¸ì›Œí¬/JSON í˜•ì‹) í™•ì¸")
                st.caption(str(e))


# =========================================================
# Tab 3: Results
# =========================================================
with tabs[2]:
    st.subheader("ğŸ“Œ ê²°ê³¼")
    if st.session_state.result is None or st.session_state.payload is None:
        st.info("ë¨¼ì € 'ğŸ“ ì§„ë‹¨ ì…ë ¥'ì—ì„œ ê²°ê³¼ë¥¼ ìƒì„±í•´ì¤˜.")
    else:
        payload = st.session_state.payload
        plan = st.session_state.result
        meta = plan.get("_meta", {})

        # --- Section 1: Possibility Card (Technical Spec ê·¸ëŒ€ë¡œ)
        st.markdown("## ì„¹ì…˜ 1 â€” ë‚´ê°€ ì›í•˜ëŠ” ì „í˜• ê°€ëŠ¥ì„± ì¹´ë“œ")
        a, b, c = st.columns([1.0, 1.0, 2.2], gap="large")

        with a:
            with st.container(border=True):
                st.markdown("**ì»¤ë²„ë¦¬ì§€**")
                st.write(payload["coverage"])
                st.caption("ë°ì´í„° ê¸°ë°˜ì´ë©´ ì—°ë„/ì¶œì²˜ ê·¼ê±° ë° ê·¸ë˜í”„ ì œê³µ")

        with b:
            with st.container(border=True):
                st.markdown("**êµ¬ê°„(ì•ˆì •/ì ì •/ë„ì „)**")
                st.write(f"**{payload['band_label']}**")
                st.caption(f"ì´ì : {payload['score_total']:.1f} / 100")

        with c:
            with st.container(border=True):
                st.markdown("**ì™œ ì´ êµ¬ê°„ì¸ê°€? (ì„¤ëª…ê°€ëŠ¥ ì ìˆ˜í™”)**")
                st.write(meta.get("academics_msg", ""))
                st.markdown("**ê¸°ì—¬ë„(ê°€ì¤‘ì¹˜ ë°˜ì˜)**")
                bd = payload["score_breakdown"]
                st.write(f"- í•™ì—…(ì„±ì ): {bd['í•™ì—…(ì„±ì )']:.1f}")
                st.write(f"- ë¹„êµê³¼: {bd['ë¹„êµê³¼']:.1f}")
                st.write(f"- ì í•©ë„: {bd['ì í•©ë„(ì„±í–¥â†”ì „í˜•)']:.1f}")
                st.write(f"- ì œì•½(ê°ì ): {bd['ì œì•½(ê°ì )']:.1f}")

        st.divider()

        # --- Evidence visualization when data-based
        df_all = st.session_state.df_data if st.session_state.df_data is not None else pd.DataFrame()
        if payload["coverage"].startswith("ë°ì´í„° ê¸°ë°˜") and not df_all.empty:
            st.markdown("### ê·¼ê±° ì‹œê°í™”(ì—°ë„ë³„ ê¸°ì¤€ì„  vs ë‚´ ì„±ì )")
            metric = payload["metric_used"]
            university = payload.get("desired_university", "")
            major = payload.get("desired_major", "")
            route = payload.get("route", "ìˆ˜ì‹œ")
            route_detail = payload.get("route_detail", "")

            matched = match_rows(df_all, university, major, route, route_detail, metric)
            if matched is not None and not matched.empty:
                chart_df = matched.sort_values("year")[["year", "threshold"]].copy()
                chart_df["user_value"] = payload.get("metric_value", None)

                st.dataframe(chart_df, use_container_width=True)

                st.line_chart(chart_df.set_index("year")[["threshold", "user_value"]])
                st.caption("â€» ë“±ê¸‰ ê¸°ì¤€: ë‚®ì„ìˆ˜ë¡ ìœ ë¦¬. (ê·¸ë˜í”„ëŠ” ì°¸ê³ ìš©ì´ë©°, ë‹¨ì •ì  í•©ê²© ì˜ˆì¸¡ì´ ì•„ë‹˜)")
            else:
                st.info("ì‹œê°í™”í•  ë§¤ì¹­ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤(í•™ê³¼ëª…/ì „í˜• í‚¤ì›Œë“œ í™•ì¸).")

        st.divider()

        # --- Section 2: A/B/C cards
        st.markdown("## ì„¹ì…˜ 2 â€” AI ì¶”ì²œ ì „í˜•/ì „ëµ TOP3 (A/B/C)")
        routes = plan.get("routes", {})
        cols = st.columns(3, gap="large")
        keys = ["A", "B", "C"]
        title_map = {"A": "A: ì•ˆì •", "B": "B: ì ì •", "C": "C: ë„ì „"}

        for i, k in enumerate(keys):
            r = routes.get(k, {})
            with cols[i]:
                with st.container(border=True):
                    st.markdown(f"### {title_map[k]}")
                    st.caption(r.get("title", ""))

                    st.markdown("**ì¶”ì²œ ì´ìœ (3)**")
                    for x in (r.get("reasons") or [])[:3]:
                        st.write(f"- {x}")

                    st.markdown("**ì¤€ë¹„ ì•¡ì…˜(5)**")
                    for x in (r.get("actions") or [])[:5]:
                        st.write(f"- {x}")

                    st.markdown("**ë¦¬ìŠ¤í¬/ê°€ì •(2)**")
                    for x in (r.get("risks") or [])[:2]:
                        st.write(f"- {x}")

        st.divider()

        # --- Section 3: 8-week Roadmap
        st.markdown("## ì„¹ì…˜ 3 â€” 8ì£¼ ë¡œë“œë§µ")
        roadmap = plan.get("roadmap", [])
        if not roadmap:
            st.warning("ë¡œë“œë§µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        else:
            for item in roadmap[:8]:
                w = item.get("week")
                with st.expander(f"Week {w} â€” {item.get('goal','')}", expanded=(w == 1)):
                    st.markdown("**í•  ì¼(2~3)**")
                    for t in (item.get("tasks") or [])[:3]:
                        st.write(f"- {t}")
                    st.markdown("**ì‚°ì¶œë¬¼**")
                    st.write(item.get("deliverable", ""))

        st.divider()

        # --- Evidence (RAG)
        st.markdown("### ê·¼ê±° ë³´ê¸°(ì¶œì²˜)")
        evs = plan.get("evidence", []) or st.session_state.evidence or []
        if evs:
            for ev in evs[:15]:
                with st.expander(ev.get("title", "ê·¼ê±°")):
                    st.write(ev.get("note", ""))
        else:
            st.caption("í‘œì‹œí•  ê·¼ê±°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        st.divider()

        # --- Download
        st.markdown("### ê²°ê³¼ ì €ì¥(ì œì¶œ/ì‹œì—°ìš©)")
        report = {
            "payload": payload,
            "summary_5lines": plan.get("summary_5lines", []),
            "routes": plan.get("routes", {}),
            "roadmap": plan.get("roadmap", []),
            "evidence": plan.get("evidence", []),
            "meta": plan.get("_meta", {}),
        }
        st.download_button(
            "ğŸ“„ ê²°ê³¼ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ (.json)",
            data=json.dumps(report, ensure_ascii=False, indent=2),
            file_name="y_compass_report.json",
            mime="application/json",
        )


# =========================================================
# Tab 4: Report / Spec (ë³´ê³ ì„œ ëŠë‚Œ + Technical Spec ë°˜ì˜)
# =========================================================
with tabs[3]:
    st.subheader("ğŸ“ ê¸°íšì„œ/ë¦¬í¬íŠ¸ (Report Ver.)")

    st.markdown(
        """
## 1. ê°œìš”
**ì•± ì´ë¦„:** Y-Compass(ì™€ì´ì»´í¼ìŠ¤) â€” Y(ì—°ì„¸ëŒ€ ë…¸í•˜ìš°) + Compass(ë°©í–¥ ì¡ê¸°)  
**ì•± í•œì¤„ ì„¤ëª…:** ëŒ€í•™ ì§„í•™ì´ ë§‰ë§‰í•œ 10ëŒ€ì—ê²Œ, ê·¼ê±° ê¸°ë°˜ í›„ë³´ 3ê°œ(A/B/C)ì™€ 8ì£¼ ë¡œë“œë§µì„ ì œê³µí•˜ëŠ” AI ì§„í•™ ì¹´ìš´ì…€ëŸ¬

### Problem Statement
- **ì •ë³´ ê³¼ì‰/ë¶„ì‚°:** ì „í˜•Â·ì „ê³µ ì •ë³´ê°€ í©ì–´ì ¸ ìˆì–´ ë¬´ì—‡ë¶€í„° ë³¼ì§€ ì–´ë ¤ì›€  
- **ë¹„ìš©/ì ‘ê·¼ì„±:** ì»¨ì„¤íŒ…ì€ ë¹„ì‹¸ê³  ì§€ì—­/ì‹œê°„ ì œì•½ì´ í¼  
- **ì‹ ë¢°ì„± ë¶€ì¡±:** â€œì¹´ë”ë¼â€ ì¡°ì–¸ì´ ë§ì•„ ê·¼ê±°Â·ì¶œì²˜ê°€ ë¶ˆíˆ¬ëª…

**í•´ê²° ì „ëµ:** ì§§ì€ ì…ë ¥ â†’ ê·¼ê±° ê¸°ë°˜ ì¶”ì²œ(ì¶œì²˜ ì œì‹œ) â†’ ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ë¡œë“œë§µ
"""
    )

    st.markdown("## 2. í•µì‹¬ ê¸°ëŠ¥(3)")
    st.markdown(
        """
1) **8ë¬¸í•­ ì§„í•™ ìƒí™© ìŠ¤ìº”(Intake & Profiling)**: ìƒí™© ìš”ì•½ 5ì¤„ + ê°•ì /ì œì•½ íƒœê·¸  
2) **ê·¼ê±° ê¸°ë°˜ í›„ë³´ 3ê°œ ì¶”ì²œ(A/B/C)**: ì¶”ì²œ ì´ìœ /ì•¡ì…˜/ë¦¬ìŠ¤í¬ + ê·¼ê±°(ì¶œì²˜)  
3) **8ì£¼ ë¡œë“œë§µ**: ì „í˜•+ì‹œì  ë°˜ì˜, ì£¼ì°¨ë³„ ëª©í‘œ1 + í•  ì¼2~3 + ì‚°ì¶œë¬¼1
"""
    )

    st.markdown("## 3. Technical Spec (í”¼ë“œë°± ë°˜ì˜)")
    st.table(
        [
            {
                "êµ¬ë¶„": "Input Data",
                "ìƒì„¸ ì •ì˜": "ì‚¬ìš©ì í¬ë§ ì „í˜•(ì§ì ‘ ì„ íƒ/ì…ë ¥) + ìˆ˜ì‹œ/ì •ì‹œ ëŒ€ë¶„ë¥˜ + ìˆ˜ì‹œ ì„¸ë¶€ ì „í˜• ë¶„ê¸° + ì„±ì (ë‚´ì‹ /ëª¨ì˜ êµ¬ê°„)",
            },
            {
                "êµ¬ë¶„": "AI Prompting",
                "ìƒì„¸ ì •ì˜": "ì „í˜• ì¡´ì¤‘ + ê°€ëŠ¥ì„±/ë¦¬ìŠ¤í¬/ëŒ€ì•ˆ ì œì‹œ. ê³¼ê±° ì…ì‹œ ê²°ê³¼ëŠ” ì—°ë„/ë²”ìœ„/í•œê³„ ëª…ì‹œ, í™•ë¥  ë‹¨ì • ê¸ˆì§€(ì•ˆì •/ì ì •/ë„ì „). ë°ì´í„° ì—†ëŠ” ê²½ìš° ìˆ˜ì¹˜ ì˜ˆì¸¡ ê¸ˆì§€â†’ì „í˜• íŠ¹ì„± ê¸°ë°˜ ê°€ì´ë“œ.",
            },
            {
                "êµ¬ë¶„": "Output Format",
                "ìƒì„¸ ì •ì˜": "ì„¹ì…˜1: ë‚´ê°€ ì›í•˜ëŠ” ì „í˜• ê°€ëŠ¥ì„± ì¹´ë“œ(ì»¤ë²„ë¦¬ì§€ í‘œì‹œ) / ì„¹ì…˜2: TOP3(A/B/C) / ì„¹ì…˜3: 8ì£¼ ë¡œë“œë§µ + ê·¼ê±°(expander)",
            },
        ]
    )

    st.markdown("## 4. ìƒìš©í™” í‹°ì–´(ì´ˆì•ˆ)")
    st.table(
        [
            {"Tier": "Free", "ì œê³µ": "ì§„ë‹¨ + A/B/C ìš”ì•½ + 2ì£¼ ë¯¸ë‹ˆ ì²´í¬ë¦¬ìŠ¤íŠ¸"},
            {"Tier": "Basic", "ì œê³µ": "A/B/C ìƒì„¸ + 8ì£¼ ë¡œë“œë§µ + ê·¼ê±° ë³´ê¸°"},
            {"Tier": "Pro", "ì œê³µ": "ì „í˜•ë³„ ì‹¬í™”(ìì†Œì„œ/ë©´ì ‘ í¬ì¸íŠ¸) + ë¦¬í¬íŠ¸/PDF + ì €ì¥/ë²„ì „ê´€ë¦¬(ì»¨ì…‰)"},
        ]
    )

    st.markdown("## 5. KPI(ì˜ˆì‹œ 3ê°œ)")
    st.markdown(
        """
- **Time-to-Plan**: ì…ë ¥ ì‹œì‘â†’8ì£¼ í”Œëœ ìƒì„±ê¹Œì§€ ê±¸ë¦° ì‹œê°„(ë¶„)  
- **Plan Save Rate**: ê²°ê³¼ ì €ì¥/ë‹¤ìš´ë¡œë“œ ë¹„ìœ¨(%)  
- **Perceived Trust**: â€œê·¼ê±°(ì¶œì²˜) ì œì‹œê°€ ë„ì›€ì´ ëë‹¤â€ ë§Œì¡±ë„(5ì  ì²™ë„)
"""
    )

st.caption("â€» ë³¸ ì•±ì€ ì°¸ê³ ìš© ì»¨ì„¤íŒ… ë„êµ¬ì´ë©°, í™•ë¥  ë‹¨ì •/í•©ê²© ë³´ì¥ì€ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
