# Y-Compass (ì™€ì´ì»´í¼ìŠ¤) â€” Streamlit MVP++ (ì‹¬í™” A/B ë°˜ì˜ í†µí•© app.py)
# =========================================================
# âœ… ì‹¬í™” A. ì™¸ë¶€ API ì—°ë™(1ê°œ ì´ìƒ)
#   - OpenWeatherMap: ë‚ ì”¨ ê¸°ë°˜ ì¶”ì²œ/ì¡°ì–¸ (key ì˜ˆì‹œ í¬í•¨)
#   - NewsAPI: ì‹¤ì‹œê°„ ë‰´ìŠ¤ ê¸°ë°˜ ë¶„ì„(í‚¤ ì…ë ¥ ì‹œ)
#   - ë²ˆì—­ API: DeepL / Papago(í‚¤ ì…ë ¥ ì‹œ) â†’ ë‹¤êµ­ì–´ ê²°ê³¼ ì œê³µ
#
# âœ… ì‹¬í™” B. UX/ê¸°ëŠ¥ ê³ ë„í™”
#   - ì‚¬ìš©ì ì…ë ¥/ê²°ê³¼ íˆìŠ¤í† ë¦¬ ì €ì¥(ì„¸ì…˜) + ì„ íƒ/ë³µì›
#   - ê²°ê³¼ ë‚´ë³´ë‚´ê¸°: JSON + PDF(ReportLab)
#   - ë°ì´í„° ì‹œê°í™” ëŒ€ì‹œë³´ë“œ(ê¸°ì¡´ ì°¨íŠ¸ + ì™¸ë¶€ ë°ì´í„° ìœ„ì ¯)
#   - ë‹¤êµ­ì–´ ì§€ì›(ko/en) + ë²ˆì—­ API ì—°ë™(ì„ íƒ)
#
# ì‹¤í–‰:
#   streamlit run app.py
#
# í•„ìš” íŒ¨í‚¤ì§€:
#   pip install streamlit pandas altair requests reportlab
#
# ---------------------------------------------------------

from __future__ import annotations

import io
import json
from dataclasses import dataclass
from datetime import date
from typing import Any, Dict, List, Optional, Tuple

import altair as alt
import pandas as pd
import requests
import streamlit as st
from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas

# =========================================================
# Page Config + Styling
# =========================================================
st.set_page_config(page_title="ğŸ§­ Y-Compass", page_icon="ğŸ§­", layout="wide")

st.markdown(
    """
<style>
.badge { display:inline-block; padding:0.25rem 0.6rem; border-radius:999px; font-weight:700; font-size:0.9rem;
         line-height:1.2rem; border:1px solid rgba(0,0,0,0.08); }
.badge-data { background:rgba(16,185,129,0.14); color:rgb(6,95,70); }
.badge-guide{ background:rgba(245,158,11,0.18); color:rgb(120,53,15); }
.badge-stable{ background:rgba(59,130,246,0.14); color:rgb(30,64,175); }
.badge-fit{ background:rgba(168,85,247,0.14); color:rgb(88,28,135); }
.badge-challenge{ background:rgba(239,68,68,0.14); color:rgb(153,27,27); }

.card-title{ font-weight:800; margin-bottom:0.2rem; }
.small{ color:rgba(0,0,0,0.6); font-size:0.92rem; }
.mono{ font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace; }
</style>
""",
    unsafe_allow_html=True,
)

# =========================================================
# i18n (UI ìµœì†Œ ì§€ì›: ko/en)
# =========================================================
I18N = {
    "ko": {
        "app_title": "ğŸ§­ Y-Compass (ì™€ì´ì»´í¼ìŠ¤)",
        "subtitle": "ì—°ì„¸ëŒ€ AX ìº í”„ Track 1 â€” ì†Œê·¸ë£¹ ì±Œë¦°ì§€ | ê·¼ê±° ê¸°ë°˜ AI ì§„í•™ ì¹´ìš´ì…€ëŸ¬ (MVP++)",
        "policy": "âš ï¸ í™˜ê° ë°©ì§€ ì •ì±…: ë³¸ ì•±ì€ ì—…ë¡œë“œëœ CSV/ê·¼ê±°(expander)ì— ì—†ëŠ” ìˆ˜ì¹˜Â·ìš”ê°•ì„ 'ì‚¬ì‹¤'ë¡œ ë‹¨ì •í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì»¤ë²„ë¦¬ì§€ ë°–ì—ì„œëŠ” 'ì¼ë°˜ ê°€ì´ë“œ'ë¡œë§Œ ì•ˆë‚´í•˜ë©°, í•©ê²© í™•ë¥ /ë³´ì¥ í‘œí˜„ì„ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
        "data_based": "ë°ì´í„° ê¸°ë°˜ âœ…",
        "guide_based": "ê°€ì´ë“œ ê¸°ë°˜ ğŸŸ¡",
        "stable": "ì•ˆì •",
        "fit": "ì ì •",
        "challenge": "ë„ì „",
        "export_pdf": "ğŸ“„ ê²°ê³¼ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ (PDF)",
        "export_json": "ğŸ“„ ê²°ê³¼ ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ (.json)",
    },
    "en": {
        "app_title": "ğŸ§­ Y-Compass",
        "subtitle": "Yonsei AX Camp Track 1 â€” Small-group Challenge | Evidence-aware AI Admissions Counselor (MVP++)",
        "policy": "âš ï¸ Anti-hallucination policy: This app does NOT assert numbers/rules as facts unless they exist in uploaded CSV/evidence. Outside coverage, it provides general guidance only. No acceptance probability/guarantee language.",
        "data_based": "Data-backed âœ…",
        "guide_based": "Guide-based ğŸŸ¡",
        "stable": "Safe",
        "fit": "Fit",
        "challenge": "Reach",
        "export_pdf": "ğŸ“„ Download Report (PDF)",
        "export_json": "ğŸ“„ Download Report (.json)",
    },
}


def t(key: str, lang: str) -> str:
    return I18N.get(lang, I18N["ko"]).get(key, key)


# =========================================================
# Options
# =========================================================
ADMISSION_ROUTE = ["ìˆ˜ì‹œ", "ì •ì‹œ"]
SUSI_DETAIL = ["í•™ìƒë¶€êµê³¼", "í•™ìƒë¶€ì¢…í•©", "ë…¼ìˆ ", "íŠ¹ê¸°ì(í•´ë‹¹ ì‹œ)"]
MAJOR_GROUPS = ["ì¸ë¬¸", "ì‚¬íšŒ", "ìƒê²½", "ìì—°", "ê³µí•™", "ì˜ˆì²´ëŠ¥", "ìœµí•©/ììœ ì „ê³µ"]
ACTIVITY_PREF = ["ì‚¬ëŒ(ì†Œí†µ/ë¦¬ë”ì‹­)", "ë°ì´í„°(ë¶„ì„/ì •ëŸ‰)", "ê¸€(ì—ì„¸ì´/ìŠ¤í† ë¦¬)", "í˜„ì¥(í™œë™/í”„ë¡œì íŠ¸)"]
GOAL_PRIORITY = ["í•©ê²© ì•ˆì •ì„±", "ì ì„±/í¥ë¯¸", "ì·¨ì—…/ì§„ë¡œ ì—°ê³„", "ì¥í•™/ë¹„ìš©", "ì§€ì—­/ìƒí™œí™˜ê²½"]
CONSTRAINTS = ["ì§€ì—­(í†µí•™/ê±°ì£¼)", "ì˜ˆì‚°(ë¹„ìš©)", "ì‹œê°„(ë³‘í–‰ ì¼ì •)", "ê°€ì¡±/ëŒë´„", "ê¸°íƒ€"]
CURRENT_STAGE = ["ë‚´ì‹ /ìˆ˜ëŠ¥ ì¤€ë¹„", "ìê¸°ì†Œê°œì„œ/í•™ìƒë¶€ ì •ë¦¬", "ë©´ì ‘ ì¤€ë¹„", "ë…¼ìˆ  ì¤€ë¹„", "ì§€ì›ì „ëµ ìµœì¢… ì ê²€"]
EXTRACURRICULAR_LEVELS = ["ë‚®ìŒ", "ë³´í†µ", "ë†’ìŒ"]

CSV_REQUIRED_COLS = ["university", "major", "route", "year", "metric", "threshold"]
CSV_OPTIONAL_COLS = ["route_detail", "source", "note"]


# =========================================================
# Utilities
# =========================================================
def _nonempty(s: Optional[str]) -> str:
    return s.strip() if isinstance(s, str) and s.strip() else ""


def safe_int(x: Any) -> Optional[int]:
    try:
        return int(x)
    except Exception:
        return None


def safe_float(x: Any) -> Optional[float]:
    try:
        v = float(x)
        if pd.isna(v):
            return None
        return v
    except Exception:
        return None


def band_to_float(band: str) -> Optional[float]:
    band = _nonempty(band)
    if not band or "ëª¨ë¦„" in band:
        return None
    if band.endswith(".x"):
        try:
            return float(band.replace(".x", "")) + 0.5
        except Exception:
            return None
    try:
        return float(band)
    except Exception:
        return None


def clamp(v: float, lo: float, hi: float) -> float:
    return max(lo, min(v, hi))


def coverage_badge_html(is_data_based: bool, lang: str) -> str:
    if is_data_based:
        return f'<span class="badge badge-data">{t("data_based", lang)}</span>'
    return f'<span class="badge badge-guide">{t("guide_based", lang)}</span>'


def band_badge_html(band: str, lang: str) -> str:
    band = _nonempty(band)
    if band == "ì•ˆì •":
        return f'<span class="badge badge-stable">{t("stable", lang)}</span>'
    if band == "ì ì •":
        return f'<span class="badge badge-fit">{t("fit", lang)}</span>'
    return f'<span class="badge badge-challenge">{t("challenge", lang)}</span>'


# =========================================================
# External APIs (ì‹¬í™” A)
# =========================================================
@st.cache_data(show_spinner=False, ttl=60 * 15)
def fetch_weather_openweather(api_key: str, city: str, units: str = "metric", lang: str = "kr") -> Dict[str, Any]:
    """
    OpenWeatherMap Current Weather API
    https://openweathermap.org/current
    """
    api_key = _nonempty(api_key)
    city = _nonempty(city)
    if not api_key or not city:
        return {"ok": False, "error": "missing_key_or_city"}

    url = "https://api.openweathermap.org/data/2.5/weather"
    params = {"q": city, "appid": api_key, "units": units, "lang": lang}
    r = requests.get(url, params=params, timeout=20)
    if r.status_code != 200:
        return {"ok": False, "error": f"HTTP {r.status_code}", "raw": r.text[:500]}
    data = r.json()
    return {"ok": True, "data": data}


@st.cache_data(show_spinner=False, ttl=60 * 15)
def fetch_news_newsapi(api_key: str, q: str, language: str = "ko", page_size: int = 8) -> Dict[str, Any]:
    """
    NewsAPI Everything endpoint
    https://newsapi.org/docs/endpoints/everything
    """
    api_key = _nonempty(api_key)
    q = _nonempty(q)
    if not api_key or not q:
        return {"ok": False, "error": "missing_key_or_query"}

    url = "https://newsapi.org/v2/everything"
    params = {
        "q": q,
        "language": language,
        "pageSize": page_size,
        "sortBy": "publishedAt",
        "apiKey": api_key,
    }
    r = requests.get(url, params=params, timeout=20)
    if r.status_code != 200:
        return {"ok": False, "error": f"HTTP {r.status_code}", "raw": r.text[:500]}
    data = r.json()
    return {"ok": True, "data": data}


@st.cache_data(show_spinner=False, ttl=60 * 60)
def translate_deepl(api_key: str, text: str, target_lang: str = "EN") -> Dict[str, Any]:
    """
    DeepL translate API
    https://www.deepl.com/docs-api
    - free endpoint: https://api-free.deepl.com/v2/translate
    - pro endpoint:  https://api.deepl.com/v2/translate
    """
    api_key = _nonempty(api_key)
    text = _nonempty(text)
    if not api_key or not text:
        return {"ok": False, "error": "missing_key_or_text"}

    url = "https://api-free.deepl.com/v2/translate"
    headers = {"Authorization": f"DeepL-Auth-Key {api_key}"}
    data = {"text": text, "target_lang": target_lang}
    r = requests.post(url, headers=headers, data=data, timeout=25)
    if r.status_code != 200:
        return {"ok": False, "error": f"HTTP {r.status_code}", "raw": r.text[:500]}
    j = r.json()
    out = (j.get("translations") or [{}])[0].get("text", "")
    return {"ok": True, "text": out}


@st.cache_data(show_spinner=False, ttl=60 * 60)
def translate_papago(
    client_id: str, client_secret: str, text: str, source: str = "ko", target: str = "en"
) -> Dict[str, Any]:
    """
    Naver Papago NMT API (requires client_id + client_secret)
    https://developers.naver.com/docs/papago/papago-nmt-overview.md
    """
    client_id = _nonempty(client_id)
    client_secret = _nonempty(client_secret)
    text = _nonempty(text)
    if not client_id or not client_secret or not text:
        return {"ok": False, "error": "missing_credentials_or_text"}

    url = "https://openapi.naver.com/v1/papago/n2mt"
    headers = {"X-Naver-Client-Id": client_id, "X-Naver-Client-Secret": client_secret}
    data = {"source": source, "target": target, "text": text}
    r = requests.post(url, headers=headers, data=data, timeout=25)
    if r.status_code != 200:
        return {"ok": False, "error": f"HTTP {r.status_code}", "raw": r.text[:500]}
    j = r.json()
    out = j.get("message", {}).get("result", {}).get("translatedText", "")
    return {"ok": True, "text": out}


def weather_micro_advice(weather_json: Dict[str, Any], lang: str = "ko") -> str:
    """
    ì™¸ë¶€ API ë°ì´í„° ê¸°ë°˜ 'ë§ˆì´í¬ë¡œ ì¡°ì–¸' (ë£° ê¸°ë°˜)
    """
    try:
        w = weather_json["weather"][0]["main"].lower()
        desc = weather_json["weather"][0].get("description", "")
        temp = weather_json["main"].get("temp")
        feels = weather_json["main"].get("feels_like")
        hum = weather_json["main"].get("humidity")
        wind = weather_json["wind"].get("speed")
    except Exception:
        return "ë‚ ì”¨ ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨(ì‘ë‹µ êµ¬ì¡° í™•ì¸ í•„ìš”)."

    if lang == "en":
        tips = []
        tips.append(f"Weather: {desc} | Temp {temp}Â°C (feels {feels}Â°C), humidity {hum}%, wind {wind} m/s.")
        if "rain" in w or "drizzle" in w or "thunderstorm" in w:
            tips.append("Plan: choose an indoor study spot + allow commute buffer; keep devices/notes protected.")
        elif "snow" in w:
            tips.append("Plan: add extra commute time; prioritize online tasks (drafting, reviewing) over errands.")
        elif "clear" in w:
            tips.append("Plan: do one outdoor walk break; keep long-focus blocks (50â€“10) for writing and drills.")
        elif "cloud" in w or "mist" in w or "fog" in w:
            tips.append("Plan: start with quick wins (10â€“15 min) to beat low-energy vibes; then ramp up.")
        if temp is not None and temp >= 30:
            tips.append("Heat: hydrate + reduce high-cognitive load tasks during peak daytime; do them in the evening.")
        if temp is not None and temp <= 0:
            tips.append("Cold: warm-up routine (5 min) before deep work; keep hands warm for typing/writing.")
        return " ".join(tips)

    tips = []
    tips.append(f"ë‚ ì”¨: {desc} | ê¸°ì˜¨ {temp}Â°C(ì²´ê° {feels}Â°C), ìŠµë„ {hum}%, ë°”ëŒ {wind}m/s.")
    if "rain" in w or "drizzle" in w or "thunderstorm" in w:
        tips.append("ì¶”ì²œ: ì‹¤ë‚´ ì§‘ì¤‘ ê³¼ì œ(ìì†Œì„œ/ì˜¤ë‹µì •ë¦¬)ë¡œ ê°€ê³ , ì´ë™ ì‹œê°„ ë²„í¼ + ì¤€ë¹„ë¬¼ ë°©ìˆ˜.")
    elif "snow" in w:
        tips.append("ì¶”ì²œ: ì´ë™ ë¦¬ìŠ¤í¬â†‘ â†’ ì˜¨ë¼ì¸/ì§‘ì¤‘í˜• ì‘ì—… ìœ„ì£¼(ì›ì„œ ì²´í¬ë¦¬ìŠ¤íŠ¸/ë¡œë“œë§µ ì ê²€).")
    elif "clear" in w:
        tips.append("ì¶”ì²œ: ì‚°ì±… 10ë¶„ìœ¼ë¡œ ë¦¬í”„ë ˆì‹œí•˜ê³ , ê¸´ ì§‘ì¤‘ ë¸”ë¡(50â€“10)ìœ¼ë¡œ ê¸€/ë¬¸í’€ ëª°ì•„ì¹˜ê¸°.")
    elif "cloud" in w or "mist" in w or "fog" in w:
        tips.append("ì¶”ì²œ: ì»¨ë””ì…˜ ì• ë§¤í•˜ë©´ 10ë¶„ 'ì‹œë™' ì‘ì—…(ìš”ì•½/ì •ë¦¬)â†’ ê·¸ ë‹¤ìŒ ë”¥ì›Œí¬ë¡œ ì§„ì….")
    if temp is not None and temp >= 30:
        tips.append("í­ì—¼: ìˆ˜ë¶„/ì¹´í˜ì¸ ì¡°ì ˆ, ê³ ë‚œë„ ì‘ì—…ì€ ì €ë…ìœ¼ë¡œ ë¯¸ë£¨ê¸°.")
    if temp is not None and temp <= 0:
        tips.append("í•œíŒŒ: ì›Œë°ì—… 5ë¶„ í›„ ë”¥ì›Œí¬, ì† ì‹œë¦¼ ëŒ€ë¹„.")
    return " ".join(tips)


# =========================================================
# CSV Auto Validation Report + Data Trust Score
# =========================================================
def csv_validation_report(df_raw: pd.DataFrame) -> Dict[str, Any]:
    rep: Dict[str, Any] = {"ok": True, "issues": [], "stats": {}}

    if df_raw is None or df_raw.empty:
        rep["ok"] = False
        rep["issues"].append("CSVê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        return rep

    cols = [c.strip().lower() for c in df_raw.columns]
    rep["stats"]["n_rows_raw"] = int(len(df_raw))
    rep["stats"]["n_cols_raw"] = int(len(cols))

    missing_required = [c for c in CSV_REQUIRED_COLS if c not in cols]
    rep["stats"]["missing_required"] = missing_required
    if missing_required:
        rep["ok"] = False
        rep["issues"].append(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_required}")

    key_cols = [c for c in ["university", "major", "route", "route_detail", "year", "metric"] if c in cols]
    if key_cols:
        tmp = df_raw.copy()
        tmp.columns = cols
        dup_cnt = int(tmp.duplicated(subset=key_cols, keep=False).sum())
        rep["stats"]["duplicates_by_key"] = dup_cnt
        if dup_cnt > 0:
            rep["issues"].append(f"ì¤‘ë³µ í–‰ ê°ì§€: {dup_cnt} (í‚¤={key_cols})")
    else:
        rep["stats"]["duplicates_by_key"] = None

    tmp2 = df_raw.copy()
    tmp2.columns = cols

    if "year" in cols:
        y = tmp2["year"].apply(safe_int)
        bad_year = int(((y.isna()) | (y < 2000) | (y > 2100)).sum())
        rep["stats"]["bad_year_rows"] = bad_year
        if bad_year > 0:
            rep["issues"].append(f"ì—°ë„ ì´ìƒì¹˜/ê²°ì¸¡: {bad_year}")

    if "threshold" in cols:
        th = tmp2["threshold"].apply(safe_float)
        bad_th = int(((th.isna()) | (th <= 0) | (th >= 10)).sum())
        rep["stats"]["bad_threshold_rows"] = bad_th
        if bad_th > 0:
            rep["issues"].append(f"threshold ì´ìƒì¹˜/ê²°ì¸¡: {bad_th}")

    if "route" in cols and "route_detail" in cols:
        r = tmp2["route"].astype(str).str.strip()
        rd = tmp2["route_detail"].astype(str).fillna("").str.strip()
        susi_rows = (r == "ìˆ˜ì‹œ").sum()
        susi_with_detail = int(((r == "ìˆ˜ì‹œ") & (rd != "")).sum())
        rep["stats"]["susi_rows"] = int(susi_rows)
        rep["stats"]["susi_route_detail_filled"] = susi_with_detail
        rep["stats"]["route_detail_coverage_susi"] = (susi_with_detail / susi_rows) if susi_rows else None
        if susi_rows and (susi_with_detail / susi_rows) < 0.6:
            rep["issues"].append("ìˆ˜ì‹œ route_detail ì»¤ë²„ë¦¬ì§€ê°€ ë‚®ìŒ(<60%): ì„¸ë¶€ ê²½ë¡œ ì ìˆ˜ ë¶„ë¦¬ ì‹ ë¢°ë„â†“")

    rep["ok"] = rep["ok"] and (len(rep["issues"]) == 0)
    return rep


def data_trust_score(df_norm: pd.DataFrame, report: Dict[str, Any]) -> Tuple[int, List[str]]:
    score = 100
    reasons: List[str] = []

    if df_norm is None or df_norm.empty:
        return 0, ["ì •ê·œí™”ëœ ë°ì´í„°ê°€ ì—†ìŒ(ê°€ì´ë“œ ê¸°ë°˜ ëª¨ë“œ)"]

    n = len(df_norm)
    years = df_norm["year"].nunique() if "year" in df_norm.columns else 0

    if n < 30:
        score -= 18
        reasons.append("ë°ì´í„° rows < 30 (í‘œë³¸ ì ìŒ)")
    elif n < 100:
        score -= 8
        reasons.append("ë°ì´í„° rows < 100 (í‘œë³¸ ì¤‘ê°„)")

    if years < 3:
        score -= 15
        reasons.append("ì—°ë„ ë‹¤ì–‘ì„± < 3 (ì¶”ì„¸/ê¸°ì¤€ì„  ì•ˆì •ì„±â†“)")
    elif years < 5:
        score -= 6
        reasons.append("ì—°ë„ ë‹¤ì–‘ì„± < 5")

    dup = report.get("stats", {}).get("duplicates_by_key")
    if isinstance(dup, int) and dup > 0:
        score -= min(15, dup // 10 + 5)
        reasons.append(f"ì¤‘ë³µ í–‰ ì¡´ì¬({dup})")

    bad_year = report.get("stats", {}).get("bad_year_rows", 0)
    bad_th = report.get("stats", {}).get("bad_threshold_rows", 0)
    if isinstance(bad_year, int) and bad_year > 0:
        score -= min(10, bad_year // 10 + 3)
        reasons.append(f"ì—°ë„ ì´ìƒì¹˜/ê²°ì¸¡({bad_year})")
    if isinstance(bad_th, int) and bad_th > 0:
        score -= min(15, bad_th // 10 + 5)
        reasons.append(f"threshold ì´ìƒì¹˜/ê²°ì¸¡({bad_th})")

    cov = report.get("stats", {}).get("route_detail_coverage_susi")
    if isinstance(cov, float):
        if cov < 0.6:
            score -= 15
            reasons.append("ìˆ˜ì‹œ route_detail ì»¤ë²„ë¦¬ì§€ ë‚®ìŒ(<60%)")
        elif cov < 0.8:
            score -= 6
            reasons.append("ìˆ˜ì‹œ route_detail ì»¤ë²„ë¦¬ì§€ ë³´í†µ(<80%)")

    score = int(clamp(float(score), 0.0, 100.0))
    if score >= 90:
        reasons = ["ì •í•©ì„±/ì»¤ë²„ë¦¬ì§€ ì–‘í˜¸"] + reasons[:2]
    return score, reasons


# =========================================================
# Data Handling: CSV -> normalized dataframe
# =========================================================
def normalize_df(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    df.columns = [c.strip().lower() for c in df.columns]

    missing = [c for c in CSV_REQUIRED_COLS if c not in df.columns]
    if missing:
        raise ValueError(f"CSVì— í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë¨: {missing}")

    for c in CSV_OPTIONAL_COLS:
        if c not in df.columns:
            df[c] = ""

    df["university"] = df["university"].astype(str).str.strip()
    df["major"] = df["major"].astype(str).str.strip()
    df["route"] = df["route"].astype(str).str.strip()
    df["route_detail"] = df["route_detail"].astype(str).str.strip()
    df["metric"] = df["metric"].astype(str).str.strip().str.lower()

    df["year"] = df["year"].apply(safe_int)
    df["threshold"] = df["threshold"].apply(safe_float)

    df["source"] = df["source"].astype(str).str.strip()
    df["note"] = df["note"].astype(str).str.strip()

    df = df.dropna(subset=["year", "threshold"])
    df = df[df["metric"].isin(["gpa", "mock"])]

    df["route"] = df["route"].replace({"ìˆ˜ì‹œ ": "ìˆ˜ì‹œ", "ì •ì‹œ ": "ì •ì‹œ"})
    df = df[df["route"].isin(["ìˆ˜ì‹œ", "ì •ì‹œ"])]

    df = df[(df["threshold"] > 0) & (df["threshold"] < 10)]
    return df


def _major_match(mj_input: str, mj_row: str) -> bool:
    mj_input = _nonempty(mj_input)
    mj_row = _nonempty(mj_row)
    if not mj_input or not mj_row:
        return True
    return (mj_input in mj_row) or (mj_row in mj_input)


def match_rows(
    df: pd.DataFrame,
    university: str,
    major_text: str,
    route: str,
    route_detail: str,
    metric: str,
    max_rows: int = 200,
) -> pd.DataFrame:
    if df is None or df.empty:
        return df

    uni = _nonempty(university)
    mj = _nonempty(major_text)

    sub = df[df["university"] == uni]
    if mj:
        sub = sub[sub["major"].apply(lambda x: _major_match(mj, str(x)))]

    sub = sub[sub["route"] == route]
    sub = sub[sub["metric"] == metric]

    if route == "ìˆ˜ì‹œ":
        rd = _nonempty(route_detail)
        if rd:
            exact = sub[sub["route_detail"] == rd]
            generic = sub[sub["route_detail"] == ""]
            sub = pd.concat([exact, generic], ignore_index=True).drop_duplicates()

    sub = sub.sort_values("year", ascending=True).head(max_rows)
    return sub


# =========================================================
# Explainable Scoring
# =========================================================
@dataclass
class ScoreWeights:
    academics: float
    extracurricular: float
    constraints: float
    preference_fit: float


def extracurricular_score(level: str) -> float:
    return {"ë‚®ìŒ": 20.0, "ë³´í†µ": 60.0, "ë†’ìŒ": 90.0}.get(level, 60.0)


def constraints_penalty(constraints: List[str]) -> float:
    p = 0.0
    for c in constraints:
        if "ì‹œê°„" in c:
            p += 18
        elif "ì˜ˆì‚°" in c:
            p += 15
        elif "ì§€ì—­" in c:
            p += 12
        else:
            p += 10
    return min(p, 45.0)


def preference_fit_score(activity_pref: List[str], route: str, route_detail: str) -> float:
    s = 50.0
    pref = " ".join(activity_pref)

    if route == "ì •ì‹œ":
        if "ë°ì´í„°" in pref:
            s += 25
        if "ê¸€" in pref:
            s += 5
        if "ì‚¬ëŒ" in pref:
            s += 5

    if route == "ìˆ˜ì‹œ":
        if "í•™ìƒë¶€ì¢…í•©" in route_detail:
            if "ê¸€" in pref:
                s += 20
            if "í˜„ì¥" in pref:
                s += 15
            if "ì‚¬ëŒ" in pref:
                s += 10
        elif "í•™ìƒë¶€êµê³¼" in route_detail:
            if "ë°ì´í„°" in pref:
                s += 20
        elif "ë…¼ìˆ " in route_detail:
            if "ê¸€" in pref:
                s += 20
            if "ë°ì´í„°" in pref:
                s += 10

    return clamp(s, 0.0, 100.0)


def academics_score(user_value: Optional[float], ref_series: Optional[pd.Series]) -> Tuple[float, str, Optional[float]]:
    if user_value is None:
        return 50.0, "ì„±ì  ì…ë ¥ì´ ì—†ì–´ í•™ì—… ì ìˆ˜ëŠ” ì¤‘ë¦½(50)ìœ¼ë¡œ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.", None

    if ref_series is None or ref_series.empty:
        s = 100.0 - (user_value - 1.0) * 15.0
        s = clamp(s, 10.0, 90.0)
        return s, "ë°ì´í„° ì»¤ë²„ë¦¬ì§€ ë°–ì´ë¼ ì ˆëŒ€ê°’ ê¸°ë°˜(ê±°ì¹œ) ì ìˆ˜ë¡œ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.", None

    anchor = float(ref_series.dropna().iloc[-1])
    diff = user_value - anchor

    if diff <= -0.2:
        s = 90.0
        msg = f"ì…ë ¥ ì„±ì ({user_value:.1f})ì´ ìµœê·¼ ê¸°ì¤€ì„ ({anchor:.1f})ë³´ë‹¤ ìœ ë¦¬ â†’ í•™ì—… ì ìˆ˜â†‘"
    elif diff <= 0.4:
        s = 65.0
        msg = f"ì…ë ¥ ì„±ì ({user_value:.1f})ì´ ìµœê·¼ ê¸°ì¤€ì„ ({anchor:.1f}) ê·¼ì²˜ â†’ í•™ì—… ì ìˆ˜ ì¤‘ê°„"
    else:
        s = 35.0
        msg = f"ì…ë ¥ ì„±ì ({user_value:.1f})ì´ ìµœê·¼ ê¸°ì¤€ì„ ({anchor:.1f})ë³´ë‹¤ ë¶ˆë¦¬ â†’ í•™ì—… ì ìˆ˜â†“"

    return s, msg, anchor


def normalize_weights(w: ScoreWeights) -> ScoreWeights:
    s = w.academics + w.extracurricular + w.constraints + w.preference_fit
    if s <= 0:
        return ScoreWeights(0.45, 0.25, 0.2, 0.1)
    return ScoreWeights(w.academics / s, w.extracurricular / s, w.constraints / s, w.preference_fit / s)


def total_score(w: ScoreWeights, acad: float, extra: float, penalty: float, fit: float) -> Tuple[float, Dict[str, float]]:
    wn = normalize_weights(w)

    contrib_acad = acad * wn.academics
    contrib_extra = extra * wn.extracurricular
    contrib_fit = fit * wn.preference_fit
    contrib_penalty = penalty * wn.constraints

    score = contrib_acad + contrib_extra + contrib_fit - contrib_penalty
    score = clamp(score, 0.0, 100.0)

    breakdown = {
        "í•™ì—…(ì„±ì )": contrib_acad,
        "ë¹„êµê³¼": contrib_extra,
        "ì í•©ë„(ì„±í–¥â†”ì „í˜•)": contrib_fit,
        "ì œì•½(ê°ì )": -contrib_penalty,
        "ì´ì ": score,
    }
    return score, breakdown


def score_to_band(score: float) -> str:
    if score >= 75:
        return "ì•ˆì •"
    if score >= 55:
        return "ì ì •"
    return "ë„ì „"


def abc_scores(base_score: float, constraints: List[str], priorities: List[str]) -> Dict[str, Dict[str, Any]]:
    n_constraints = len(constraints)
    risk_factor = clamp(n_constraints / 4.0, 0.0, 1.0)  # 0~1

    p = " ".join(priorities or [])

    a_nudge = 2.0 if "í•©ê²© ì•ˆì •ì„±" in p else 0.0
    b_nudge = 1.5 if "ì ì„±/í¥ë¯¸" in p else 0.0
    c_nudge = 1.5 if "ì·¨ì—…/ì§„ë¡œ ì—°ê³„" in p else 0.0

    a = base_score + 8.0 + (risk_factor * 4.0) + a_nudge
    b = base_score + 0.0 + b_nudge
    c = base_score - 10.0 - (risk_factor * 5.0) + c_nudge

    out = {
        "A": {"label": "ì•ˆì •", "score": clamp(a, 0, 100)},
        "B": {"label": "ì ì •", "score": clamp(b, 0, 100)},
        "C": {"label": "ë„ì „", "score": clamp(c, 0, 100)},
    }
    for k in out:
        out[k]["band"] = score_to_band(out[k]["score"])
    return out


def abc_scores_by_route_detail(
    base_score: float, constraints: List[str], priorities: List[str], route: str, route_detail: str
) -> Dict[str, Any]:
    abc = abc_scores(base_score, constraints, priorities)

    if route != "ìˆ˜ì‹œ":
        return {"selected_route_detail": "", "variants": {"(ì •ì‹œ/ê³µí†µ)": abc}}

    rd = _nonempty(route_detail)
    variants: Dict[str, Dict[str, Any]] = {}

    def adj(abc_in: Dict[str, Dict[str, Any]], a=0.0, b=0.0, c=0.0) -> Dict[str, Dict[str, Any]]:
        out = {k: dict(v) for k, v in abc_in.items()}
        out["A"]["score"] = clamp(out["A"]["score"] + a, 0, 100)
        out["B"]["score"] = clamp(out["B"]["score"] + b, 0, 100)
        out["C"]["score"] = clamp(out["C"]["score"] + c, 0, 100)
        for kk in out:
            out[kk]["band"] = score_to_band(out[kk]["score"])
        return out

    variants["(ê³µí†µ)"] = abc
    variants["í•™ìƒë¶€ì¢…í•©"] = adj(abc, a=-2, b=0, c=-4)
    variants["í•™ìƒë¶€êµê³¼"] = adj(abc, a=+3, b=+1, c=-2)
    variants["ë…¼ìˆ "] = adj(abc, a=-2, b=0, c=+3)

    picked = "(ê³µí†µ)"
    for k in ["í•™ìƒë¶€ì¢…í•©", "í•™ìƒë¶€êµê³¼", "ë…¼ìˆ "]:
        if k in rd:
            picked = k
            break

    return {"selected_route_detail": picked, "variants": variants}


# =========================================================
# OpenAI Responses API (optional)
# =========================================================
def openai_generate_plan(api_key: str, model: str, payload_json: Dict[str, Any], context_docs: List[Dict[str, str]]) -> Dict[str, Any]:
    url = "https://api.openai.com/v1/responses"
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}

    prompt = f"""
ë„ˆëŠ” 'ëŒ€í•™ ì§„í•™ AI ì»¨ì„¤í„´íŠ¸'ë‹¤.

ì›ì¹™(ë§¤ìš° ì¤‘ìš”):
- ì‚¬ìš©ìê°€ ì„ íƒ/ì…ë ¥í•œ ì „í˜•ì„ ìš°ì„  ì¡´ì¤‘í•˜ë˜, ê°€ëŠ¥ì„±/ë¦¬ìŠ¤í¬/ëŒ€ì•ˆê¹Œì§€ í•¨ê»˜ ì œì‹œí•˜ë¼.
- ì‚¬ì‹¤(ì „í˜•ìš”ê°•/ë°ì´í„°)ì€ ì•„ë˜ [ê·¼ê±° ë¬¸ì„œ]ì— ìˆëŠ” ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ë¼.
- ê·¼ê±° ë¬¸ì„œì— ì—†ëŠ” ìˆ˜ì¹˜/ì‚¬ì‹¤ì€ ë‹¨ì •í•˜ì§€ ë§ê³  "ì¼ë°˜ ê°€ì´ë“œ"ë¡œ í‘œí˜„í•˜ë¼.
- í™•ë¥  ë‹¨ì • ê¸ˆì§€. ëŒ€ì‹  ì•ˆì •/ì ì •/ë„ì „ êµ¬ê°„ìœ¼ë¡œ í‘œí˜„í•˜ë¼.
- 8ì£¼ ë¡œë“œë§µì€ ì‚¬ìš©ìê°€ ì„ íƒí•œ ì „í˜•ê³¼ í˜„ì¬ ë‹¨ê³„(ì…ë ¥ê°’)ë¥¼ ê³ ë ¤í•´
  "ì£¼ì°¨ë³„ í•µì‹¬ ëª©í‘œ 1ê°œ + í•  ì¼ 2~3ê°œ + ì‚°ì¶œë¬¼ 1ê°œ"ë¡œ êµ¬ì¡°í™”í•˜ë¼.

ì¶œë ¥ì€ ë°˜ë“œì‹œ ì•„ë˜ JSON ìŠ¤í‚¤ë§ˆë¡œë§Œ ì‘ì„±í•˜ë¼(ë‹¤ë¥¸ ë¬¸ì¥ ê¸ˆì§€).

JSON ìŠ¤í‚¤ë§ˆ:
{{
  "summary_5lines": [string, string, string, string, string],
  "routes": {{
    "A": {{"title":"ì•ˆì •","reasons":[string,string,string],"actions":[string,string,string,string,string],"risks":[string,string]}},
    "B": {{"title":"ì ì •","reasons":[string,string,string],"actions":[string,string,string,string,string],"risks":[string,string]}},
    "C": {{"title":"ë„ì „","reasons":[string,string,string],"actions":[string,string,string,string,string],"risks":[string,string]}}
  }},
  "roadmap": [{{"week": number,"goal": string,"tasks":[string,string,string],"deliverable": string}}],
  "evidence": [{{"title": string,"note": string}}]
}}

[ì‚¬ìš©ì ì…ë ¥(JSON)]
{json.dumps(payload_json, ensure_ascii=False)}

[ê·¼ê±° ë¬¸ì„œ]
{json.dumps(context_docs, ensure_ascii=False)}
""".strip()

    body = {
        "model": model,
        "input": [{"role": "user", "content": [{"type": "input_text", "text": prompt}]}],
        "text": {"format": {"type": "json_object"}},
    }

    r = requests.post(url, headers=headers, json=body, timeout=75)
    r.raise_for_status()
    data = r.json()

    text_out = ""
    for out_item in data.get("output", []):
        for c in out_item.get("content", []):
            if c.get("type") in ("output_text", "text") and c.get("text"):
                text_out += c["text"]

    text_out = text_out.strip()
    if not text_out:
        raise ValueError("OpenAI ì‘ë‹µ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

    try:
        return json.loads(text_out)
    except json.JSONDecodeError:
        start = text_out.find("{")
        end = text_out.rfind("}")
        if start != -1 and end != -1 and end > start:
            return json.loads(text_out[start : end + 1])
        raise


# =========================================================
# Rule-based fallback
# =========================================================
def rule_based_plan(payload: Dict[str, Any]) -> Dict[str, Any]:
    route = payload.get("route", "ìˆ˜ì‹œ")
    route_detail = payload.get("route_detail", "")
    major_group = payload.get("major_group", "")
    band = payload.get("band_label", "ì ì •")

    summary = [
        f"í¬ë§ ì „í˜•ì€ '{route}{(' - ' + route_detail) if route_detail else ''}'ì´ë©°, ì…ë ¥ ì¡°ê±´ ê¸°ë°˜ êµ¬ê°„ì€ '{band}'ì…ë‹ˆë‹¤.",
        f"ê´€ì‹¬ ì „ê³µêµ°ì€ '{major_group}'ì´ê³ , ì„±í–¥/ì œì•½ì„ ì „í˜• íŠ¹ì„±ê³¼ ë§¤ì¹­í–ˆìŠµë‹ˆë‹¤.",
        "ë°ì´í„° ì»¤ë²„ë¦¬ì§€ ë‚´ì—ì„œëŠ” ì—°ë„/ì¶œì²˜ ê·¼ê±°ë¥¼ ì œì‹œí•˜ê³ , ë°–ì—ì„œëŠ” ì „ëµ ê°€ì´ë“œ(ì •ì„±)ë¡œ ì „í™˜í•©ë‹ˆë‹¤.",
        "ì¶”ì²œì€ ë‹¨ì •ì´ ì•„ë‹ˆë¼ A/B/C ë¹„êµ êµ¬ì¡°ë¡œ ì œê³µí•©ë‹ˆë‹¤.",
        "8ì£¼ ë¡œë“œë§µì€ ì „í˜•/í˜„ì¬ ë‹¨ê³„ ê¸°ì¤€ìœ¼ë¡œ ì£¼ì°¨ë³„ ëª©í‘œÂ·í•  ì¼Â·ì‚°ì¶œë¬¼ì„ ê³ ì • ì¶œë ¥í•©ë‹ˆë‹¤.",
    ]

    def mk_route(title: str) -> Dict[str, Any]:
        return {
            "title": title,
            "reasons": [
                "ì‚¬ìš©ì ì…ë ¥(ì„±ì /ì„±í–¥/ì œì•½)ê³¼ ì „í˜• íŠ¹ì„±ì˜ ì •í•©ì„±ì„ ê¸°ì¤€ìœ¼ë¡œ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.",
                "ë¶ˆí™•ì‹¤ ìš”ì†ŒëŠ” ë¦¬ìŠ¤í¬ë¡œ ë¶„ë¦¬í•˜ê³  ëŒ€ì•ˆì„ í•¨ê»˜ ì œì‹œí•©ë‹ˆë‹¤.",
                "ì‹¤í–‰ ê°€ëŠ¥ì„±ì„ ë†’ì´ê¸° ìœ„í•´ í•  ì¼ì„ ì•¡ì…˜ ë‹¨ìœ„ë¡œ ìª¼ê°°ìŠµë‹ˆë‹¤.",
            ],
            "actions": [
                "ì „í˜• ìš”ê±´ ì²´í¬ë¦¬ìŠ¤íŠ¸ ì‘ì„±(í•„ìˆ˜/ì„ íƒ ë¶„ë¦¬)",
                "í•µì‹¬ ìŠ¤í† ë¦¬ 3ê°œë¥¼ STARë¡œ ì •ë¦¬(í™œë™-ì—­í• -ì„±ê³¼-ë°°ì›€)",
                "ì§€ì› ì¡°í•© 3ê°œ(A/B/C)ë¡œ ë¶„ì‚° ì„¤ê³„",
                "ì£¼ 1íšŒ í”¼ë“œë°± ë£¨í”„(ì„ ìƒë‹˜/ì„ ë°°/AI)ë¡œ ìˆ˜ì •",
                "ë¦¬ìŠ¤í¬ ëŒ€ë¹„ ëŒ€ì•ˆ ì „í˜• 1ê°œ í™•ë³´",
            ],
            "risks": [
                "ë°ì´í„° ë²”ìœ„ ë°–ì—ì„œëŠ” ìˆ˜ì¹˜ ì˜ˆì¸¡ì„ ì œê³µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
                "ì „í˜•ë³„ ì‚°ì¶œë¬¼/ì¼ì •ì´ ì´‰ë°•í•´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            ],
        }

    routes = {"A": mk_route("ì•ˆì •"), "B": mk_route("ì ì •"), "C": mk_route("ë„ì „")}

    roadmap = []
    for w in range(1, 9):
        if route == "ì •ì‹œ":
            goal = "ì‹¤ì „ ì ìˆ˜ ì•ˆì •í™”" if w <= 3 else ("ì•½ì  ë³´ì™„ ì§‘ì¤‘" if w <= 6 else "ì‹¤ì „ ë£¨í‹´ ê³ ì •")
            tasks = ["ê¸°ì¶œ/ëª¨ì˜ 1íšŒë¶„ í’€ì´", "ì˜¤ë‹µ ì›ì¸ ë¶„ë¥˜(ê°œë…/ì‹œê°„/ì‹¤ìˆ˜)", "ì·¨ì•½ ë‹¨ì› 1ê°œ ë³´ì™„"]
            deliverable = f"Week {w}: ì˜¤ë‹µ ë¶„ë¥˜í‘œ + ì·¨ì•½ ë‹¨ì› ê³„íš"
        else:
            goal = "ì§€ì›ì „ëµ í™•ì •" if w <= 2 else ("ìì†Œì„œ/í™œë™ ì •ë¦¬" if w <= 5 else "ë©´ì ‘/ë…¼ìˆ  ëŒ€ë¹„")
            tasks = ["ì „í˜• ìš”ê°• ì²´í¬ + ì œì¶œë¬¼ ëª©ë¡í™”", "í™œë™ 3ê°œ STAR ì •ë¦¬", "ìì†Œì„œ/ë©´ì ‘ ì§ˆë¬¸ 5ê°œ ì´ˆì•ˆ ì‘ì„±"]
            deliverable = f"Week {w}: {route_detail or 'ìˆ˜ì‹œ'} ì‚°ì¶œë¬¼ 1ì¢… ì´ˆì•ˆ"
        roadmap.append({"week": w, "goal": goal, "tasks": tasks, "deliverable": deliverable})

    evidence = [{"title": "ì¼ë°˜ ì „ëµ ê°€ì´ë“œ", "note": "í‚¤ ë¯¸ì…ë ¥/ë°ì´í„° ë²”ìœ„ ë°– ì‹œ ë£°ë² ì´ìŠ¤ë¡œ ì œê³µ"}]
    return {"summary_5lines": summary, "routes": routes, "roadmap": roadmap, "evidence": evidence}


# =========================================================
# PDF Export (ì‹¬í™” B)
# =========================================================
def _wrap_text(text: str, max_len: int = 95) -> List[str]:
    text = text or ""
    lines: List[str] = []
    buf = ""
    for ch in text:
        buf += ch
        if len(buf) >= max_len and ch == " ":
            lines.append(buf.strip())
            buf = ""
    if buf.strip():
        lines.append(buf.strip())
    if not lines:
        return [""]
    return lines


def build_pdf_report_bytes(report: Dict[str, Any], title: str = "Y-Compass Report") -> bytes:
    buff = io.BytesIO()
    c = canvas.Canvas(buff, pagesize=A4)
    width, height = A4

    x = 40
    y = height - 50

    def draw_line(line: str, dy: int = 14, font: str = "Helvetica", size: int = 10):
        nonlocal y
        c.setFont(font, size)
        c.drawString(x, y, line[:1400])
        y -= dy
        if y < 60:
            c.showPage()
            y = height - 50

    c.setTitle(title)
    draw_line(title, dy=18, font="Helvetica-Bold", size=14)
    draw_line(f"Generated: {date.today().isoformat()}", dy=18, font="Helvetica", size=10)
    draw_line("")

    payload = report.get("payload", {})
    plan = {
        "summary_5lines": report.get("summary_5lines", []),
        "routes": report.get("routes", {}),
        "roadmap": report.get("roadmap", []),
        "evidence": report.get("evidence", []),
    }

    draw_line("[1] Key Summary", font="Helvetica-Bold", size=12)
    for s in plan.get("summary_5lines", [])[:5]:
        for ln in _wrap_text(f"- {s}", 105):
            draw_line(ln)
    draw_line("")

    draw_line("[2] Score Snapshot", font="Helvetica-Bold", size=12)
    draw_line(f"- Total Score: {payload.get('score_total')}")
    draw_line(f"- Band: {payload.get('band_label')}")
    draw_line(f"- Coverage: {'Data' if payload.get('coverage_is_data') else 'Guide'}")
    bd = payload.get("score_breakdown", {}) or {}
    draw_line(f"- Breakdown: {json.dumps(bd, ensure_ascii=False)}")
    draw_line("")

    draw_line("[3] A/B/C Routes", font="Helvetica-Bold", size=12)
    routes = plan.get("routes", {}) or {}
    for k in ["A", "B", "C"]:
        r = routes.get(k, {})
        draw_line(f"{k}. {r.get('title','')}", font="Helvetica-Bold", size=11)
        for s in (r.get("reasons") or [])[:3]:
            for ln in _wrap_text(f"  - Reason: {s}", 105):
                draw_line(ln)
        for s in (r.get("actions") or [])[:5]:
            for ln in _wrap_text(f"  - Action: {s}", 105):
                draw_line(ln)
        for s in (r.get("risks") or [])[:2]:
            for ln in _wrap_text(f"  - Risk: {s}", 105):
                draw_line(ln)
        draw_line("")

    draw_line("[4] 8-Week Roadmap", font="Helvetica-Bold", size=12)
    for item in (plan.get("roadmap") or [])[:8]:
        draw_line(f"Week {item.get('week')}: {item.get('goal','')}", font="Helvetica-Bold", size=11)
        for tsk in (item.get("tasks") or [])[:3]:
            for ln in _wrap_text(f"  - {tsk}", 105):
                draw_line(ln)
        draw_line(f"  - Deliverable: {item.get('deliverable','')}")
        draw_line("")

    draw_line("[5] Evidence (Sources)", font="Helvetica-Bold", size=12)
    for ev in (plan.get("evidence") or [])[:20]:
        draw_line(f"- {ev.get('title','')}")
        for ln in _wrap_text(f"  {ev.get('note','')}", 105):
            draw_line(ln)

    c.save()
    return buff.getvalue()


# =========================================================
# Session State (íˆìŠ¤í† ë¦¬ í¬í•¨)
# =========================================================
if "df_data" not in st.session_state:
    st.session_state.df_data = pd.DataFrame()
if "result" not in st.session_state:
    st.session_state.result = None
if "payload" not in st.session_state:
    st.session_state.payload = None
if "evidence" not in st.session_state:
    st.session_state.evidence = []
if "score_breakdown" not in st.session_state:
    st.session_state.score_breakdown = None
if "abc" not in st.session_state:
    st.session_state.abc = None
if "csv_report" not in st.session_state:
    st.session_state.csv_report = None
if "data_trust" not in st.session_state:
    st.session_state.data_trust = None
if "history" not in st.session_state:
    st.session_state.history = []  # list[dict]: {id, payload, result, report}


# =========================================================
# Header
# =========================================================
with st.sidebar:
    st.header("ğŸŒ Language / ì–¸ì–´")
    ui_lang = st.selectbox("UI Language", ["ko", "en"], index=0)

st.title(t("app_title", ui_lang))
st.caption(t("subtitle", ui_lang))


# =========================================================
# Sidebar (Keys + UX controls)
# =========================================================
with st.sidebar:
    st.header("ğŸ”‘ OpenAI (ì„ íƒ)")
    openai_key_default = st.secrets.get("OPENAI_API_KEY", "")
    openai_api_key = st.text_input("OpenAI API Key", value=openai_key_default, type="password", placeholder="sk-...")
    openai_model = st.text_input("ëª¨ë¸", value="gpt-4.1-mini")

    st.divider()
    st.header("ğŸŒ¦ï¸ OpenWeatherMap (ë‚ ì”¨ API)")
    owm_default = st.secrets.get("OPENWEATHER_API_KEY", "d37e79836cacd29a16ecdd370963270a")
    openweather_key = st.text_input("OpenWeatherMap API Key", value=owm_default, type="password")
    weather_city = st.text_input("ë„ì‹œ(ì˜ˆ: Seoul)", value="Seoul")

    st.divider()
    st.header("ğŸ“° NewsAPI (ë‰´ìŠ¤ API)")
    news_default = st.secrets.get("NEWS_API_KEY", "")
    news_api_key = st.text_input("NewsAPI Key", value=news_default, type="password")
    news_query = st.text_input("ë‰´ìŠ¤ í‚¤ì›Œë“œ(ì˜ˆ: ëŒ€í•™ì…ì‹œ OR êµìœ¡ì •ì±… OR ìˆ˜ëŠ¥)", value="ëŒ€í•™ì…ì‹œ OR êµìœ¡ì •ì±…")

    st.divider()
    st.header("ğŸŒ Translation API (ì„ íƒ)")
    translator = st.selectbox("ë²ˆì—­ ì—”ì§„", ["Off", "DeepL", "Papago"], index=0)
    deepl_key = ""
    papago_id = ""
    papago_secret = ""
    if translator == "DeepL":
        deepl_key = st.text_input("DeepL Auth Key", value=st.secrets.get("DEEPL_API_KEY", ""), type="password")
    elif translator == "Papago":
        papago_id = st.text_input("Papago Client ID", value=st.secrets.get("PAPAGO_CLIENT_ID", ""), type="password")
        papago_secret = st.text_input("Papago Client Secret", value=st.secrets.get("PAPAGO_CLIENT_SECRET", ""), type="password")

    st.divider()
    st.header("âš™ï¸ ì ìˆ˜ ê°€ì¤‘ì¹˜(ì„¤ëª…ê°€ëŠ¥ì„±)")
    st.caption("ì´ì  0~100. ì œì•½ì€ ê°ì ì´ë©°, ê¸°ì—¬ë„(breakdown)ë¥¼ ê³µê°œí•©ë‹ˆë‹¤.")
    w_acad = st.slider("í•™ì—…(ì„±ì )", 0.0, 1.0, 0.45, 0.05)
    w_extra = st.slider("ë¹„êµê³¼", 0.0, 1.0, 0.25, 0.05)
    w_const = st.slider("ì œì•½(ê°ì )", 0.0, 1.0, 0.20, 0.05)
    w_fit = st.slider("ì „í˜•-ì„±í–¥ ì í•©ë„", 0.0, 1.0, 0.10, 0.05)
    weights = ScoreWeights(w_acad, w_extra, w_const, w_fit)

    st.divider()
    today = st.date_input("í˜„ì¬ ì‹œì (ë¡œë“œë§µ ê¸°ì¤€)", value=date.today())

    st.divider()
    st.header("ğŸ•˜ íˆìŠ¤í† ë¦¬")
    if st.session_state.history:
        labels = [
            f"{i+1}) {h.get('id','')} | {h.get('payload',{}).get('route','')}/{h.get('payload',{}).get('desired_university','')}"
            for i, h in enumerate(st.session_state.history)
        ]
        pick = st.selectbox("ì €ì¥ëœ ê¸°ë¡ ë¶ˆëŸ¬ì˜¤ê¸°", ["(ì„ íƒ ì•ˆ í•¨)"] + labels, index=0)
        if pick != "(ì„ íƒ ì•ˆ í•¨)":
            idx = int(pick.split(")")[0]) - 1
            sel = st.session_state.history[idx]
            if st.button("â†©ï¸ ì´ ê¸°ë¡ìœ¼ë¡œ ë³µì›(ê²°ê³¼ íƒ­ì— í‘œì‹œ)"):
                st.session_state.payload = sel.get("payload")
                st.session_state.result = sel.get("result")
                st.session_state.evidence = sel.get("report", {}).get("evidence", []) or []
                st.session_state.csv_report = sel.get("report", {}).get("csv_validation_report")
                st.session_state.data_trust = sel.get("report", {}).get("data_trust")
                st.success("ë³µì› ì™„ë£Œ! 'ğŸ“Œ ê²°ê³¼' íƒ­ìœ¼ë¡œ ì´ë™í•´ í™•ì¸í•´ì¤˜.")


# =========================================================
# Tabs
# =========================================================
tabs = st.tabs(["ğŸ—ƒï¸ ë°ì´í„° ì—…ë¡œë“œ", "ğŸ“ ì§„ë‹¨ ì…ë ¥", "ğŸ“Œ ê²°ê³¼", "ğŸŒ¦ï¸ ë‚ ì”¨/ë‰´ìŠ¤", "ğŸ“ ë¦¬í¬íŠ¸/ê¸°íšì„œ"])


# =========================================================
# Tab 1: Data Upload
# =========================================================
with tabs[0]:
    st.subheader("ğŸ—ƒï¸ ì…ì‹œ ë°ì´í„° ì—…ë¡œë“œ (CSV)")
    st.write("ì—…ë¡œë“œëœ ë°ì´í„°ëŠ” **ê·¼ê±°(ì¶œì²˜/ì—°ë„) + ê°€ëŠ¥ì„± ê·¸ë˜í”„ + ì ìˆ˜ ì‚°ì •(í•™ì—… ë¹„êµ)**ì— ë°˜ì˜ë©ë‹ˆë‹¤.")

    template = (
        "university,major,route,route_detail,year,metric,threshold,source,note\n"
        "ì—°ì„¸ëŒ€,ê²½ì˜í•™ê³¼,ìˆ˜ì‹œ,í•™ìƒë¶€ì¢…í•©,2022,gpa,2.0,ì…í•™ì²˜,ì˜ˆì‹œ\n"
        "ì—°ì„¸ëŒ€,ê²½ì˜í•™ê³¼,ìˆ˜ì‹œ,í•™ìƒë¶€ì¢…í•©,2023,gpa,2.1,ì…í•™ì²˜,ì˜ˆì‹œ\n"
        "ì—°ì„¸ëŒ€,ê²½ì˜í•™ê³¼,ìˆ˜ì‹œ,í•™ìƒë¶€ì¢…í•©,2024,gpa,2.2,ì…í•™ì²˜,ì˜ˆì‹œ\n"
        "ì—°ì„¸ëŒ€,ê²½ì˜í•™ê³¼,ì •ì‹œ,,2024,mock,1.6,ì…í•™ì²˜,ì˜ˆì‹œ\n"
    )

    col_a, col_b = st.columns([1.2, 1.0], gap="large")
    with col_a:
        with st.expander("CSV í…œí”Œë¦¿(ê¶Œì¥ ì»¬ëŸ¼) ë³´ê¸°", expanded=True):
            st.code(template, language="text")

    with col_b:
        st.download_button(
            "â¬‡ï¸ CSV í…œí”Œë¦¿ ë‹¤ìš´ë¡œë“œ",
            data=template.encode("utf-8"),
            file_name="y_compass_admissions_template.csv",
            mime="text/csv",
        )

    uploaded = st.file_uploader("CSV ì—…ë¡œë“œ", type=["csv"])
    if uploaded is not None:
        try:
            df_raw = pd.read_csv(uploaded)
            rep = csv_validation_report(df_raw)
            st.session_state.csv_report = rep
            with st.expander("ğŸ§ª CSV ìë™ ê²€ì¦ ë¦¬í¬íŠ¸(í•„ìˆ˜ ì»¬ëŸ¼/ì´ìƒì¹˜/ì¤‘ë³µ/route_detail ì»¤ë²„ë¦¬ì§€)", expanded=True):
                st.json(rep)

            df = normalize_df(df_raw)
            st.session_state.df_data = df

            trust, reasons = data_trust_score(df, rep)
            st.session_state.data_trust = {"score": trust, "reasons": reasons}
            st.metric("ë°ì´í„° ì‹ ë¢°ë„ ì ìˆ˜(0~100)", trust)
            st.caption("ê°ì  ì‚¬ìœ : " + " / ".join(reasons))

            st.success(f"ì—…ë¡œë“œ ì„±ê³µ! rows={len(df):,}")
            st.dataframe(df.head(30), use_container_width=True)

        except Exception as e:
            st.error("CSV íŒŒì‹±/ì •ê·œí™” ì‹¤íŒ¨")
            st.caption(str(e))

    if st.session_state.df_data is not None and not st.session_state.df_data.empty:
        st.divider()
        st.markdown("#### ë°ì´í„° ì»¤ë²„ë¦¬ì§€ ì ê²€(ë¹ ë¥¸ í•„í„°)")
        df = st.session_state.df_data
        u = st.selectbox("ëŒ€í•™", sorted(df["university"].unique().tolist()))
        majors = sorted(df[df["university"] == u]["major"].unique().tolist())
        m = st.selectbox("í•™ê³¼", majors)
        r = st.selectbox("ì „í˜•(ìˆ˜ì‹œ/ì •ì‹œ)", ["ìˆ˜ì‹œ", "ì •ì‹œ"])
        rd = ""
        if r == "ìˆ˜ì‹œ":
            rd_list = sorted(
                df[(df["university"] == u) & (df["major"] == m) & (df["route"] == "ìˆ˜ì‹œ")]["route_detail"]
                .fillna("")
                .unique()
                .tolist()
            )
            rd = st.selectbox("ìˆ˜ì‹œ ì„¸ë¶€", rd_list)
        metric = st.selectbox("ê¸°ì¤€ì„  ìœ í˜•(metric)", ["gpa", "mock"])

        matched = match_rows(df, u, m, r, rd, metric)
        st.write(f"ë§¤ì¹­ ê²°ê³¼: {len(matched)} rows")
        st.dataframe(matched, use_container_width=True)


# =========================================================
# Tab 2: Intake
# =========================================================
with tabs[1]:
    st.subheader("ğŸ“ ì§„ë‹¨ ì…ë ¥ (3ë¶„)")
    st.caption("í¬ë§ ì „í˜• ì…ë ¥ â†’ ì„±ì /ì„±í–¥/ì œì•½ ê¸°ë°˜ ì ìˆ˜í™” â†’ ë°ì´í„° ê¸°ë°˜ì´ë©´ ê·¼ê±°/ê·¸ë˜í”„ê¹Œì§€ ìƒì„±")

    df_all = st.session_state.df_data if st.session_state.df_data is not None else pd.DataFrame()
    use_df = not df_all.empty

    with st.form("intake", clear_on_submit=False):
        c1, c2 = st.columns(2, gap="large")

        with c1:
            st.markdown("#### 1) í¬ë§ ì „í˜• ì…ë ¥")
            grade_status = st.selectbox("í•™ë…„/ìƒíƒœ", ["ê³ 3", "Nìˆ˜(ì¬ìˆ˜/ì‚¼ìˆ˜)", "ê³ 2(ë¯¸ë¦¬ë³´ê¸°)"])
            route = st.selectbox("ìˆ˜ì‹œ/ì •ì‹œ", ADMISSION_ROUTE)
            route_detail = ""
            if route == "ìˆ˜ì‹œ":
                route_detail = st.selectbox("ìˆ˜ì‹œ ì„¸ë¶€ ì „í˜•", SUSI_DETAIL)

            desired_university = st.text_input("í¬ë§ ëŒ€í•™(ê¶Œì¥)", placeholder="ì˜ˆ: ì—°ì„¸ëŒ€")
            desired_major = st.text_input("í¬ë§ í•™ê³¼(ê¶Œì¥)", placeholder="ì˜ˆ: ê²½ì˜í•™ê³¼")
            desired_text = st.text_input("í¬ë§ ì „í˜•/í•™ê³¼/ëŒ€í•™(ììœ  ì…ë ¥)", placeholder="ì˜ˆ: ì—°ì„¸ëŒ€ ê²½ì˜í•™ê³¼ í•™ìƒë¶€ì¢…í•©")

            st.markdown("#### 2) ì„±ì  ì…ë ¥(êµ¬ê°„)")
            gpa_band = st.selectbox("ë‚´ì‹  ë“±ê¸‰", ["ëª¨ë¦„/ì…ë ¥ì•ˆí•¨", "1.x", "2.x", "3.x", "4.x", "5.x", "ì§ì ‘ì…ë ¥"])
            gpa_direct = st.text_input("ë‚´ì‹  ì§ì ‘ ì…ë ¥(ì„ íƒ)", placeholder="ì˜ˆ: 2.3") if gpa_band == "ì§ì ‘ì…ë ¥" else ""
            mock_band = st.selectbox("ëª¨ì˜ê³ ì‚¬ ë“±ê¸‰/í™˜ì‚°", ["ëª¨ë¦„/ì…ë ¥ì•ˆí•¨", "1.x", "2.x", "3.x", "4.x", "5.x", "ì§ì ‘ì…ë ¥"])
            mock_direct = st.text_input("ëª¨ì˜ ì§ì ‘ ì…ë ¥(ì„ íƒ)", placeholder="ì˜ˆ: 2.1") if mock_band == "ì§ì ‘ì…ë ¥" else ""

        with c2:
            st.markdown("#### 3) ì„±í–¥/ë¹„êµê³¼/ì œì•½")
            major_group = st.selectbox("ê´€ì‹¬ ì „ê³µêµ°", MAJOR_GROUPS)
            activity_pref = st.multiselect("ì„ í˜¸ í™œë™/ê°•ì ", ACTIVITY_PREF, default=[ACTIVITY_PREF[0]])
            extracurricular = st.select_slider("ë¹„êµê³¼ ê°•ë„(ìê°€í‰ê°€)", options=EXTRACURRICULAR_LEVELS, value="ë³´í†µ")
            priorities = st.multiselect("ëª©í‘œ ìš°ì„ ìˆœìœ„(ìµœëŒ€ 2)", GOAL_PRIORITY, default=[GOAL_PRIORITY[0], GOAL_PRIORITY[1]])
            constraints = st.multiselect("ì œì•½", CONSTRAINTS, default=[])

            current_stage = st.selectbox("í˜„ì¬ ë‹¨ê³„(ë¡œë“œë§µ ê¸°ì¤€)", CURRENT_STAGE)
            notes = st.text_area("ì¶”ê°€ ë©”ëª¨(ì„ íƒ)", placeholder="ì˜ˆ: ë…¼ìˆ  ë³‘í–‰ / í†µí•™ ì œì•½ / ë©´ì ‘ì´ ë¶ˆì•ˆ")
            st.info("ê°œì¸ì •ë³´(í•™êµ/ì‹¤ëª…/ì—°ë½ì²˜ ë“±) ì…ë ¥ ê¸ˆì§€. ì¶”ì²œì€ ì°¸ê³ ìš©ì…ë‹ˆë‹¤.")

        go = st.form_submit_button("ê²°ê³¼ ìƒì„±", type="primary")

    if go:
        gpa_val = band_to_float(gpa_direct if gpa_band == "ì§ì ‘ì…ë ¥" else gpa_band)
        mock_val = band_to_float(mock_direct if mock_band == "ì§ì ‘ì…ë ¥" else mock_band)

        metric = "mock" if route == "ì •ì‹œ" else "gpa"
        user_metric_value = mock_val if metric == "mock" else gpa_val

        uni = _nonempty(desired_university)
        mj = _nonempty(desired_major)
        if not uni and _nonempty(desired_text):
            uni = _nonempty(desired_text).split()[0]
        if not mj and _nonempty(desired_text):
            toks = _nonempty(desired_text).split()
            if len(toks) >= 2:
                mj = toks[1]

        matched = pd.DataFrame()
        if use_df and uni and mj:
            matched = match_rows(df_all, uni, mj, route, route_detail, metric)

        is_data_based = (matched is not None) and (not matched.empty)

        ref_series = matched.sort_values("year")["threshold"] if is_data_based else None
        acad_s, acad_msg, anchor = academics_score(user_metric_value, ref_series)

        extra_s = extracurricular_score(extracurricular)
        penalty = constraints_penalty(constraints)
        fit_s = preference_fit_score(activity_pref, route, route_detail)

        tot, breakdown = total_score(weights, acad_s, extra_s, penalty, fit_s)
        band = score_to_band(tot)
        abc = abc_scores(tot, constraints, priorities[:2])
        abc_detail_pack = abc_scores_by_route_detail(tot, constraints, priorities[:2], route, route_detail)

        payload = {
            "today": str(today),
            "grade_status": grade_status,
            "route": route,
            "route_detail": route_detail,
            "desired_university": uni,
            "desired_major": mj,
            "desired_text": desired_text,
            "major_group": major_group,
            "gpa_value": gpa_val,
            "mock_value": mock_val,
            "metric_used": metric,
            "metric_value": user_metric_value,
            "activity_pref": activity_pref,
            "extracurricular_level": extracurricular,
            "priorities": priorities[:2],
            "constraints": constraints,
            "current_stage": current_stage,
            "notes": notes,
            "band_label": band,
            "coverage_is_data": is_data_based,
            "score_total": float(tot),
            "score_breakdown": breakdown,
            "abc_scores": abc,
            "abc_scores_by_route_detail": abc_detail_pack,
            "scoring_notes": {
                "academics": acad_msg,
                "fit": "ì „í˜•-ì„±í–¥ ì í•©ë„ëŠ” ì„ íƒ ì„±í–¥ê³¼ ì „í˜• íŠ¹ì„± ë§¤ì¹­ìœ¼ë¡œ ì‚°ì¶œí–ˆìŠµë‹ˆë‹¤.",
                "constraints": "ì œì•½ì€ ê°ì ìœ¼ë¡œ ì ìš©ë˜ë©°(ê°€ì¤‘ì¹˜ ë°˜ì˜), ë§ì„ìˆ˜ë¡ ë¦¬ìŠ¤í¬ê°€ ì»¤ì§‘ë‹ˆë‹¤.",
            },
            "data_anchor_threshold": anchor,
        }

        st.session_state.payload = payload
        st.session_state.score_breakdown = breakdown
        st.session_state.abc = abc

        evidence_docs: List[Dict[str, str]] = []
        if is_data_based:
            tail = matched.sort_values("year").tail(12)
            for _, row in tail.iterrows():
                title = f"{row['university']} {row['major']} | {row['route']}{(' - ' + row['route_detail']) if row['route_detail'] else ''} | {int(row['year'])}"
                note = f"metric={row['metric']} threshold={row['threshold']} | source={row.get('source','')} | note={row.get('note','')}"
                evidence_docs.append({"title": title, "note": note})
        else:
            evidence_docs.append(
                {
                    "title": "ë°ì´í„° ë¯¸ë³´ìœ (ê°€ì´ë“œ ê¸°ë°˜)",
                    "note": "í•´ë‹¹ ëŒ€í•™/í•™ê³¼/ì „í˜•ì˜ ì—…ë¡œë“œ ë°ì´í„°ê°€ ì—†ì–´ ìˆ˜ì¹˜ ê¸°ë°˜ ì˜ˆì¸¡ì„ ì œê³µí•˜ì§€ ì•Šê³ , ì „í˜• íŠ¹ì„± ê¸°ë°˜ ì „ëµ ê°€ì´ë“œë¡œ ì•ˆë‚´í•©ë‹ˆë‹¤.",
                }
            )

        st.session_state.evidence = evidence_docs

        # ì™¸ë¶€ API (ë‚ ì”¨/ë‰´ìŠ¤) ë°ì´í„°ë„ payloadì— ë„£ì–´ "ê¸°ëŠ¥ í™•ì¥" ì¦ë¹™
        weather_pack = fetch_weather_openweather(openweather_key, weather_city, lang=("kr" if ui_lang == "ko" else "en"))
        payload["external_weather_ok"] = bool(weather_pack.get("ok"))
        payload["external_weather_city"] = weather_city
        if weather_pack.get("ok"):
            payload["external_weather_summary"] = weather_micro_advice(weather_pack["data"], lang=ui_lang)

        news_pack = fetch_news_newsapi(news_api_key, news_query, language=("ko" if ui_lang == "ko" else "en"))
        payload["external_news_ok"] = bool(news_pack.get("ok"))
        payload["external_news_query"] = news_query
        if news_pack.get("ok"):
            arts = (news_pack["data"].get("articles") or [])[:6]
            payload["external_news_titles"] = [a.get("title", "") for a in arts if a.get("title")]

        with st.spinner("A/B/C ì¶”ì²œ + 8ì£¼ ë¡œë“œë§µ ìƒì„± ì¤‘..."):
            try:
                if _nonempty(openai_api_key):
                    plan = openai_generate_plan(
                        api_key=openai_api_key.strip(),
                        model=openai_model.strip(),
                        payload_json=payload,
                        context_docs=evidence_docs,
                    )
                else:
                    plan = rule_based_plan(payload)

                plan["_meta"] = {
                    "coverage_is_data": is_data_based,
                    "score_total": payload["score_total"],
                    "score_breakdown": payload["score_breakdown"],
                    "abc_scores": payload["abc_scores"],
                    "academics_msg": acad_msg,
                    "external_weather": payload.get("external_weather_summary", ""),
                    "external_news_titles": payload.get("external_news_titles", []),
                }

                st.session_state.result = plan

                # íˆìŠ¤í† ë¦¬ ì €ì¥(ì„¸ì…˜)
                hist_id = f"{date.today().isoformat()}_{len(st.session_state.history)+1:02d}"
                report = {
                    "payload": payload,
                    "summary_5lines": plan.get("summary_5lines", []),
                    "routes": plan.get("routes", {}),
                    "roadmap": plan.get("roadmap", []),
                    "evidence": plan.get("evidence", []),
                    "meta": plan.get("_meta", {}),
                    "csv_validation_report": st.session_state.get("csv_report"),
                    "data_trust": st.session_state.get("data_trust"),
                }
                st.session_state.history.insert(0, {"id": hist_id, "payload": payload, "result": plan, "report": report})

                st.success("ì™„ë£Œ! 'ğŸ“Œ ê²°ê³¼' íƒ­ì—ì„œ í™•ì¸í•´ì¤˜.")
            except Exception as e:
                st.session_state.result = None
                st.error("ìƒì„± ì‹¤íŒ¨(í‚¤/ëª¨ë¸/ë„¤íŠ¸ì›Œí¬/JSON í˜•ì‹) í™•ì¸")
                st.caption(str(e))


# =========================================================
# Charts (Altair helpers)
# =========================================================
def chart_threshold_vs_user(chart_df: pd.DataFrame, anchor: Optional[float], is_data_based: bool) -> alt.Chart:
    long_df = chart_df.melt(id_vars=["year"], value_vars=["threshold", "user_value"], var_name="series", value_name="value")
    long_df["series"] = long_df["series"].replace({"threshold": "ê¸°ì¤€ì„ (threshold)", "user_value": "ë‚´ ì„±ì (user)"})

    line = alt.Chart(long_df).mark_line(point=True).encode(
        x=alt.X("year:O", title="ì—°ë„"),
        y=alt.Y("value:Q", title="ë“±ê¸‰(ë‚®ì„ìˆ˜ë¡ ìœ ë¦¬)", scale=alt.Scale(reverse=True)),
        color=alt.Color("series:N", title=""),
        tooltip=[
            alt.Tooltip("year:O", title="ì—°ë„"),
            alt.Tooltip("series:N", title="í•­ëª©"),
            alt.Tooltip("value:Q", title="ê°’", format=".2f"),
        ],
    )

    y_min = float(chart_df[["threshold", "user_value"]].min().min())
    y_max = float(chart_df[["threshold", "user_value"]].max().max())
    x_min = str(chart_df["year"].min())
    x_max = str(chart_df["year"].max())
    y_anchor = float(anchor) if anchor is not None else float(chart_df["threshold"].iloc[-1])

    ann_df = pd.DataFrame(
        [
            {"x": x_min, "y": y_min, "t": "â‘  yì¶• ì—­ì¶•: ë‚®ì„ìˆ˜ë¡ ìœ ë¦¬"},
            {"x": x_max, "y": y_anchor, "t": "â‘¡ ìµœê·¼ ê¸°ì¤€ì„ (anchor)"},
            {"x": x_min, "y": y_max, "t": f"â‘¢ ì»¤ë²„ë¦¬ì§€: {'ë°ì´í„° ê¸°ë°˜' if is_data_based else 'ê°€ì´ë“œ ê¸°ë°˜'}"},
        ]
    )

    annotations = alt.Chart(ann_df).mark_text(align="left", dx=6, dy=-6).encode(
        x=alt.X("x:O", title=None),
        y=alt.Y("y:Q", scale=alt.Scale(reverse=True), title=None),
        text="t:N",
    )

    return (line + annotations).properties(height=260)


def chart_breakdown(breakdown: Dict[str, float]) -> alt.Chart:
    keys = ["í•™ì—…(ì„±ì )", "ë¹„êµê³¼", "ì í•©ë„(ì„±í–¥â†”ì „í˜•)", "ì œì•½(ê°ì )"]
    rows = [{"ìš”ì†Œ": k, "ê¸°ì—¬ë„": float(breakdown.get(k, 0.0))} for k in keys]
    df = pd.DataFrame(rows)
    return (
        alt.Chart(df)
        .mark_bar()
        .encode(
            x=alt.X("ê¸°ì—¬ë„:Q", title="ê¸°ì—¬ë„(ê°€ì¤‘ì¹˜ ë°˜ì˜)"),
            y=alt.Y("ìš”ì†Œ:N", title=""),
            tooltip=[alt.Tooltip("ìš”ì†Œ:N"), alt.Tooltip("ê¸°ì—¬ë„:Q", format=".2f")],
        )
        .properties(height=220)
    )


def chart_abc_scores(abc: Dict[str, Dict[str, Any]]) -> alt.Chart:
    df = pd.DataFrame(
        [
            {"ê²½ë¡œ": "A(ì•ˆì •)", "ì ìˆ˜": abc["A"]["score"], "êµ¬ê°„": abc["A"]["band"]},
            {"ê²½ë¡œ": "B(ì ì •)", "ì ìˆ˜": abc["B"]["score"], "êµ¬ê°„": abc["B"]["band"]},
            {"ê²½ë¡œ": "C(ë„ì „)", "ì ìˆ˜": abc["C"]["score"], "êµ¬ê°„": abc["C"]["band"]},
        ]
    )
    return (
        alt.Chart(df)
        .mark_bar()
        .encode(
            x=alt.X("ê²½ë¡œ:N", title="ê²½ë¡œ(A/B/C)"),
            y=alt.Y("ì ìˆ˜:Q", title="ì ìˆ˜(0~100)", scale=alt.Scale(domain=[0, 100])),
            tooltip=[alt.Tooltip("ê²½ë¡œ:N"), alt.Tooltip("ì ìˆ˜:Q", format=".1f"), alt.Tooltip("êµ¬ê°„:N")],
        )
        .properties(height=260)
    )


# =========================================================
# Tab 3: Results
# =========================================================
with tabs[2]:
    st.subheader("ğŸ“Œ ê²°ê³¼")
    st.warning(t("policy", ui_lang))

    trust_pack = st.session_state.get("data_trust") or {}
    if isinstance(trust_pack, dict) and trust_pack.get("score") is not None:
        st.metric("ë°ì´í„° ì‹ ë¢°ë„ ì ìˆ˜(0~100)", trust_pack.get("score"))
        reasons = trust_pack.get("reasons") or []
        if reasons:
            st.caption("ê°ì  ì‚¬ìœ : " + " / ".join(reasons))

    if st.session_state.result is None or st.session_state.payload is None:
        st.info("ë¨¼ì € 'ğŸ“ ì§„ë‹¨ ì…ë ¥'ì—ì„œ ê²°ê³¼ë¥¼ ìƒì„±í•´ì¤˜.")
    else:
        payload = st.session_state.payload
        plan = st.session_state.result
        meta = plan.get("_meta", {})

        st.markdown("### ğŸ§¾ ê°€ì¤‘ì¹˜ í…Œì´ë¸”(ì„¤ëª…ê°€ëŠ¥ì„±)")
        wn = normalize_weights(weights)
        w_df = pd.DataFrame(
            [
                {"ìš”ì†Œ": "í•™ì—…(ì„±ì )", "ê°€ì¤‘ì¹˜": wn.academics},
                {"ìš”ì†Œ": "ë¹„êµê³¼", "ê°€ì¤‘ì¹˜": wn.extracurricular},
                {"ìš”ì†Œ": "ì œì•½(ê°ì )", "ê°€ì¤‘ì¹˜": wn.constraints},
                {"ìš”ì†Œ": "ì í•©ë„(ì„±í–¥â†”ì „í˜•)", "ê°€ì¤‘ì¹˜": wn.preference_fit},
            ]
        )
        st.dataframe(w_df.style.format({"ê°€ì¤‘ì¹˜": "{:.2f}"}), use_container_width=True)
        st.caption("ì´ì (0~100) = (í•™ì—…*ê°€ì¤‘ì¹˜ + ë¹„êµê³¼*ê°€ì¤‘ì¹˜ + ì í•©ë„*ê°€ì¤‘ì¹˜) - (ì œì•½*ê°€ì¤‘ì¹˜)")

        st.divider()
        st.markdown("## ì„¹ì…˜ 1 â€” ë‚´ê°€ ì›í•˜ëŠ” ì „í˜• ê°€ëŠ¥ì„± ì¹´ë“œ")

        col1, col2, col3 = st.columns([1.2, 1.2, 2.4], gap="large")

        with col1:
            with st.container(border=True):
                st.markdown('<div class="card-title">ì»¤ë²„ë¦¬ì§€</div>', unsafe_allow_html=True)
                st.markdown(coverage_badge_html(payload["coverage_is_data"], ui_lang), unsafe_allow_html=True)
                st.markdown('<div class="small">ë°ì´í„° ê¸°ë°˜ì´ë©´ ì—°ë„/ì¶œì²˜ ê·¼ê±° ë° ê·¸ë˜í”„ ì œê³µ</div>', unsafe_allow_html=True)

        with col2:
            with st.container(border=True):
                st.markdown('<div class="card-title">ê°€ëŠ¥ì„± êµ¬ê°„(ì•ˆì •/ì ì •/ë„ì „)</div>', unsafe_allow_html=True)
                st.markdown(band_badge_html(payload["band_label"], ui_lang), unsafe_allow_html=True)
                st.metric("ì´ì (0~100)", f"{payload['score_total']:.1f}", help="ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì„¤ëª…ê°€ëŠ¥ ì ìˆ˜")
                if payload.get("metric_value") is None:
                    st.caption("ì„±ì  ë¯¸ì…ë ¥ â†’ í•™ì—… ì ìˆ˜ëŠ” ì¤‘ë¦½ ì²˜ë¦¬")
                else:
                    st.caption(f"ì‚¬ìš© ì§€í‘œ: {payload['metric_used']} | ì…ë ¥ê°’: {payload['metric_value']:.2f}")

        with col3:
            with st.container(border=True):
                st.markdown('<div class="card-title">ì™œ ì´ êµ¬ê°„ì¸ê°€? (ì„¤ëª…ê°€ëŠ¥ ì ìˆ˜í™”)</div>', unsafe_allow_html=True)
                st.write(meta.get("academics_msg", ""))
                bd = payload["score_breakdown"]
                st.altair_chart(chart_breakdown(bd), use_container_width=True)

        st.markdown("### ğŸ”Œ ì™¸ë¶€ API ê¸°ë°˜ ì¶”ê°€ ì¸ì‚¬ì´íŠ¸(ì‹¬í™” A ì¦ë¹™)")
        wx = meta.get("external_weather", "")
        nt = meta.get("external_news_titles", []) or []
        cwx, cnews = st.columns([1, 1], gap="large")
        with cwx:
            with st.container(border=True):
                st.markdown("**ğŸŒ¦ï¸ ë‚ ì”¨ ê¸°ë°˜ ì˜¤ëŠ˜ì˜ ê³µë¶€/ì´ë™ ì¡°ì–¸**")
                if payload.get("external_weather_ok") and wx:
                    st.write(wx)
                else:
                    st.caption("ë‚ ì”¨ API í‚¤/ë„ì‹œ ì„¤ì • í›„ ì§„ë‹¨ì„ ë‹¤ì‹œ ìƒì„±í•˜ë©´ í‘œì‹œë©ë‹ˆë‹¤.")
        with cnews:
            with st.container(border=True):
                st.markdown("**ğŸ“° ì‹¤ì‹œê°„ ë‰´ìŠ¤(ì œëª©) ê¸°ë°˜ ì²´í¬ë¦¬ìŠ¤íŠ¸**")
                if payload.get("external_news_ok") and nt:
                    for i, title in enumerate(nt[:6], 1):
                        st.write(f"{i}. {title}")
                    st.caption("â€» ë‰´ìŠ¤ëŠ” 'ì œëª©/ë°œí–‰ ì‹œê°'ë§Œ ê·¼ê±°ë¡œ í‘œì‹œ(ë‚´ìš© ë‹¨ì •/ì¶”ë¡  ìµœì†Œí™”).")
                else:
                    st.caption("NewsAPI í‚¤/í‚¤ì›Œë“œ ì„¤ì • í›„ ì§„ë‹¨ì„ ë‹¤ì‹œ ìƒì„±í•˜ë©´ í‘œì‹œë©ë‹ˆë‹¤.")

        st.divider()

        df_all = st.session_state.df_data if st.session_state.df_data is not None else pd.DataFrame()
        if payload["coverage_is_data"] and not df_all.empty:
            st.markdown("### ê·¼ê±° ì‹œê°í™”(ì—°ë„ë³„ ê¸°ì¤€ì„  vs ë‚´ ì„±ì )")
            metric = payload["metric_used"]
            uni = payload.get("desired_university", "")
            mj = payload.get("desired_major", "")
            route = payload.get("route", "ìˆ˜ì‹œ")
            rd = payload.get("route_detail", "")

            matched = match_rows(df_all, uni, mj, route, rd, metric)
            if matched is not None and not matched.empty and payload.get("metric_value") is not None:
                chart_df = matched.sort_values("year")[["year", "threshold"]].copy()
                chart_df["user_value"] = float(payload["metric_value"])

                st.dataframe(chart_df, use_container_width=True)
                st.altair_chart(
                    chart_threshold_vs_user(chart_df, payload.get("data_anchor_threshold"), payload["coverage_is_data"]),
                    use_container_width=True,
                )
                st.caption("â€» ê·¸ë˜í”„ëŠ” ì°¸ê³ ìš©ì´ë©°, ë‹¨ì •ì  í•©ê²© ì˜ˆì¸¡ì´ ì•„ë‹™ë‹ˆë‹¤.")
            elif matched is not None and not matched.empty:
                st.info("ë§¤ì¹­ ë°ì´í„°ëŠ” ìˆìœ¼ë‚˜, ì„±ì  ì…ë ¥ì´ ì—†ì–´ ë¹„êµ ê·¸ë˜í”„ë¥¼ ë§Œë“¤ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.info("ì‹œê°í™”í•  ë§¤ì¹­ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤(í•™ê³¼ëª…/ì „í˜• í‚¤ì›Œë“œ í™•ì¸).")
        else:
            st.info("í˜„ì¬ëŠ” **ê°€ì´ë“œ ê¸°ë°˜**ì´ê±°ë‚˜ ë°ì´í„° ì—…ë¡œë“œê°€ ì—†ì–´ ê·¸ë˜í”„ë¥¼ í‘œì‹œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        st.divider()
        st.markdown("## ì„¹ì…˜ 2 â€” A/B/C ì¶”ì²œ ì ìˆ˜í™”(ì„¤ëª…ê°€ëŠ¥ì„± ê°•í™”)")
        abc = payload.get("abc_scores") or {}
        if abc:
            st.altair_chart(chart_abc_scores(abc), use_container_width=True)
            st.caption("A/B/C ì ìˆ˜ëŠ” ì´ì (ê¸°ë³¸ ì í•©ë„)ì„ ê¸°ì¤€ìœ¼ë¡œ, ì œì•½/ëª©í‘œ ìš°ì„ ìˆœìœ„ë¥¼ ë°˜ì˜í•´ ê²½ë¡œ ë‚œì´ë„ë¥¼ ë³´ì •í•´ ì‚°ì¶œí•©ë‹ˆë‹¤.")
        else:
            st.warning("A/B/C ì ìˆ˜í™” ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

        st.markdown("### ğŸ§­ A/B/C ê²½ë¡œë³„ ì ìˆ˜(ìˆ˜ì‹œ ì„¸ë¶€ì „í˜• ë¶„ë¦¬)")
        pack = payload.get("abc_scores_by_route_detail", {})
        variants = pack.get("variants", {})
        picked = pack.get("selected_route_detail", "(ê³µí†µ)")

        if variants:
            keys = list(variants.keys())
            idx = keys.index(picked) if picked in keys else 0
            opt = st.selectbox("ì„¸ë¶€ì „í˜•(ì„¤ëª…ìš© ë¶„ë¦¬)", keys, index=idx)
            st.altair_chart(chart_abc_scores(variants[opt]), use_container_width=True)
            st.caption("â€» ë™ì¼ ì´ì ì„ ê¸°ë°˜ìœ¼ë¡œ, ì „í˜• íŠ¹ì„±(ë³€ë™ì„±/ì •ëŸ‰ì„±)ì— ë”°ë¼ A/B/Cë¥¼ ë¯¸ì„¸ ì¡°ì •í•œ 'ì„¤ëª…ìš© ë¶„ë¦¬'ì…ë‹ˆë‹¤.")

        st.divider()
        st.markdown("## ì„¹ì…˜ 3 â€” AI ì¶”ì²œ ì „í˜•/ì „ëµ TOP3 (A/B/C)")
        routes = plan.get("routes", {})
        cols = st.columns(3, gap="large")
        keys = ["A", "B", "C"]
        title_map = {"A": "A: ì•ˆì •", "B": "B: ì ì •", "C": "C: ë„ì „"}

        for i, k in enumerate(keys):
            r = routes.get(k, {})
            with cols[i]:
                with st.container(border=True):
                    st.markdown(f"### {title_map[k]}")
                    if abc and k in abc:
                        st.caption(f"ì ìˆ˜: {abc[k]['score']:.1f} / 100 Â· êµ¬ê°„: {abc[k]['band']}")
                    else:
                        st.caption(r.get("title", ""))

                    st.markdown("**ì¶”ì²œ ì´ìœ (3)**")
                    for x in (r.get("reasons") or [])[:3]:
                        st.write(f"- {x}")

                    st.markdown("**ì¤€ë¹„ ì•¡ì…˜(5)**")
                    for x in (r.get("actions") or [])[:5]:
                        st.write(f"- {x}")

                    st.markdown("**ë¦¬ìŠ¤í¬/ê°€ì •(2)**")
                    for x in (r.get("risks") or [])[:2]:
                        st.write(f"- {x}")

        st.divider()
        st.markdown("## ì„¹ì…˜ 4 â€” 8ì£¼ ë¡œë“œë§µ")
        roadmap = plan.get("roadmap", [])
        if not roadmap:
            st.warning("ë¡œë“œë§µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        else:
            for item in roadmap[:8]:
                w = item.get("week")
                with st.expander(f"Week {w} â€” {item.get('goal','')}", expanded=(w == 1)):
                    st.markdown("**í•  ì¼(2~3)**")
                    for tsk in (item.get("tasks") or [])[:3]:
                        st.write(f"- {tsk}")
                    st.markdown("**ì‚°ì¶œë¬¼**")
                    st.write(item.get("deliverable", ""))

        st.divider()
        st.markdown("### ê·¼ê±° ë³´ê¸°(ì¶œì²˜)")
        evs = plan.get("evidence", []) or st.session_state.evidence or []
        if evs:
            for ev in evs[:15]:
                with st.expander(ev.get("title", "ê·¼ê±°")):
                    st.write(ev.get("note", ""))
        else:
            st.caption("í‘œì‹œí•  ê·¼ê±°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        st.divider()
        st.markdown("### ê²°ê³¼ ì €ì¥(ì œì¶œ/ì‹œì—°ìš©)")

        report = {
            "payload": payload,
            "summary_5lines": plan.get("summary_5lines", []),
            "routes": plan.get("routes", {}),
            "roadmap": plan.get("roadmap", []),
            "evidence": plan.get("evidence", []),
            "meta": plan.get("_meta", {}),
            "csv_validation_report": st.session_state.get("csv_report"),
            "data_trust": st.session_state.get("data_trust"),
        }

        trans_block = ""
        if translator != "Off":
            base_text = "\n".join(plan.get("summary_5lines", [])[:5])
            if base_text.strip():
                if translator == "DeepL" and _nonempty(deepl_key):
                    res = translate_deepl(deepl_key, base_text, target_lang=("EN" if ui_lang == "ko" else "KO"))
                    if res.get("ok"):
                        trans_block = res.get("text", "")
                elif translator == "Papago" and _nonempty(papago_id) and _nonempty(papago_secret):
                    res = translate_papago(
                        papago_id,
                        papago_secret,
                        base_text,
                        source=("ko" if ui_lang == "ko" else "en"),
                        target=("en" if ui_lang == "ko" else "ko"),
                    )
                    if res.get("ok"):
                        trans_block = res.get("text", "")

        st.download_button(
            t("export_json", ui_lang),
            data=json.dumps(report, ensure_ascii=False, indent=2),
            file_name="y_compass_report.json",
            mime="application/json",
        )

        pdf_bytes = build_pdf_report_bytes(report, title="Y-Compass Report")
        st.download_button(
            t("export_pdf", ui_lang),
            data=pdf_bytes,
            file_name="y_compass_report.pdf",
            mime="application/pdf",
        )

        if trans_block:
            st.markdown("#### ğŸŒ ë²ˆì—­(ìš”ì•½ 5ì¤„)")
            st.text_area("Translated summary", value=trans_block, height=140)
            st.download_button(
                "â¬‡ï¸ ë²ˆì—­ í…ìŠ¤íŠ¸ ë‹¤ìš´ë¡œë“œ (.txt)",
                data=trans_block.encode("utf-8"),
                file_name="y_compass_summary_translated.txt",
                mime="text/plain",
            )


# =========================================================
# Tab 4: Weather/News (ì‹¬í™” A) + UX ëŒ€ì‹œë³´ë“œ(ì‹¬í™” B)
# =========================================================
with tabs[3]:
    st.subheader("ğŸŒ¦ï¸ ë‚ ì”¨/ë‰´ìŠ¤ ê¸°ë°˜ ì‹¤ì‹œê°„ ë³´ì¡° ì¸ì‚¬ì´íŠ¸ (ì‹¬í™” A)")
    st.caption("ì™¸ë¶€ APIë¥¼ í†µí•´ ì•± ê¸°ëŠ¥ì„ 'ì‹¤ì œë¡œ' í™•ì¥: ì˜¤ëŠ˜ ì»¨ë””ì…˜/ì´ë™/í•™ìŠµ ìš´ì˜ + êµìœ¡/ì…ì‹œ í‚¤ì›Œë“œ ë‰´ìŠ¤ ëª¨ë‹ˆí„°ë§")

    colw, coln = st.columns([1, 1], gap="large")

    with colw:
        st.markdown("### ğŸŒ¦ï¸ Weather (OpenWeatherMap)")
        with st.spinner("ë‚ ì”¨ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
            wp = fetch_weather_openweather(openweather_key, weather_city, lang=("kr" if ui_lang == "ko" else "en"))
        if wp.get("ok"):
            data = wp["data"]
            st.json(
                {
                    "city": data.get("name"),
                    "weather": (data.get("weather") or [{}])[0].get("description"),
                    "temp": data.get("main", {}).get("temp"),
                    "feels_like": data.get("main", {}).get("feels_like"),
                    "humidity": data.get("main", {}).get("humidity"),
                    "wind": data.get("wind", {}).get("speed"),
                }
            )
            st.success("ë‚ ì”¨ ê¸°ë°˜ ì¡°ì–¸")
            st.write(weather_micro_advice(data, lang=ui_lang))
        else:
            st.warning("ë‚ ì”¨ í˜¸ì¶œ ì‹¤íŒ¨(í‚¤/ë„ì‹œ/ìš”ì²­ ì œí•œ í™•ì¸).")
            st.caption(str(wp.get("error")))

    with coln:
        st.markdown("### ğŸ“° News (NewsAPI)")
        with st.spinner("ë‰´ìŠ¤ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
            np = fetch_news_newsapi(news_api_key, news_query, language=("ko" if ui_lang == "ko" else "en"))
        if np.get("ok"):
            arts = (np["data"].get("articles") or [])[:8]
            if not arts:
                st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤(í‚¤ì›Œë“œ ë³€ê²½í•´ë´).")
            for a in arts:
                title = a.get("title", "")
                src = (a.get("source") or {}).get("name", "")
                pub = a.get("publishedAt", "")
                st.markdown(f"- **{title}**  \n  {src} Â· {pub}")
            st.caption("â€» ê¸°ì‚¬ ë‚´ìš© ë‹¨ì •/ì¶”ë¡  ì—†ì´, ì œëª©Â·ì¶œì²˜Â·ì‹œê°ë§Œ í‘œì‹œ(ê·¼ê±° ìµœì†Œ ë‹¨ìœ„).")
        else:
            st.warning("ë‰´ìŠ¤ í˜¸ì¶œ ì‹¤íŒ¨(í‚¤/ì¿¼ë¦¬/ìš”ì²­ ì œí•œ í™•ì¸).")
            st.caption(str(np.get("error")))

    st.divider()
    st.markdown("### ğŸ“Š UX ëŒ€ì‹œë³´ë“œ (ì‹¬í™” B)")
    st.write("ì•„ë˜ëŠ” ì•± ë‚´ë¶€ ë°ì´í„°(ì ìˆ˜/íˆìŠ¤í† ë¦¬/ì™¸ë¶€ API ìƒíƒœ)ë¥¼ í•œ í™”ë©´ì—ì„œ ë³´ì—¬ì£¼ëŠ” 'ì‹œì—°ìš© ëŒ€ì‹œë³´ë“œ'ì•¼.")

    h = st.session_state.history
    st.metric("íˆìŠ¤í† ë¦¬ ì €ì¥ ê±´ìˆ˜", len(h))
    if h:
        last = h[0].get("payload", {})
        st.write("ìµœê·¼ ê¸°ë¡ ìš”ì•½")
        st.json(
            {
                "route": last.get("route"),
                "route_detail": last.get("route_detail"),
                "university": last.get("desired_university"),
                "major": last.get("desired_major"),
                "score_total": last.get("score_total"),
                "band": last.get("band_label"),
                "weather_ok": last.get("external_weather_ok"),
                "news_ok": last.get("external_news_ok"),
            }
        )


# =========================================================
# Tab 5: Report / Spec
# =========================================================
with tabs[4]:
    st.subheader("ğŸ“ ê¸°íšì„œ/ë¦¬í¬íŠ¸ (Report Ver.)")

    st.markdown(
        """
## 1. ê°œìš”
**ì•± ì´ë¦„:** Y-Compass(ì™€ì´ì»´í¼ìŠ¤) â€” Y(ì—°ì„¸ëŒ€ ë…¸í•˜ìš°) + Compass(ë°©í–¥ ì¡ê¸°)  
**ì•± í•œì¤„ ì„¤ëª…:** â€œëŒ€í•™ ì§„í•™ì´ ë§‰ë§‰í•œ 10ëŒ€ì—ê²Œ, ê·¼ê±° ê¸°ë°˜ ì „í˜•/ì „ê³µ í›„ë³´ 3ê°œ(A/B/C)ì™€ 8ì£¼ ì¤€ë¹„ ë¡œë“œë§µì„ ì œê³µí•˜ëŠ” AI ì§„í•™ ì¹´ìš´ì…€ëŸ¬â€

### Problem Statement
- **ì •ë³´ ê³¼ì‰/ë¶„ì‚°:** ì „í˜•Â·ì „ê³µ ì •ë³´ê°€ í©ì–´ì ¸ ìˆì–´ ë¬´ì—‡ë¶€í„° í™•ì¸í•´ì•¼ í• ì§€ ì–´ë ¤ì›€  
- **ë¹„ìš©/ì ‘ê·¼ì„±:** ì „ë¬¸ ì»¨ì„¤íŒ…ì€ ë¹„ìš© ë¶€ë‹´ì´ í¬ê³  ì§€ì—­Â·ì‹œê°„ ì œì•½ìœ¼ë¡œ ì ‘ê·¼ì„±ì´ ë‚®ìŒ  
- **ì‹ ë¢°ì„± ë¶€ì¡±:** ê²½í—˜ë‹´ ì¤‘ì‹¬ ì¡°ì–¸ì´ ë§ì•„ ê·¼ê±°Â·ì¶œì²˜ê°€ ë¶ˆíˆ¬ëª…

**í•´ê²° ì „ëµ:** ì§§ì€ ì…ë ¥ â†’ ê·¼ê±° ê¸°ë°˜ ì¶”ì²œ(ì¶œì²˜ ì œì‹œ) â†’ ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ë¡œë“œë§µ
"""
    )

    st.markdown("## 2. í•µì‹¬ ê¸°ëŠ¥(3)")
    st.markdown(
        """
1) **3ë¶„ ì§„ë‹¨(Intake & Profiling)**: ìƒí™© ìš”ì•½ + ê°•ì /ì œì•½ ì…ë ¥  
2) **ê·¼ê±° ê¸°ë°˜ í›„ë³´ 3ê°œ ì¶”ì²œ(A/B/C)**: ì¶”ì²œ ì´ìœ /ì•¡ì…˜/ë¦¬ìŠ¤í¬ + ê·¼ê±°(ì¶œì²˜/ì—°ë„)  
3) **8ì£¼ ë¡œë“œë§µ**: ì „í˜•+í˜„ì¬ ë‹¨ê³„ ë°˜ì˜, ì£¼ì°¨ë³„ ëª©í‘œ1 + í•  ì¼2~3 + ì‚°ì¶œë¬¼1
"""
    )

    st.markdown("## 3. ì‹¬í™” A â€” ì™¸ë¶€ API ì—°ë™ìœ¼ë¡œ ê¸°ëŠ¥ í™•ì¥")
    st.markdown(
        """
- **OpenWeatherMap(ë‚ ì”¨)**: ì˜¤ëŠ˜ ë‚ ì”¨(ë¹„/ëˆˆ/í­ì—¼/í•œíŒŒ ë“±)ì— ë”°ë¼ **í•™ìŠµ ì¥ì†Œ/ì´ë™/ë£¨í‹´ ì¡°ì–¸**ì„ ë£° ê¸°ë°˜ìœ¼ë¡œ ì œê³µ  
- **NewsAPI(ë‰´ìŠ¤)**: êµìœ¡/ì…ì‹œ/ì •ì±… í‚¤ì›Œë“œë¡œ **ì‹¤ì‹œê°„ ë‰´ìŠ¤ íƒ€ì´í‹€ ëª¨ë‹ˆí„°ë§**ì„ ì œê³µ(ì¶œì²˜Â·ì‹œê° í¬í•¨)  
- **DeepL/Papago(ë²ˆì—­)**: ê²°ê³¼ ìš”ì•½(5ì¤„)ì„ **ë‹¤êµ­ì–´ë¡œ ë³€í™˜**í•˜ì—¬ ë‹¤ìš´ë¡œë“œ ì œê³µ(ì„ íƒ)

âœ… ì²´í¬: OpenAI ì™¸ ì¶”ê°€ API 1ê°œ ì´ìƒ ì—°ë™ + ì•± ê°€ì¹˜(ì •ë³´/ì¡°ì–¸/ë‹¤êµ­ì–´)ê°€ ì‹¤ì œë¡œ í™•ì¥ë¨
"""
    )

    st.markdown("## 4. ì‹¬í™” B â€” UX/ê¸°ëŠ¥ ê³ ë„í™”")
    st.markdown(
        """
- **íˆìŠ¤í† ë¦¬ ì €ì¥/ë³µì›**: ì„¸ì…˜ ë‚´ ì§„ë‹¨ ê¸°ë¡ì„ ì €ì¥í•˜ê³ , í´ë¦­ í•œ ë²ˆìœ¼ë¡œ ê²°ê³¼ ë³µì›  
- **ê²°ê³¼ ë‚´ë³´ë‚´ê¸°**: JSON + PDF(ReportLab) ë‹¤ìš´ë¡œë“œë¡œ ì œì¶œ/ê³µìœ  í¸ì˜ì„± ê°•í™”  
- **ëŒ€ì‹œë³´ë“œ**: ìµœê·¼ ê¸°ë¡/ì™¸ë¶€ API ìƒíƒœ/ì ìˆ˜ ìŠ¤ëƒ…ìƒ·ì„ í•œ í™”ë©´ì—ì„œ í™•ì¸  
- **ë‹¤êµ­ì–´ UI ìµœì†Œ ì§€ì›**: ko/en ì „í™˜ + ë²ˆì—­ APIë¡œ ê²°ê³¼ í™•ì¥

âœ… ì²´í¬: ê¸°ë³¸ ê¸°ëŠ¥ ì™¸ UX ê°œì„ ì´ ì‹¤ì œ ê°€ì¹˜(ì‹œì—°/ì œì¶œ/ë°˜ë³µì‚¬ìš©)ë¥¼ ë†’ì„
"""
    )

    st.markdown("## 5. ì‹ ë¢°ì„±/ì„¤ëª…ê°€ëŠ¥ì„±(ì‹¬ì‚¬ì í¬ì¸íŠ¸)")
    st.markdown(
        """
- **í™˜ê° ë°©ì§€ ì •ì±… ë¬¸êµ¬**: ê·¼ê±° ì—†ëŠ” ìˆ˜ì¹˜/ìš”ê°• ë‹¨ì • ê¸ˆì§€  
- **CSV ìë™ ê²€ì¦ ë¦¬í¬íŠ¸**: í•„ìˆ˜ ì»¬ëŸ¼/ì´ìƒì¹˜/ì¤‘ë³µ/route_detail ì»¤ë²„ë¦¬ì§€ ì ê²€  
- **ë°ì´í„° ì‹ ë¢°ë„ ì ìˆ˜(0~100)**: í‘œë³¸/ì—°ë„ ë‹¤ì–‘ì„±/ê²°ì¸¡/ì¤‘ë³µ/ì»¤ë²„ë¦¬ì§€ ê¸°ë°˜  
- **ê°€ì¤‘ì¹˜ í…Œì´ë¸” ê³µê°œ + ê¸°ì—¬ë„ breakdown**: ì™œ ì´ëŸ° ì ìˆ˜ê°€ ë‚˜ì™”ëŠ”ì§€ ì„¤ëª… ê°€ëŠ¥  
- **(ìˆ˜ì‹œ) ì„¸ë¶€ ì „í˜• ì ìˆ˜ ë¶„ë¦¬(ì„¤ëª…ìš©)**: í•™ì¢…/êµê³¼/ë…¼ìˆ ë³„ ê²½ë¡œ ë¦¬ìŠ¤í¬ í‘œí˜„ ê°•í™”
"""
    )

    st.markdown("## 6. Technical Spec")
    st.table(
        [
            {"êµ¬ë¶„": "Input Data", "ìƒì„¸ ì •ì˜": "í¬ë§ ì „í˜•(ì§ì ‘ ì„ íƒ) + ì„±ì (ë‚´ì‹ /ëª¨ì˜ êµ¬ê°„) + (ì„ íƒ)ëŒ€í•™/í•™ê³¼ í‚¤ + ì„±í–¥/ë¹„êµê³¼/ì œì•½ + ì™¸ë¶€ API ì…ë ¥(ë„ì‹œ/ë‰´ìŠ¤í‚¤ì›Œë“œ/ì–¸ì–´)"},
            {"êµ¬ë¶„": "AI Prompting", "ìƒì„¸ ì •ì˜": "ì „í˜• ì¡´ì¤‘ + ê°€ëŠ¥ì„±/ë¦¬ìŠ¤í¬/ëŒ€ì•ˆ ì œì‹œ. ê·¼ê±° ë¬¸ì„œ ë°– ìˆ˜ì¹˜ ë‹¨ì • ê¸ˆì§€. í™•ë¥  ë‹¨ì • ëŒ€ì‹  ì•ˆì •/ì ì •/ë„ì „ êµ¬ê°„."},
            {"êµ¬ë¶„": "Output Format", "ìƒì„¸ ì •ì˜": "ê°€ëŠ¥ì„± ì¹´ë“œ + ì ìˆ˜ breakdown + A/B/C ì°¨íŠ¸ + 8ì£¼ ë¡œë“œë§µ + ê·¼ê±°(expander) + ì™¸ë¶€ API ì¸ì‚¬ì´íŠ¸ + JSON/PDF/ë²ˆì—­ ë‹¤ìš´ë¡œë“œ"},
        ]
    )

    st.markdown("## 7. KPI(ì˜ˆì‹œ 3ê°œ)")
    st.markdown(
        """
- **Time-to-Plan**: ì…ë ¥ ì‹œì‘â†’8ì£¼ í”Œëœ ìƒì„±ê¹Œì§€ ê±¸ë¦° ì‹œê°„(ë¶„)  
- **Plan Save Rate**: ê²°ê³¼ ì €ì¥/ë‹¤ìš´ë¡œë“œ ë¹„ìœ¨(%)  
- **Perceived Trust**: â€œê·¼ê±°(ì¶œì²˜) ì œì‹œê°€ ë„ì›€ì´ ëë‹¤â€ ë§Œì¡±ë„(5ì  ì²™ë„)
"""
    )

st.caption("â€» ë³¸ ì•±ì€ ì°¸ê³ ìš© ì»¨ì„¤íŒ… ë„êµ¬ì´ë©°, í™•ë¥  ë‹¨ì •/í•©ê²© ë³´ì¥ì€ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
